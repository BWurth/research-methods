[
  {
    "objectID": "LICENSE-CODE.html",
    "href": "LICENSE-CODE.html",
    "title": "Research Methods in R",
    "section": "",
    "text": "MIT License\nCopyright (c) 2024 Bernd Wurth\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "01-introduction/01-introduction.html",
    "href": "01-introduction/01-introduction.html",
    "title": "1. Practical Introduction to R",
    "section": "",
    "text": "This introduction covers the basics of R programming. As you progress, you’ll discover more advanced features and packages that extend R’s capabilities even further. Remember to use the help function (?function_name) to learn more about specific functions and their usage."
  },
  {
    "objectID": "LICENSE-CONTENT.html",
    "href": "LICENSE-CONTENT.html",
    "title": "Research Methods in R",
    "section": "",
    "text": "Creative Commons Attribution 4.0 International (CC BY 4.0)\nCopyright (c) 2024 Bernd Wurth\nYou are free to: - Share — copy and redistribute the material in any medium or format - Adapt — remix, transform, and build upon the material for any purpose, even commercially.\nUnder the following terms: - Attribution — You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\nNo additional restrictions — You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.\nFull legal text: https://creativecommons.org/licenses/by/4.0/legalcode"
  },
  {
    "objectID": "00-getting-started/00-getting-started.html",
    "href": "00-getting-started/00-getting-started.html",
    "title": "0. Getting Started",
    "section": "",
    "text": "R is a powerful, open-source programming language and software environment for statistical computing, data analysis, and graphical visualisation. It provides a wide variety of statistical and graphical techniques, including linear and nonlinear modeling, time-series analysis, classification, clustering, and more.\n\n\n\nR was created by Ross Ihaka and Robert Gentleman at the University of Auckland, New Zealand, and is currently developed by the R Development Core Team. The project was conceived in 1992, with an initial version released in 1995 and a stable beta version in 2000. R is named partly after its creators (shared first letter of the authors, Ross and Robert) and partly as a play on the name of the S language, which it was designed to emulate. While S was a commercial software, R was created as a free alternative, gaining wide adoption due to its open-source nature and flexibility.\n\n\n\nR has become increasingly popular in academic fields such as social sciences, economics, entrepreneurship, and business/management as well as in corporate environments. Its appeal stems from being an open-source, free platform, making it globally accessible to researchers and students. R’s extensive ecosystem of user-contributed packages significantly expands its functionality, while its scripting capability ensures reproducibility of analyses. Researchers and analysts leverage R’s comprehensive statistical and machine learning techniques to explore data trends, build predictive models, and create publication-quality visualizations that inform decision-making. The language is further bolstered by a large, active community that continuously contributes to its development and provides abundant learning resources, making R an invaluable tool for data exploration, analysis, and presentation across various disciplines.\n\n\n\nR’s versatility makes it an excellent tool for various aspects of research:\n\nData wrangling: R excels at cleaning, transforming, and restructuring data. Packages like dplyr and tidyr provide intuitive ways to manipulate data.\nStatistical analysis: From basic descriptive statistics to advanced modeling techniques, R covers a wide range of statistical methods. It’s particularly strong in areas like regression analysis, ANOVA, time series analysis, and machine learning.\nData visualisation: The ggplot2 package, part of the tidyverse, allows for the creation of complex, publication-quality visualisations with a consistent and intuitive syntax.\nLarge dataset handling: R can efficiently work with large datasets, especially when using packages optimized for big data, such as data.table or spark.\nReproducible research: R Markdown and Quarto (like this document) allow for the integration of code, results, and narrative, facilitating reproducible research practices.\nExtensibility: R’s package system allows users to easily extend its functionality, making it adaptable to specific research needs.\nCommunity support: R has a vibrant community that provides help and feedback and continuously develops and shares packages.\n\n\n\n\nR can integrate with various other tools and technologies, allowing for flexible workflows across different technologies. Example include:\n\nPython: The reticulate package allows R to interface with Python, combining the strengths of both languages.\nDatabases: R can connect to various databases (e.g., SQL, MongoDB) for data retrieval and storage.\nWeb technologies: Packages like shiny allow for the creation of interactive web applications using R.\nVersion control: R projects can be managed with Git and GitHub, facilitating collaboration and version control."
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#what-is-r",
    "href": "00-getting-started/00-getting-started.html#what-is-r",
    "title": "0. Getting Started",
    "section": "",
    "text": "R is a powerful, open-source programming language and software environment for statistical computing, data analysis, and graphical visualisation. It provides a wide variety of statistical and graphical techniques, including linear and nonlinear modeling, time-series analysis, classification, clustering, and more."
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#brief-history-of-r",
    "href": "00-getting-started/00-getting-started.html#brief-history-of-r",
    "title": "0. Getting Started",
    "section": "",
    "text": "R was created by Ross Ihaka and Robert Gentleman at the University of Auckland, New Zealand, and is currently developed by the R Development Core Team. The project was conceived in 1992, with an initial version released in 1995 and a stable beta version in 2000. R is named partly after its creators (shared first letter of the authors, Ross and Robert) and partly as a play on the name of the S language, which it was designed to emulate. While S was a commercial software, R was created as a free alternative, gaining wide adoption due to its open-source nature and flexibility."
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#used-of-r-in-research-and-data-analysis",
    "href": "00-getting-started/00-getting-started.html#used-of-r-in-research-and-data-analysis",
    "title": "0. Getting Started",
    "section": "",
    "text": "R has become increasingly popular in academic fields such as social sciences, economics, entrepreneurship, and business/management as well as in corporate environments. Its appeal stems from being an open-source, free platform, making it globally accessible to researchers and students. R’s extensive ecosystem of user-contributed packages significantly expands its functionality, while its scripting capability ensures reproducibility of analyses. Researchers and analysts leverage R’s comprehensive statistical and machine learning techniques to explore data trends, build predictive models, and create publication-quality visualizations that inform decision-making. The language is further bolstered by a large, active community that continuously contributes to its development and provides abundant learning resources, making R an invaluable tool for data exploration, analysis, and presentation across various disciplines."
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#key-features-and-advantages-of-r",
    "href": "00-getting-started/00-getting-started.html#key-features-and-advantages-of-r",
    "title": "0. Getting Started",
    "section": "",
    "text": "R’s versatility makes it an excellent tool for various aspects of research:\n\nData wrangling: R excels at cleaning, transforming, and restructuring data. Packages like dplyr and tidyr provide intuitive ways to manipulate data.\nStatistical analysis: From basic descriptive statistics to advanced modeling techniques, R covers a wide range of statistical methods. It’s particularly strong in areas like regression analysis, ANOVA, time series analysis, and machine learning.\nData visualisation: The ggplot2 package, part of the tidyverse, allows for the creation of complex, publication-quality visualisations with a consistent and intuitive syntax.\nLarge dataset handling: R can efficiently work with large datasets, especially when using packages optimized for big data, such as data.table or spark.\nReproducible research: R Markdown and Quarto (like this document) allow for the integration of code, results, and narrative, facilitating reproducible research practices.\nExtensibility: R’s package system allows users to easily extend its functionality, making it adaptable to specific research needs.\nCommunity support: R has a vibrant community that provides help and feedback and continuously develops and shares packages."
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#rs-interface-with-other-tools",
    "href": "00-getting-started/00-getting-started.html#rs-interface-with-other-tools",
    "title": "0. Getting Started",
    "section": "",
    "text": "R can integrate with various other tools and technologies, allowing for flexible workflows across different technologies. Example include:\n\nPython: The reticulate package allows R to interface with Python, combining the strengths of both languages.\nDatabases: R can connect to various databases (e.g., SQL, MongoDB) for data retrieval and storage.\nWeb technologies: Packages like shiny allow for the creation of interactive web applications using R.\nVersion control: R projects can be managed with Git and GitHub, facilitating collaboration and version control."
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#what-is-rstudio",
    "href": "00-getting-started/00-getting-started.html#what-is-rstudio",
    "title": "0. Getting Started",
    "section": "2.1 What is RStudio?",
    "text": "2.1 What is RStudio?\nRStudio is an integrated development environment (IDE) specifically designed for R. It provides a user-friendly interface that makes working with R more accessible and efficient, especially for beginners."
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#how-rstudio-enhances-the-r-programming-experience",
    "href": "00-getting-started/00-getting-started.html#how-rstudio-enhances-the-r-programming-experience",
    "title": "0. Getting Started",
    "section": "2.2 How RStudio enhances the R programming experience",
    "text": "2.2 How RStudio enhances the R programming experience\nRStudio improves R programming productivity by offering a unified platform that integrates all aspects of the R workflow. Within a single window, users can write, edit, and execute R code, visualize results, and manage files efficiently. The IDE features a sophisticated code editor with syntax highlighting and auto-completion, streamlining the coding process. It provides seamless access to R documentation and help files, facilitating quick reference and learning. RStudio’s integrated plot and data viewers allow for immediate visualisation and inspection of results. The platform also includes robust project management tools to organize work effectively. Furthermore, RStudio’s built-in support for version control systems like Git enables smooth collaboration and code versioning, making it an all-encompassing solution for R programmers of all levels."
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#key-features-of-rstudio",
    "href": "00-getting-started/00-getting-started.html#key-features-of-rstudio",
    "title": "0. Getting Started",
    "section": "2.3 Key features of RStudio",
    "text": "2.3 Key features of RStudio\nRStudio’s interface is divided into four main panes (Figure 1):\n\nSource Editor: Write and save R scripts for easy reproducibility.\nConsole: Interact with R directly for quick calculations or testing code snippets.\nEnvironment/History: Displays your current workspace objects, command history, and has build-in integration for Git.\nFiles/Plots/Packages/Help: A multi-purpose pane for file management, viewing plots, managing packages, and accessing help documentation.\n\n\n\n\n\n\n\nFigure 1: Overview of the RStudio user interface"
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#rstudio-cloud-option",
    "href": "00-getting-started/00-getting-started.html#rstudio-cloud-option",
    "title": "0. Getting Started",
    "section": "2.4 RStudio Cloud Option",
    "text": "2.4 RStudio Cloud Option\nFor students who prefer not to install R locally, RStudio Cloud offers a browser-based alternative. With a free account, you can create projects and run R code in your browser without the need for installation. To set up a free RStudio Cloud account:\n\nVisit https://rstudio.cloud/\nClick “Get Started for Free”\nSign up using your email or Google account\nOnce logged in, you can create new projects and start using R immediately in your browser\n\nRStudio Cloud provides a consistent environment across different computers and operating systems, which can be particularly useful for collaborative work or when working on multiple devices."
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#system-requirements-for-r-and-rstudio",
    "href": "00-getting-started/00-getting-started.html#system-requirements-for-r-and-rstudio",
    "title": "0. Getting Started",
    "section": "3.1 System requirements for R and RStudio",
    "text": "3.1 System requirements for R and RStudio\nBefore installing R and RStudio, ensure your system meets these requirements:\n\nFor Windows:\n\nWindows 7 or later\n32-bit or 64-bit operating system\n\nFor Mac:\n\nmacOS 10.13 (High Sierra) or later\n64-bit operating system\n\n\nBoth R and RStudio are relatively lightweight programs and should run on most modern computers."
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#step-by-step-installation-process-for-windows",
    "href": "00-getting-started/00-getting-started.html#step-by-step-installation-process-for-windows",
    "title": "0. Getting Started",
    "section": "3.2 Step-by-step installation process for Windows",
    "text": "3.2 Step-by-step installation process for Windows\n1. Download R:\nGo to https://cran.r-project.org/\nClick on “Download R for Windows” (Figure 2)\n\n\n\n\n\n\nFigure 2: CRAN homepage (red arrow pointing to the link for downloading R for Windows)\n\n\n\nClick on “base” (Figure 3)\n\n\n\n\n\n\nFigure 3: CRAN download page with subdirectories for Windows (red arrow pointing to the link for first time installation of R)\n\n\n\nClick on the download link for the latest version (Figure 4)\n\n\n\n\n\n\nFigure 4: CRAN download page for base version for Windows (red arrow pointing to the download link)\n\n\n\n2. Install R:\nRun the downloaded .exe file\nFollow the installation wizard, accepting the default options\n3. Download RStudio:\nGo to https://www.rstudio.com/products/rstudio/download/\nScroll down to “RStudio Desktop”\nClick on “Download RStudio for Windows” (Figure 5)\n\n\n\n\n\n\nFigure 5: Posit page for RStudio (red arrow pointing to the download link for Windows)\n\n\n\n4. Install RStudio:\nRun the downloaded .exe file\nFollow the installation wizard, accepting the default options (Figure 6)\n\n\n\n\n\n\nFigure 6: RStudio installation wizard for Windows"
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#step-by-step-installation-process-for-mac",
    "href": "00-getting-started/00-getting-started.html#step-by-step-installation-process-for-mac",
    "title": "0. Getting Started",
    "section": "3.3 Step-by-step installation process for Mac",
    "text": "3.3 Step-by-step installation process for Mac\n1. Download R:\nGo to https://cran.r-project.org/\nClick on “Download R for macOS” (Figure 7)\n\n\n\n\n\n\nFigure 7: CRAN homepage (red arrow pointing to the link for downloading R for Mac\n\n\n\nClick on the .pkg file appropriate for your macOS version (Figure 8)\n\n\n\n\n\n\nFigure 8: CRAN download page for Mac (red arrows pointing to the download link for respective Mac version, depending on whether you have a newer Apple Silicone Mac or an older Intel Mac)\n\n\n\n2. Install R:\nOpen the downloaded .pkg file\nFollow the installation wizard, accepting the default options (Figure 9)\n\n\n\n\n\n\nFigure 9: Instalation window for R (Mac)\n\n\n\n3. Download RStudio:\nGo to https://www.rstudio.com/products/rstudio/download/\nScroll down to “Install RStudio” and click on “Download RStudio Desktop for macOS” (Figure 10)\n\n\n\n\n\n\nFigure 10: Posit page for RStudio (red arrow pointing to the download link for Mac)\n\n\n\n4. Install RStudio:\nOpen the downloaded .dmg file\nDrag the RStudio icon to your Applications folder (Figure 11)\n\n\n\n\n\n\nFigure 11: Installation window for RStudio on Mac (drag-and-drop the RStudio icon to the Applications folder)"
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#verifying-successful-installation",
    "href": "00-getting-started/00-getting-started.html#verifying-successful-installation",
    "title": "0. Getting Started",
    "section": "3.4 Verifying successful installation",
    "text": "3.4 Verifying successful installation\nAfter installation, open RStudio. You should see the console and other features of RStudio. In the Console pane (usually bottom-left), you should see information about the R version. Type 1 + 1 in the Console and press Enter. If you get the result 2, both R and RStudio are working correctly."
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#r-and-rstudio-updates",
    "href": "00-getting-started/00-getting-started.html#r-and-rstudio-updates",
    "title": "0. Getting Started",
    "section": "3.5 R and RStudio Updates",
    "text": "3.5 R and RStudio Updates\nKeeping R and RStudio up to date is important for accessing the latest features and bug fixes:\n\nTo check for R updates:\n\nOpen RStudio\nGo to Tools &gt; Check for Updates\nIf an update is available, it will prompt you to install it\n\nTo check for RStudio updates:\n\nOpen RStudio\nGo to Help &gt; Check for Updates\nIf an update is available, it will prompt you to install it\n\n\nIt’s generally a good practice to update both R and RStudio every few months or when starting a new project."
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#what-are-r-packages",
    "href": "00-getting-started/00-getting-started.html#what-are-r-packages",
    "title": "0. Getting Started",
    "section": "4.1 What are R packages?",
    "text": "4.1 What are R packages?\nR packages are collections of R functions, data, and documentation that extend the capabilities of base R. They are the fundamental units of reproducible R code, allowing users to easily share and reuse code."
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#the-importance-of-packages-in-extending-rs-functionality",
    "href": "00-getting-started/00-getting-started.html#the-importance-of-packages-in-extending-rs-functionality",
    "title": "0. Getting Started",
    "section": "4.2 The importance of packages in extending R’s functionality",
    "text": "4.2 The importance of packages in extending R’s functionality\nR packages provide users with access to specialised, pre-written functions, eliminating the need to code complex operations from scratch. These packages typically undergo rigorous testing and maintenance, ensuring code consistency and reliability. By offering a standardised method for sharing code and methodologies, packages facilitate collaboration among researchers and developers. Moreover, they significantly expand R’s capabilities, extending its reach into specific domains, ranging from advanced statistical techniques to interfaces with other software systems. This extensibility through packages makes R a versatile and powerful tool adaptable to a wide array of analytical challenges across various fields."
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#brief-introduction-to-cran",
    "href": "00-getting-started/00-getting-started.html#brief-introduction-to-cran",
    "title": "0. Getting Started",
    "section": "4.3 Brief introduction to CRAN",
    "text": "4.3 Brief introduction to CRAN\nThe Comprehensive R Archive Network (CRAN) serves as the official repository for R packages, hosting thousands of user-contributed extensions to the R language. CRAN ensures the quality and consistency of its offerings through a rigorous review process for all submitted packages. Users can easily install these packages directly within R using the install.packages() function, streamlining the process of extending R’s capabilities. Furthermore, CRAN provides comprehensive documentation and vignettes for each package, offering users detailed information on functionality, usage, and implementation. This centralized, curated repository plays a crucial role in maintaining R’s ecosystem, facilitating easy access to a vast array of tools and functions for R users worldwide. To explore CRAN, visit https://cran.r-project.org/."
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#setting-up-a-working-directory",
    "href": "00-getting-started/00-getting-started.html#setting-up-a-working-directory",
    "title": "0. Getting Started",
    "section": "5.1 Setting up a working directory",
    "text": "5.1 Setting up a working directory\nSetting up a proper working directory is crucial for organizing your R projects:\n\nUse RStudio’s project feature:\n\nGo to File &gt; New Project\nChoose a new or existing directory\nThis creates an .Rproj file and sets the working directory automatically\n\nAlternatively, set the working directory manually:\n\nUse setwd(\"/path/to/your/directory\") in your R script\nOr use Session &gt; Set Working Directory &gt; Choose Directory in RStudio"
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#how-to-organize-project-files-for-research",
    "href": "00-getting-started/00-getting-started.html#how-to-organize-project-files-for-research",
    "title": "0. Getting Started",
    "section": "5.2 How to organize project files for research",
    "text": "5.2 How to organize project files for research\nA well-organized project structure might look like this:\nproject/\n├── data/\n│   ├── raw/\n│   └── processed/\n├── scripts/\n├── output/\n│   ├── figures/\n│   └── tables/\n├── docs/\n└── project.Rproj\n\ndata/: Store your data files\nscripts/: Keep your R scripts\noutput/: Save generated figures and tables\ndocs/: Store documentation and reports"
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#importance-of-commenting-and-code-organization",
    "href": "00-getting-started/00-getting-started.html#importance-of-commenting-and-code-organization",
    "title": "0. Getting Started",
    "section": "5.3 Importance of commenting and code organization",
    "text": "5.3 Importance of commenting and code organization\nGood coding practices improve readability and reproducibility:\n\nUse clear and concise comments to explain your code\nOrganize your code into logical sections\nUse meaningful variable and function names\nKeep your code DRY (Don’t Repeat Yourself)\n\nExample of well-commented code:\n# Load necessary libraries\nlibrary(tidyverse)\n\n# Read in the data\ndata &lt;- read_csv(\"data/raw/survey_results.csv\")\n\n# Clean the data\nclean_data &lt;- data %&gt;%\n  filter(!is.na(age)) %&gt;%  # Remove rows with missing age\n  mutate(income = as.numeric(income))  # Convert income to numeric\n\n# Calculate summary statistics\nsummary_stats &lt;- clean_data %&gt;%\n  group_by(education) %&gt;%\n  summarize(\n    mean_income = mean(income, na.rm = TRUE),\n    median_age = median(age, na.rm = TRUE)\n  )\n\n# Print results\nprint(summary_stats)"
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#version-control-basics",
    "href": "00-getting-started/00-getting-started.html#version-control-basics",
    "title": "0. Getting Started",
    "section": "5.4 Version control basics",
    "text": "5.4 Version control basics\nVersion control is essential for tracking changes in your code and collaborating with others. Git is a popular version control system, and GitHub is a platform for hosting Git repositories.\nBasic Git concepts:\n\nRepository: A project’s folder containing all files and version history\nCommit: A snapshot of your project at a specific point in time\nBranch: A parallel version of your repository\nPull request: A method to propose changes to a repository\n\nWhile we won’t go into detail here, learning Git can greatly enhance your research workflow."
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#official-r-documentation",
    "href": "00-getting-started/00-getting-started.html#official-r-documentation",
    "title": "0. Getting Started",
    "section": "6.1 Official R Documentation",
    "text": "6.1 Official R Documentation\nThe official R documentation is a valuable resource for learning about the functions and packages available in R.\n\nThe R Project: https://www.r-project.org/\nR Documentation: https://www.rdocumentation.org/\n\nIn addition, the R Journal, a peer-reviewed open-access publication, serves as an invaluable resource for R users, offering in-depth articles on new packages, statistical methods, and applications of R in various fields, thereby providing both support for current users and insights into the evolving capabilities of the R ecosystem."
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#recommended-books-and-online-materials",
    "href": "00-getting-started/00-getting-started.html#recommended-books-and-online-materials",
    "title": "0. Getting Started",
    "section": "6.2 Recommended Books and Online Materials",
    "text": "6.2 Recommended Books and Online Materials\nBooks\n\n“R for Data Science (2e)” by Hadley Wickham, Mine Cetinkaya-Rundel, and Garrett Grolemund [ book | website | GitHub ]\n“The Art of R Programming” by Norman Matloff [ book ]\n“Advanced R (2e)” by Hadley Wickham [ book | website | GitHub ]\n“ggplot2: Elegant Graphics for Data Analysis (3e)” by Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen [ website | GitHub ]\n“R Graphics Cookbook (2e)” by Winston Chang [ book | website ]\n“Text Mining with R: A Tidy Approach” by Julia Silge and David Robinson [ book | website | GitHub]\n\nCheatsheets\nCheatsheets provide a handy reference guide for various aspects of working with R and RStudio, including RStudio, data tidying with tidyr, data transformation with dplyr, and data visualisation with ggplot2, among others (see others here).\nPosit Recipes\nPosit recipes (previously Posit primers) represent a collection of R code snippets and instructions featuring up-to-date best practices for coding in R: https://posit.cloud/learn/recipes.\nGitHub Repositories and Online Course Materials\n\nUniversity of Oregon (EC 607) by Grant McDermott [GitHub]"
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#community-forums-and-support-channels",
    "href": "00-getting-started/00-getting-started.html#community-forums-and-support-channels",
    "title": "0. Getting Started",
    "section": "6.3 Community forums and support channels",
    "text": "6.3 Community forums and support channels\nThere are a variety of other in-person and online resources available, including:\n\nStack Overflow (R tag): https://stackoverflow.com/questions/tagged/r\nRStudio community: https://community.rstudio.com/\nR-Ladies (an organization to promote gender diversity in the R community): https://rladies.org\nR-bloggers: https://www.r-bloggers.com/\n#rstats on X (formerly Twitter)\n\nRemember, the R community is known for being helpful and welcoming to newcomers. Don’t hesitate to ask questions and engage with other R users as you begin your journey!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Research Methods in R",
    "section": "",
    "text": "This course serves as an introduction to research methods, providing students with a foundational understanding of how to conduct data analysis using the R programming language. Through hands-on practice, students will learn essential concepts such as data manipulation, statistical analysis, and visualisation, all of which are critical for conducting independent research. By the end of the course, students will be equipped with the skills needed to effectively apply quantitative methods in their dissertations, enabling them to analyse real-world data and draw meaningful insights for research in business and entrepreneurship and social sciences more broadly.\nFor more information, visit our public GitHub repository."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Research Methods in R",
    "section": "",
    "text": "This course serves as an introduction to research methods, providing students with a foundational understanding of how to conduct data analysis using the R programming language. Through hands-on practice, students will learn essential concepts such as data manipulation, statistical analysis, and visualisation, all of which are critical for conducting independent research. By the end of the course, students will be equipped with the skills needed to effectively apply quantitative methods in their dissertations, enabling them to analyse real-world data and draw meaningful insights for research in business and entrepreneurship and social sciences more broadly.\nFor more information, visit our public GitHub repository."
  },
  {
    "objectID": "index.html#course-outline",
    "href": "index.html#course-outline",
    "title": "Research Methods in R",
    "section": "Course Outline",
    "text": "Course Outline\nClick on the links below to access the lesson materials. Each lesson includes theory, examples, and practical exercises. We recommend that you work through the lessons in the given order and use the HTML versions, but the PDF files contain the same information.\n\nGetting Started [ html | pdf ]\nIntroduction [ html | pdf ]"
  },
  {
    "objectID": "index.html#university-of-glasgow-mgt4018-and-mgt4090",
    "href": "index.html#university-of-glasgow-mgt4018-and-mgt4090",
    "title": "Research Methods in R",
    "section": "University of Glasgow MGT4018 and MGT4090",
    "text": "University of Glasgow MGT4018 and MGT4090\nThis course covers all required materials and more for the University of Glasgow’s third year courses MGT4018 and MGT4090 that prepare students for their dissertations. In addition to the general lessons and exercises above, the following tutorials cover the same exercises than the SPSS tutorials. If you have never used R before, please go through 00. Getting Started and 01. Introduction before starting with these labs. The video below will help you get started:\n\nLab 1 [ html | pdf ]\nLab 2 [ html | pdf ]"
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Research Methods in R",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis course and its materials are the culmination of many years of work and delivering a variety of classes around research methods and data science at the University of Strathclyde and the University of Glasgow. Some of the content in the earlier lessons is inspired by and adapted from teaching materials from Kate Pyper (LinkedIn) and the organisation and structure of this course have benefited from Grant McDermott’s (GitHub) EC 607 Data Science for Economists at the University of Oregon."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Research Methods in R",
    "section": "License",
    "text": "License\nThis repository is licensed under two different licenses for different types of content:\n\nCode (MIT License): All R scripts, code snippets, and technical components of the course are licensed under the MIT License. You are free to use, copy, modify, merge, publish, distribute, sublicense, or sell copies of the code, as long as attribution is provided. See the LICENSE-CODE file for details.\nCourse Materials (CC BY 4.0): All written content, lessons, quizzes, and educational materials in this repository are licensed under the Creative Commons Attribution 4.0 International License. You are free to share and adapt the materials, even for commercial purposes, as long as attribution is provided. See the LICENSE-CONTENT file for details."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html",
    "href": "lab-uofg-01/lab-uofg-01.html",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "",
    "text": "This lab is the same as the SPSS Lab 1 for MGT4018 and MGT4090. We use base R functions as the default. While there are many R packages available, understanding base R operations provides a strong foundation for data analysis.\n\n\n\n\n\n\nAlternatives using R packages\n\n\n\n\n\nAlternatives for achieving the same outcomes using different R packages are provided in green boxes. If you want to explore these alternatives, each box will introduce the respective package, how to install and use it, and the outputs it can produce."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-1-set-up-your-workspace",
    "href": "lab-uofg-01/lab-uofg-01.html#step-1-set-up-your-workspace",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.1 Step 1: Set Up Your Workspace",
    "text": "2.1 Step 1: Set Up Your Workspace\n\nOpen RStudio and start a new script.\nSave your script with an appropriate name, e.g., Lab1_Exercise_A.R."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-2-creating-variables",
    "href": "lab-uofg-01/lab-uofg-01.html#step-2-creating-variables",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.2 Step 2: Creating Variables",
    "text": "2.2 Step 2: Creating Variables\nIn base R, we will create our vectors and combine them into a data frame. Use the following code to create your variables:\n\n# Create vectors for our data\nid &lt;- 1:30\n\n# Create age bands with labels\nage_bands &lt;- factor(\n  c(1,3,2,4,2,5,5,2,3,1,4,1,3,2,4,2,5,5,2,3,1,4,2,4,2,6,5,2,3,1),\n  levels = 1:6,\n  labels = c(\"&lt;21\", \"21-30\", \"31-40\", \"41-50\", \"&gt;50\", \"Invalid\")\n)\n\n# Create gender categories with labels\ngender &lt;- factor(\n  c(0,1,1,0,0,0,1,1,1,0,9,0,2,1,0,0,1,1,0,0,1,0,0,0,1,1,1,0,9,8),\n  levels = c(0,1,2,9),\n  labels = c(\"Male\", \"Female\", \"Other\", \"Prefer not to say\")\n)\n\n\n\n\n\n\n\nNote\n\n\n\nIn R, we use factor() to create categorical variables. This is similar to value labels in SPSS. The levels argument specifies the underlying codes, while labels provides the human-readable labels."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-3-assign-labels-and-levels",
    "href": "lab-uofg-01/lab-uofg-01.html#step-3-assign-labels-and-levels",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.3 Step 3: Assign Labels and Levels",
    "text": "2.3 Step 3: Assign Labels and Levels\nIn R, we use factors to represent categorical data with defined levels.\n\n\n\n\n\n\nNote\n\n\n\nIn R, we use factor() to create categorical variables. This is similar to value labels in SPSS. The levels argument specifies the underlying codes, while labels provides the human-readable labels."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-4-save-the-dataset",
    "href": "lab-uofg-01/lab-uofg-01.html#step-4-save-the-dataset",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.4 Step 4: Save the Dataset",
    "text": "2.4 Step 4: Save the Dataset\n\n\n\n\n\n\nTidyverse Alternative (click to expand)\n\n\n\n\n\nThis content will be hidden until clicked. Here we inclue the tidyverse alternatives.\n# Create an empty data frame with the variables ID, AgeBand, and Gender\ndata &lt;- data.frame(ID = integer(), AgeBand = factor(), Gender = factor())"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-5-entering-data",
    "href": "lab-uofg-01/lab-uofg-01.html#step-5-entering-data",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.5 Step 5: Entering Data",
    "text": "2.5 Step 5: Entering Data"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-6-loading-and-viewing-data",
    "href": "lab-uofg-01/lab-uofg-01.html#step-6-loading-and-viewing-data",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.6 Step 6: Loading and Viewing Data",
    "text": "2.6 Step 6: Loading and Viewing Data"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-7-exploring-value-labels",
    "href": "lab-uofg-01/lab-uofg-01.html#step-7-exploring-value-labels",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.7 Step 7: Exploring Value Labels",
    "text": "2.7 Step 7: Exploring Value Labels"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-8-basic-exploration-with-summary-statistics",
    "href": "lab-uofg-01/lab-uofg-01.html#step-8-basic-exploration-with-summary-statistics",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.8 Step 8: Basic Exploration with Summary Statistics",
    "text": "2.8 Step 8: Basic Exploration with Summary Statistics"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-9-correcting-errors",
    "href": "lab-uofg-01/lab-uofg-01.html#step-9-correcting-errors",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.9 Step 9: Correcting Errors",
    "text": "2.9 Step 9: Correcting Errors"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-10-descriptive-statistics",
    "href": "lab-uofg-01/lab-uofg-01.html#step-10-descriptive-statistics",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.10 Step 10: Descriptive Statistics",
    "text": "2.10 Step 10: Descriptive Statistics"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-11-setting-variable-types",
    "href": "lab-uofg-01/lab-uofg-01.html#step-11-setting-variable-types",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.11 Step 11: Setting Variable Types",
    "text": "2.11 Step 11: Setting Variable Types"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-12-cross-tabulations",
    "href": "lab-uofg-01/lab-uofg-01.html#step-12-cross-tabulations",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.12 Step 12: Cross-tabulations",
    "text": "2.12 Step 12: Cross-tabulations"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#optional-expansion-plotting-the-data",
    "href": "lab-uofg-01/lab-uofg-01.html#optional-expansion-plotting-the-data",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.13 Optional Expansion: Plotting the Data",
    "text": "2.13 Optional Expansion: Plotting the Data"
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#projects-and-setting-up-a-working-directory",
    "href": "00-getting-started/00-getting-started.html#projects-and-setting-up-a-working-directory",
    "title": "0. Getting Started",
    "section": "5.1 Projects and setting up a working directory",
    "text": "5.1 Projects and setting up a working directory\n\n5.1.1 Why does this matter?\nWhen working in R, one of the key concepts you’ll encounter is managing your working directory. The working directory is the folder on your computer where R looks for files (e.g., data) to load and saves files you create. While there are different ways to set your working directory, this lesson will discuss the benefits and drawbacks of two common methods: using setwd() and RStudio Projects.\n\n\n5.1.2 What is setwd()?\nThe setwd() function in R sets the working directory to a specific folder. Below is the code example for setting your working directory. Alternatively, you can use Session &gt; Set Working Directory &gt; Choose Directory in RStudio.\nsetwd(\"C:/Users/YourName/Documents/MyProject\")\nBenefits of setwd()\n\nQuick setup: Useful for ad hoc or one-time analyses.\nSimple to understand: Easy to use for beginners doing small, standalone projects.\n\nDrawbacks of setwd()\n\nNot portable: If you share your code with someone else, it may not work because their folder paths are different.\nError-prone: Forgetting to set the correct working directory can cause errors when loading or saving files.\nBad practice for larger projects: As projects grow, managing file paths with setwd() becomes cumbersome and difficult to maintain.\n\n\n\n5.1.3 What Are RStudio Projects?\nRStudio Projects provide a structured way to manage your working directory. When you create a Project in RStudio, a special file (.Rproj) is created. Opening this file automatically sets the working directory to the folder containing the Project. You can create a Project in RStudio by following these steps:\n\nGo to File &gt; New Project\nChoose a new or existing directory\nThis creates an .Rproj file and sets the working directory automatically\n\nFurther information on how to set up Projects in RStudio can be found in the RStudio Projects Guide.\nBenefits of RStudio Projects\n\nPortability: Code and file references work seamlessly on any computer without modification.\nOrganization: Keeps all related files (data, scripts, output) in one folder.\nBest practice: Encourages better habits for managing larger or collaborative projects.\nIntegration: Works well with version control systems like Git, making collaboration easier.\n\nDrawbacks of RStudio Projects\n\nLearning curve: May feel complex for students doing very small, simple tasks.\nOverhead for small tasks: Setting up a Project for quick analyses might seem unnecessary.\n\n\n\n\n\n\n\nNote\n\n\n\nFor most work—-especially as your projects grow in size or complexity—-we recommend using RStudio Projects. While it may feel like extra work upfront, it fosters reproducibility and reduces errors, hereby saving time and frustration in the long run. Use setwd() sparingly and only for temporary tasks."
  },
  {
    "objectID": "01-introduction/01-introduction.html#full-execution-of-an-r-script",
    "href": "01-introduction/01-introduction.html#full-execution-of-an-r-script",
    "title": "1. Practical Introduction to R",
    "section": "2.1 Full Execution of an R Script",
    "text": "2.1 Full Execution of an R Script\nRunning a script from top to bottom is useful when you want to execute all the code at once. This is typically done after you’ve written and verified the entire script.\nSteps:\n\nSave your script with a .R extension, such as my_script.R.\nUse the source() function in R to execute the entire script:\n\nsource(\"my_script.R\")\n\nAlternatively, in RStudio:\n\nClick the Source button at the top of the script editor.\nUse the shortcut Ctrl + Shift + S (Windows) or Cmd + Shift + S (Mac).\n\n\nExample script:\n# Define a function\nadd_numbers &lt;- function(x, y) {\n  return(x + y)\n}\n\n# Perform calculations\nresult &lt;- add_numbers(5, 3)\nprint(result)\n\n# Generate a sequence\nseq_data &lt;- seq(1, 10, by = 2)\nprint(seq_data)"
  },
  {
    "objectID": "01-introduction/01-introduction.html#partial-execution-of-an-r-script",
    "href": "01-introduction/01-introduction.html#partial-execution-of-an-r-script",
    "title": "1. Practical Introduction to R",
    "section": "2.2 Partial Execution of an R Script",
    "text": "2.2 Partial Execution of an R Script\nRunning parts of your script manually is useful during the development and debugging process. This allows you to test specific sections without executing the entire script.\nSteps in RStudio:\n\nHighlight the portion of the script you want to run.\nPress Ctrl + Enter (Windows) or Cmd + Enter (Mac) to run the selected lines.\nIf you want to run only the current line, place the cursor on that line and press the same shortcut.\n\n# Define a function\nadd_numbers &lt;- function(x, y) {\n  return(x + y)\n}\n\n# Highlight and run the following line:\n# result &lt;- add_numbers(5, 3)\n\n# Debugging this line separately:\nprint(result)\n\n# Highlight and run this block to test sequences:\nseq_data &lt;- seq(1, 10, by = 2)\nprint(seq_data)"
  },
  {
    "objectID": "01-introduction/01-introduction.html#best-practices-for-script-organization",
    "href": "01-introduction/01-introduction.html#best-practices-for-script-organization",
    "title": "1. Practical Introduction to R",
    "section": "2.3 Best Practices for Script Organization",
    "text": "2.3 Best Practices for Script Organization\nDivide your script into sections using comments:\n# Section 1: Load libraries\nlibrary(ggplot2)\n\n# Section 2: Load data\ndata &lt;- read.csv(\"data.csv\")\n\n# Section 3: Analysis\nsummary(data)\nUse descriptive variable and function names to make scripts easier to understand.\nKeep your script modular—write functions for reusable code blocks.\nInclude comments to explain complex logic or calculations."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-1-setup",
    "href": "lab-uofg-01/lab-uofg-01.html#step-1-setup",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.1 Step 1: Setup",
    "text": "2.1 Step 1: Setup\nBefore starting any work in R, it is important to organize your files. This ensures that your scripts, datasets, and outputs are easy to manage and reproducible. Projects are strongly recommended for better organization and reproducibility, but setting a working directory is an alternative if needed (see also the respective section in 0. Getting Started).\nThe best way to organize your work is to create an RStudio project. This keeps all related files in a single folder. Follow these steps:\n\nOpen RStudio.\nGo to File &gt; New Project.\nSelect New Directory and then New Project.\nChoose a location on your computer and give the project a name, e.g., ResearchMethodsLab. Avoid spaces in folder and file names.\nClick Create Project. RStudio will open a new session within the project folder.\nCreate a new R script: Go to File &gt; New File &gt; R Script.\nSave the script in your project folder with an appropriate name, e.g., Lab_Exercise_A.R.\n\nIf you are not using a project, you will need to set a working directory manually. The working directory is the folder where R looks for files and saves outputs.\n\nIn your Finder (Mac) or Explorer (Windows), create a new folder for the R Labs (e.g., ResearchMethodsLab). Avoid spaces in folder and file names.\nOpen RStudio.\nCreate a new R script: Go to File &gt; New File &gt; R Script.\nSave the script in the folder that you previously created with an appropriate name, e.g., Lab_Exercise_A.R.\nSet the working directory in your script using the setwd() function. Copy the following code into your script, change the path to the older that you created, and execute the script.\n\nsetwd(\"path/to/your/folder\")\nNow you are ready to begin your work in R!"
  },
  {
    "objectID": "00-getting-started/00-getting-started.html#setup-projects-wd",
    "href": "00-getting-started/00-getting-started.html#setup-projects-wd",
    "title": "0. Getting Started",
    "section": "5.1 Projects and setting up a working directory",
    "text": "5.1 Projects and setting up a working directory\n\n5.1.1 Why does this matter?\nWhen working in R, one of the key concepts you’ll encounter is managing your working directory. The working directory is the folder on your computer where R looks for files (e.g., data) to load and saves files you create. While there are different ways to set your working directory, this lesson will discuss the benefits and drawbacks of two common methods: using setwd() and RStudio Projects.\n\n\n5.1.2 What is setwd()?\nThe setwd() function in R sets the working directory to a specific folder. Below is the code example for setting your working directory. Alternatively, you can use Session &gt; Set Working Directory &gt; Choose Directory in RStudio.\nsetwd(\"C:/Users/YourName/Documents/MyProject\")\nBenefits of setwd()\n\nQuick setup: Useful for ad hoc or one-time analyses.\nSimple to understand: Easy to use for beginners doing small, standalone projects.\n\nDrawbacks of setwd()\n\nNot portable: If you share your code with someone else, it may not work because their folder paths are different.\nError-prone: Forgetting to set the correct working directory can cause errors when loading or saving files.\nBad practice for larger projects: As projects grow, managing file paths with setwd() becomes cumbersome and difficult to maintain.\n\n\n\n5.1.3 What Are RStudio Projects?\nRStudio Projects provide a structured way to manage your working directory. When you create a Project in RStudio, a special file (.Rproj) is created. Opening this file automatically sets the working directory to the folder containing the Project. You can create a Project in RStudio by following these steps:\n\nGo to File &gt; New Project\nChoose a new or existing directory\nThis creates an .Rproj file and sets the working directory automatically\n\nFurther information on how to set up Projects in RStudio can be found in the RStudio Projects Guide.\nBenefits of RStudio Projects\n\nPortability: Code and file references work seamlessly on any computer without modification.\nOrganization: Keeps all related files (data, scripts, output) in one folder.\nBest practice: Encourages better habits for managing larger or collaborative projects.\nIntegration: Works well with version control systems like Git, making collaboration easier.\n\nDrawbacks of RStudio Projects\n\nLearning curve: May feel complex for students doing very small, simple tasks.\nOverhead for small tasks: Setting up a Project for quick analyses might seem unnecessary.\n\n\n\n\n\n\n\nNote\n\n\n\nFor most work—-especially as your projects grow in size or complexity—-we recommend using RStudio Projects. While it may feel like extra work upfront, it fosters reproducibility and reduces errors, hereby saving time and frustration in the long run. Use setwd() sparingly and only for temporary tasks."
  },
  {
    "objectID": "01-introduction/01-introduction.html#numeric",
    "href": "01-introduction/01-introduction.html#numeric",
    "title": "1. Practical Introduction to R",
    "section": "5.1 Numeric",
    "text": "5.1 Numeric\nNumeric data includes real numbers (decimal values).\n# Assigning a numeric value\nsalary &lt;- 55000.75\n\n# Displaying the type of data\ntypeof(salary)  # Output: \"double\""
  },
  {
    "objectID": "01-introduction/01-introduction.html#integer",
    "href": "01-introduction/01-introduction.html#integer",
    "title": "1. Practical Introduction to R",
    "section": "5.2 Integer",
    "text": "5.2 Integer\nIntegers are whole numbers. To explicitly define an integer, add an L after the number.\n# Assigning an integer value\nage &lt;- 30L\n\n# Displaying the type of data\ntypeof(age)  # Output: \"integer\""
  },
  {
    "objectID": "01-introduction/01-introduction.html#character",
    "href": "01-introduction/01-introduction.html#character",
    "title": "1. Practical Introduction to R",
    "section": "5.3 Character",
    "text": "5.3 Character\nCharacter data represents text or strings. In R, strings are enclosed in double (“) or single (’) quotes.\n# Assigning a character string\nname &lt;- \"John Doe\"\n\n# Displaying the type of data\ntypeof(name)  # Output: \"character\""
  },
  {
    "objectID": "01-introduction/01-introduction.html#logical",
    "href": "01-introduction/01-introduction.html#logical",
    "title": "1. Practical Introduction to R",
    "section": "5.4 Logical",
    "text": "5.4 Logical\nLogical values represent TRUE or FALSE. They are useful for decision-making and logical comparisons.\n# Assigning logical values\nis_graduate &lt;- TRUE\n\n# Displaying the type of data\ntypeof(is_graduate)  # Output: \"logical\""
  },
  {
    "objectID": "01-introduction/01-introduction.html#complex",
    "href": "01-introduction/01-introduction.html#complex",
    "title": "1. Practical Introduction to R",
    "section": "5.5 Complex",
    "text": "5.5 Complex\nComplex numbers consist of a real and an imaginary part. Business students will rarely use them.\n# Assigning a complex number\nz &lt;- 2 + 3i\n\n# Displaying the type of data\ntypeof(z)  # Output: \"complex\""
  },
  {
    "objectID": "01-introduction/01-introduction.html#raw",
    "href": "01-introduction/01-introduction.html#raw",
    "title": "1. Practical Introduction to R",
    "section": "5.6 Raw",
    "text": "5.6 Raw\nRaw data represents bytes. This is an advanced data type, generally not required for business applications.\n# Creating raw data\nr &lt;- charToRaw(\"ABC\")\n\n# Displaying the type of data\ntypeof(r)  # Output: \"raw\""
  },
  {
    "objectID": "01-introduction/01-introduction.html#vectors",
    "href": "01-introduction/01-introduction.html#vectors",
    "title": "1. Practical Introduction to R",
    "section": "7.1 Vectors",
    "text": "7.1 Vectors\nVectors are one of the most fundamental data structures in R, designed to store a sequence of elements of the same type (e.g., numeric, character, logical). They are extensively used in R for data manipulation, analysis, and computations due to their simplicity and efficiency. A vector can be created using the c() function, which combines individual elements into a single structure. For example, c(1, 2, 3) creates a numeric vector containing three elements. R performs operations on vectors element-wise, making it easy to perform tasks such as arithmetic, logical comparisons, and indexing. Vectors serve as building blocks for more complex data structures like matrices, lists, and data frames, making them indispensable in R programming for both basic and advanced applications.\n# Numeric vector\nprices &lt;- c(100.5, 200.75, 300.25)   # c() is used to create both numeric and character vectors\n\n# Character vector\nproducts &lt;- c(\"Laptop\", \"Tablet\", \"Smartphone\")\n\n# Logical vector\navailable &lt;- c(TRUE, FALSE, TRUE)\n\n# Mixed vectors\nmixed &lt;- c(\"g\",1,3,\"m\")\n\n# Checking the type of a vector\ntypeof(prices)  # Output: \"double\"\ntypeof(mixed)  # Output: \"character\", if there are a mixture of strings and numbers the numbers will be forced to be characters\nWe can easily create vectors with repeating sequences of elements:\nseq_vector1 &lt;- seq(1,4, by=0.5)        # creates a vector going from 1 to 4 in steps of 0.5\nseq_vector2 &lt;- seq(1,4, length.out=10) # creates a vector of evenly spaced numbers from 1 to 4 with lenth 10\nseq_vector3 &lt;- 1:4                     # creates a vector from 1 to 4 in steps of 1\n\nrep_vector1 &lt;- rep(1, times=4)         # repeats the value 1 4 times\nrep_vector2 &lt;- rep(d, times=4)         # repeats the vector d 4 times\nrep_vector3 &lt;- rep(d, each=4)          # repeats each value in d 4 times\nWe can also access individual values from each vector using single square brackets.\n# Define vector\nseq_vector1 &lt;- seq(1,4, by=0.5)\n\nseq_vector1[2]  # Output: \"1.5\"\nseq_vector1[3]  # Output: \"2\"\nWe can perform arithmetic operations with two numeric vectors in R, such as a + b, the operation is applied component-wise. This means each element in vector d is added to the corresponding element in vector e. If the vectors are of unequal length, R recycles elements of the shorter vector until it matches the length of the longer vector, with a warning if the lengths are not multiples of each other.\na &lt;- c(1, 2, 3)\nb &lt;- c(4, 5, 6)\na + b  # Output: c(5, 7, 9) (1+4, 2+5, 3+6)\nWhen working with vectors of strings, the paste() function in R is a versatile tool. It is primarily used to concatenate elements of one or more vectors into strings, offering flexibility to combine text data either component-wise or by collapsing all elements into a single string. This makes paste() particularly useful for tasks such as creating descriptive labels, formatting output, or preparing data for presentation.\nKey Arguments:\n\nsep: Specifies the separator to place between concatenated elements. Default is a single space (\" \").\ncollapse: Combines all elements of a single vector into one string, using the specified delimiter. If not provided, each concatenated result remains as a separate string.\n\nWhen you have two or more vectors and want to combine corresponding elements (component-wise concatenation):\n# Example vectors\nproducts &lt;- c(\"Laptop\", \"Tablet\", \"Smartphone\")\nprices &lt;- c(\"1000\", \"500\", \"750\")\n\n# Combine product names and prices\nresult &lt;- paste(products, prices, sep=\" - $\")\nprint(result)  # Output: \"Laptop - $1000\" \"Tablet - $500\" \"Smartphone - $750\"\nWhen you want to combine all elements of a single vector into one string:\n# Example vector\nitems &lt;- c(\"Apple\", \"Banana\", \"Cherry\")\n\n# Collapse all items into a single string\nresult &lt;- paste(items, collapse=\", \")\nprint(result)  # Output: \"Apple, Banana, Cherry\""
  },
  {
    "objectID": "01-introduction/01-introduction.html#matrices",
    "href": "01-introduction/01-introduction.html#matrices",
    "title": "1. Practical Introduction to R",
    "section": "7.2 Matrices",
    "text": "7.2 Matrices\nMatrices in R are two-dimensional data structures that store elements of the same type (e.g., numeric, character, or logical) in a grid format with rows and columns. They are ideal for mathematical computations, linear algebra operations, and organizing data with fixed dimensions. Matrices are created using the matrix() function, where you specify the data, number of rows (nrow), and columns (ncol). Operations like addition, subtraction, or multiplication can be applied element-wise or across rows and columns, and advanced matrix-specific operations (e.g., transposition, matrix multiplication) are supported. Matrices are often used in business applications like modeling financial data, performing statistical analyses, or visualizing multidimensional datasets.\n# Creating a matrix\nsales &lt;- matrix(c(10, 20, 30, 40), nrow = 2, ncol = 2)\n\n# Displaying the matrix\nprint(sales)\n\n# Checking the type\ntypeof(sales)  # Output: \"double\"\nElement-wise multiplication performs operations on corresponding elements of two matrices of the same dimensions.\n# Create two matrices\nA &lt;- matrix(c(1, 2, 3, 4), nrow = 2, ncol = 2)\nB &lt;- matrix(c(5, 6, 7, 8), nrow = 2, ncol = 2)\n\n# Element-wise multiplication\nC &lt;- A * B\nprint(C)\n\n# Output:\n#      [,1] [,2]\n# [1,]    5   21\n# [2,]   12   32\nIn the example above, the vector c(1, 2, 3, 4) is filled column-wise by default into a 2 × 2 matrix. This results in:\nA =\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\nThe expression C &lt;- A * B performs element-wise multiplication, meaning each corresponding element in A and B is multiplied together.\nC =\n     [,1] [,2]\n[1,]  1*5  3*7  =&gt;  [1,]   5   21\n[2,]  2*6  4*8  =&gt;  [2,]  12   32\nYou can also apply operations across rows or columns using functions like apply() or colSums()/rowSums().\n# Create a matrix\nM &lt;- matrix(c(1, 2, 3, 4, 5, 6), nrow = 2, ncol = 3)\n\n# Sum across rows\nrow_totals &lt;- rowSums(M)\nprint(row_totals)\n# Output: [1] 9 12\n\n# Sum across columns\ncol_totals &lt;- colSums(M)\nprint(col_totals)\n# Output: [1]  3  7 11\nTransposition swaps rows and columns of a matrix. Use the t() function for this operation.\n# Transpose a matrix\nM &lt;- matrix(c(1, 2, 3, 4), nrow = 2, ncol = 2)\nprint(M)\n\n# Output:\n#      [,1] [,2]\n# [1,]    1    3\n# [2,]    2    4\n\ntransposed &lt;- t(M)\nprint(transposed)\n\n# Output:\n#      [,1] [,2]\n# [1,]    1    2\n# [2,]    3    4\nMatrix multiplication (dot product) is performed using the %*% operator. This is different from element-wise multiplication and follows the rules of linear algebra.\n# Create two matrices\nA &lt;- matrix(c(1, 2, 3, 4), nrow = 2, ncol = 2)\nB &lt;- matrix(c(5, 6, 7, 8), nrow = 2, ncol = 2)\n\n# Matrix multiplication\nC &lt;- A %*% B\nprint(C)\n\n# Output:\n#      [,1] [,2]\n# [1,]   23   31\n# [2,]   34   46\nThere are further advanced operations, including the determinant of a square matrix, which can be calculated using det().\ndet_A &lt;- det(A)\nprint(det_A)\n# Output: -2 (for the given matrix A)\nThe inverse of a square matrix (if it exists) can be calculated using solve().\n# Inverse of a matrix\ninverse_A &lt;- solve(A)\nprint(inverse_A)\n# Output:\n#      [,1] [,2]\n# [1,]   -2  1.5\n# [2,]    1 -0.5\nEigenvalues and eigenvectors can be calculated using the eigen() function.\neigen_A &lt;- eigen(A)\nprint(eigen_A$values)  # Eigenvalues\nprint(eigen_A$vectors) # Eigenvectors"
  },
  {
    "objectID": "01-introduction/01-introduction.html#lists",
    "href": "01-introduction/01-introduction.html#lists",
    "title": "1. Practical Introduction to R",
    "section": "7.3 Lists",
    "text": "7.3 Lists\nLists in R are highly versatile data structures that can store elements of different types, such as vectors, matrices, data frames, and even other lists. This flexibility makes lists ideal for organizing and managing complex data, such as combining related datasets or storing model outputs. Lists are created using the list() function, where each element can be named for easy reference. They are particularly useful in business analytics for grouping data with varied structures, such as customer demographics, sales figures, and statistical results. Accessing elements in a list is done using $ (by name) or double square brackets [[ ]] (by index). Lists are widely used in R for functions that return multiple results, such as regression models or simulation outputs, providing a structured yet flexible way to handle diverse data.\n# Creating a list\nemployee &lt;- list(name = \"John Doe\", age = 30L, salary = 55000.75, active = TRUE)\n\n# Accessing elements\nemployee$name  # Output: \"John Doe\""
  },
  {
    "objectID": "01-introduction/01-introduction.html#data-frames",
    "href": "01-introduction/01-introduction.html#data-frames",
    "title": "1. Practical Introduction to R",
    "section": "7.4 Data Frames",
    "text": "7.4 Data Frames\nData frames in R are one of the most widely used data structures for storing and analyzing tabular data. They organize data into rows and columns, where each column can have a different data type (e.g., numeric, character, or logical), making them ideal for real-world datasets like business transactions or survey results. Data frames are created using the data.frame() function or imported from external files like CSVs or Excel sheets. They support powerful indexing and manipulation capabilities, allowing users to filter, summarize, and transform data efficiently. Data frames are fundamental for business analytics and statistical modeling, providing a structured and intuitive way to handle datasets in R.\n# Creating a data frame\ndf &lt;- data.frame(\n  Product = c(\"Laptop\", \"Tablet\", \"Smartphone\"),\n  Price = c(1000, 500, 750),\n  InStock = c(TRUE, TRUE, FALSE)\n)\n\n# Displaying the data frame\nprint(df)"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-3-create-the-data-frame",
    "href": "lab-uofg-01/lab-uofg-01.html#step-3-create-the-data-frame",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.3 Step 3: Create the Data Frame",
    "text": "2.3 Step 3: Create the Data Frame\nWe now combine the variables that we created in the previous step into a data.frame.\n\n# Combine into a data frame\nsurvey_data &lt;- data.frame(\n  ID = id,\n  AgeBand = age_bands,\n  Gender = gender\n)\n\nYou can easily explore and check the basic structure of your data and get a summary:\n\n# View the first few rows using head()\nhead(survey_data)\n\n  ID AgeBand Gender\n1  1     &lt;21   Male\n2  2   31-40 Female\n3  3   21-30 Female\n4  4   41-50   Male\n5  5   21-30   Male\n6  6     &gt;50   Male\n\n# Examine the structure\nstr(survey_data)\n\n'data.frame':   30 obs. of  3 variables:\n $ ID     : int  1 2 3 4 5 6 7 8 9 10 ...\n $ AgeBand: Factor w/ 6 levels \"&lt;21\",\"21-30\",..: 1 3 2 4 2 5 5 2 3 1 ...\n $ Gender : Factor w/ 4 levels \"Male\",\"Female\",..: 1 2 2 1 1 1 2 2 2 1 ...\n\n# Get basic summary statistics\nsummary(survey_data)\n\n       ID           AgeBand                Gender  \n Min.   : 1.00   &lt;21    :5   Male             :14  \n 1st Qu.: 8.25   21-30  :9   Female           :12  \n Median :15.50   31-40  :5   Other            : 1  \n Mean   :15.50   41-50  :5   Prefer not to say: 2  \n 3rd Qu.:22.75   &gt;50    :5   NA's             : 1  \n Max.   :30.00   Invalid:1"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-4-frequency-tables",
    "href": "lab-uofg-01/lab-uofg-01.html#step-4-frequency-tables",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.4 Step 4: Frequency Tables",
    "text": "2.4 Step 4: Frequency Tables\nCreate frequency tables using base R functions:\n\n# Age Band frequencies\nage_freq &lt;- table(survey_data$AgeBand)\nage_prop &lt;- prop.table(age_freq) * 100\n\n# Combine frequencies and percentages\nage_summary &lt;- cbind(\n  Frequency = age_freq,\n  Percentage = round(age_prop, 1)\n)\n\n# Display the results\nprint(\"Age Band Distribution:\")\n\n[1] \"Age Band Distribution:\"\n\nprint(age_summary)\n\n        Frequency Percentage\n&lt;21             5       16.7\n21-30           9       30.0\n31-40           5       16.7\n41-50           5       16.7\n&gt;50             5       16.7\nInvalid         1        3.3\n\n\n\n# Gender frequencies\ngender_freq &lt;- table(survey_data$Gender)\ngender_prop &lt;- prop.table(gender_freq) * 100\n\n# Combine frequencies and percentages\ngender_summary &lt;- cbind(\n  Frequency = gender_freq,\n  Percentage = round(gender_prop, 1)\n)\n\n# Display the results\nprint(\"Gender Distribution:\")\n\n[1] \"Gender Distribution:\"\n\nprint(gender_summary)\n\n                  Frequency Percentage\nMale                     14       48.3\nFemale                   12       41.4\nOther                     1        3.4\nPrefer not to say         2        6.9"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-5-cross-tabulation",
    "href": "lab-uofg-01/lab-uofg-01.html#step-5-cross-tabulation",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.5 Step 5: Cross-Tabulation",
    "text": "2.5 Step 5: Cross-Tabulation\nCreate a cross-tabulation using base R:\n\n# Create cross-tabulation\ncross_tab &lt;- table(survey_data$AgeBand, survey_data$Gender)\n\n# Add row and column totals\ncross_tab_with_totals &lt;- addmargins(cross_tab)\n\n# Display the results\nprint(\"Age Band by Gender Cross-Tabulation:\")\n\n[1] \"Age Band by Gender Cross-Tabulation:\"\n\nprint(cross_tab_with_totals)\n\n         \n          Male Female Other Prefer not to say Sum\n  &lt;21        3      1     0                 0   4\n  21-30      5      4     0                 0   9\n  31-40      1      2     1                 1   5\n  41-50      4      0     0                 1   5\n  &gt;50        1      4     0                 0   5\n  Invalid    0      1     0                 0   1\n  Sum       14     12     1                 2  29\n\n# Calculate percentages (optional)\nprop_table &lt;- round(prop.table(cross_tab) * 100, 1)\nprint(\"\\nPercentage Distribution:\")\n\n[1] \"\\nPercentage Distribution:\"\n\nprint(prop_table)\n\n         \n          Male Female Other Prefer not to say\n  &lt;21     10.3    3.4   0.0               0.0\n  21-30   17.2   13.8   0.0               0.0\n  31-40    3.4    6.9   3.4               3.4\n  41-50   13.8    0.0   0.0               3.4\n  &gt;50      3.4   13.8   0.0               0.0\n  Invalid  0.0    3.4   0.0               0.0"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a1-setup",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a1-setup",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.1 Step A1: Setup",
    "text": "2.1 Step A1: Setup\nBefore starting any work in R, it is important to organize your files. This ensures that your scripts, datasets, and outputs are easy to manage and reproducible. Projects are strongly recommended for better organization and reproducibility, but setting a working directory is an alternative if needed (see also the respective section in 0. Getting Started).\n\n\n\n\n\n\nNote\n\n\n\nYou can either work through the following steps and copy/paste the respective code into the Lab_Exercise_A.R file that you will create in Step 1 or download the R script for Exercise A and follow the instructions below and save the downloaded file in the scripts folder that you will create.\n\n\n\n2.1.1 Option 1: Create a Project\nThe best way to organize your work is to create an RStudio project. This keeps all related files in a single folder. Follow these steps:\n\nOpen RStudio.\nGo to File &gt; New Project.\nSelect New Directory and then New Project.\nChoose a location on your computer and give the project a name, e.g., ResearchMethodsLab. Avoid spaces in folder and file names.\nClick Create Project. RStudio will open a new session within the project folder.\nIt is good practice to not have you files in this main folder, but create a set of subfolders similar to the following. Navigate to your project folder and create the following subfolders:\n\nResearchMethodsLab/\n├── data/\n├── scripts/\n├── output/\n│   ├── figures/\n│   └── tables/\n├── docs/\n└── ResearchMethodsLab.Rproj\n\nCreate a new R script: Go to File &gt; New File &gt; R Script.\nSave the script in your scripts folder with an appropriate name, e.g., Lab1_Exercise_A.R.\n\nNow you are ready to begin your work in R and continue with Step A2!\n\n\n2.1.2 Option 2: Set Working Directory Manually\nIf you are not using a project, you will need to set a working directory manually. The working directory is the folder where R looks for files and saves outputs.\n\nIn your Finder (Mac) or Explorer (Windows), create a new folder for the R Labs (e.g., ResearchMethodsLab) as well as the subfolder structure below. Avoid spaces in folder and file names.\n\nResearchMethodsLab/\n├── data/\n├── scripts/\n├── output/\n│   ├── figures/\n│   └── tables/\n└── docs/\n\nOpen RStudio.\nCreate a new R script: Go to File &gt; New File &gt; R Script.\nSave the script in the scripts folder that you previously created with an appropriate name, e.g., Lab_Exercise_A.R.\nSet the working directory in your script using the setwd() function. Copy the following code into your script, change the path to the older that you created, and execute the script.\n\nsetwd(\"path/to/your/folder\")\nYou can check whether the working directory is set to the folder that you want to by using the following code:\n# Display the current working directory\ngetwd()\nNow you are ready to begin your work in R and continue with Step A2!"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a2-creating-variables",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a2-creating-variables",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.2 Step A2: Creating Variables",
    "text": "2.2 Step A2: Creating Variables\nIn base R, we will create our vectors and combine them into a data frame. Use the following code to create your variables:\n# Create vectors for our data\nid &lt;- 1:30\n\n# Create age bands with labels\nage_bands &lt;- factor(\n  c(1,3,2,4,2,5,5,2,3,1,4,1,3,2,4,2,5,5,2,3,1,4,2,4,2,5,5,2,3,1),\n  levels = 1:5,\n  labels = c(\"&lt;21\", \"21-30\", \"31-40\", \"41-50\", \"&gt;50\")\n)\n\n# Create gender categories with labels\ngender &lt;- factor(\n  c(0,1,1,0,0,0,1,1,1,0,9,0,2,1,0,0,1,1,0,0,1,0,0,0,1,1,1,0,9,9),\n  levels = c(0,1,2,9),\n  labels = c(\"Male\", \"Female\", \"Other\", \"Prefer not to say\")\n)\n\n\n\n\n\n\nNote\n\n\n\nIn R, we use factor() to create categorical variables. This is similar to value labels in SPSS. The levels argument specifies the underlying codes, while labels provides the human-readable labels."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a3-create-the-data-frame",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a3-create-the-data-frame",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.3 Step A3: Create the Data Frame",
    "text": "2.3 Step A3: Create the Data Frame\nWe now combine the variables that we created in the previous step into a data.frame.\n# Combine into a data frame\nsurvey_data &lt;- data.frame(\n  ID = id,\n  AgeBand = age_bands,\n  Gender = gender\n)\nYou can easily explore and check the basic structure of your data and get a summary:\n# View the first few rows using head()\nhead(survey_data)\n\n# Examine the structure\nstr(survey_data)\n\n# Get basic summary statistics\nsummary(survey_data)\n\n2.3.1 Option 2: Load and Modify your Dataset\nAlternatively, you can download the dataset."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a4-frequency-tables",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a4-frequency-tables",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.4 Step A4: Frequency Tables",
    "text": "2.4 Step A4: Frequency Tables\nCreate frequency tables using base R functions:\n# Age Band frequencies\nage_freq &lt;- table(survey_data$AgeBand)\nage_prop &lt;- prop.table(age_freq) * 100\n\n# Combine frequencies and percentages\nage_summary &lt;- cbind(\n  Frequency = age_freq,\n  Percentage = round(age_prop, 1)\n)\n\n# Display the results\nprint(\"Age Band Distribution:\")\nprint(age_summary)\n# Gender frequencies\ngender_freq &lt;- table(survey_data$Gender)\ngender_prop &lt;- prop.table(gender_freq) * 100\n\n# Combine frequencies and percentages\ngender_summary &lt;- cbind(\n  Frequency = gender_freq,\n  Percentage = round(gender_prop, 1)\n)\n\n# Display the results\nprint(\"Gender Distribution:\")\nprint(gender_summary)"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a5-cross-tabulation",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a5-cross-tabulation",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.5 Step A5: Cross-Tabulation",
    "text": "2.5 Step A5: Cross-Tabulation\nCross-tabulations, also known as contingency tables, are a powerful tool in data analysis for examining the relationship between two or more categorical variables. They provide a matrix of frequency counts that show how categories of one variable are distributed across categories of another. Cross-tabulations are widely used in business analytics, such as comparing demographics (e.g., age and gender) or tracking customer behavior across segments.\nThis guide delves deeper into cross-tabulations using the survey_data data frame, illustrating how to create, interpret, and enhance these tables with additional insights.\n\n2.5.1 When and Why to Use Cross Tabulations\nCross-tabulations are particularly useful when:\n\nYou want to compare distributions of one variable across levels of another.\nYou need to detect patterns or relationships between categorical variables.\nYou aim to summarize multivariate data for clear communication and decision-making.\nYou are preparing data for visualization (e.g., stacked bar charts or heatmaps).\n\nFor example, in a survey analysis, you might want to compare how age groups are distributed by gender.\n\n\n2.5.2 Creating a Cross Tabulation\nIn R, the table() function is used to create cross-tabulations. For example, to examine the distribution of participants by AgeBand and Gender:\n# Create a cross-tabulation of AgeBand and Gender\nage_gender_table &lt;- table(survey_data$AgeBand, survey_data$Gender)\nprint(age_gender_table)\nThe resulting table displays the frequency counts for each combination of AgeBand and Gender. For instance:\n\nThe value at the intersection of &lt;21 and Male represents the number of participants who are under 21 and identify as male.\nThe totals for each row or column provide marginal counts (see Marginal Totals below).\n\n\n\n2.5.3 Adding Proportions to Cross Tabulations\nFrequency counts can be converted to proportions to better understand relative distributions. The prop.table() function is used for this purpose.\nProportions for the Entire Table\n# Proportions for the entire table\nage_gender_prop &lt;- prop.table(age_gender_table)\nprint(round(age_gender_prop * 100, 2))\nHere, each value represents the percentage of the total participants in that specific category combination.\nRow-Wise Proportions\nTo see proportions within each row (e.g., the percentage of each gender within an age band):\n# Row-wise proportions\nrow_prop &lt;- prop.table(age_gender_table, margin = 1)\nprint(round(row_prop * 100, 2))\nThis output helps answer questions like, “What percentage of individuals in the 31-40 age group identify as Female?”\nColumn-Wise Proportions\nTo see proportions within each column (e.g., the percentage of each age band within a gender):\n# Column-wise proportions\ncol_prop &lt;- prop.table(age_gender_table, margin = 2)\nprint(round(col_prop * 100, 2))\nThis output helps answer questions like, “What percentage of individuals identifying as Male are in the 41-50 age band?”\n\n\n2.5.4 Marginal Totals\nAdding row and column totals to a cross-tabulation provides a comprehensive overview of the data. Use the addmargins() function to include these totals:\n# Add row and column totals to the table\nage_gender_with_totals &lt;- addmargins(age_gender_table)\nprint(age_gender_with_totals)\nThe row totals show the distribution of participants across age bands, while the column totals display the distribution across gender categories.\n\n\n2.5.5 Customizing Cross Tabulation Output\nFor clearer interpretation, you can customize the table’s appearance using descriptive labels for rows and columns. Use dimnames() to update labels:\n# Customize row and column names\ndimnames(age_gender_table) &lt;- list(\n  AgeGroup = levels(survey_data$AgeBand),\n  GenderCategory = levels(survey_data$Gender)\n)\nprint(age_gender_table)\n\n\n2.5.6 Detecting Relationships in Cross Tabulations\nCross-tabulations provide a foundation for detecting relationships between variables. While frequency counts and proportions are descriptive, statistical tests such as the Chi-Square Test can quantify the association between variables.\n# Perform a Chi-Square Test of Independence\nchi_test &lt;- chisq.test(age_gender_table)\nprint(chi_test)\nThe test evaluates whether there is a significant association between AgeBand and Gender. A p-value less than 0.05 suggests that the relationship is statistically significant.\nNote: R might show a warning Chi-squared approximation may be incorrect, which indicates that the conditions for the Chi-Square test’s validity may not be fully met. Specifically, the test assumes that expected frequencies in each cell of the contingency table are sufficiently large. Typically, the rule of thumb is that each expected cell frequency should be at least 5. You can check the expected frequencies by using the expected attribute of the test result:\n# View the expected frequencies\nchi_test$expected\n\n\n2.5.7 Summary\nCross-tabulations are a versatile tool for analyzing the relationship between categorical variables. Mastering cross-tabulations equips you with the ability to summarize and interpret categorical data effectively, a crucial skill in business research and data analysis. In R, you can:\n\nUse table() to create cross-tabulations.\nAdd proportions with prop.table() for a deeper understanding of relative distributions.\nInclude totals with addmargins() for a complete summary.\nCustomize, export, or extend your analysis with statistical tests."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a6-loading-and-viewing-data",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a6-loading-and-viewing-data",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.6 Step A6: Loading and Viewing Data",
    "text": "2.6 Step A6: Loading and Viewing Data"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a7-exploring-value-labels",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a7-exploring-value-labels",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.7 Step A7: Exploring Value Labels",
    "text": "2.7 Step A7: Exploring Value Labels"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a8-basic-exploration-with-summary-statistics",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a8-basic-exploration-with-summary-statistics",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.8 Step A8: Basic Exploration with Summary Statistics",
    "text": "2.8 Step A8: Basic Exploration with Summary Statistics"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a9-correcting-errors",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a9-correcting-errors",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.9 Step A9: Correcting Errors",
    "text": "2.9 Step A9: Correcting Errors"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a10-descriptive-statistics",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a10-descriptive-statistics",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.10 Step A10: Descriptive Statistics",
    "text": "2.10 Step A10: Descriptive Statistics"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a11-setting-variable-types",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a11-setting-variable-types",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.11 Step A11: Setting Variable Types",
    "text": "2.11 Step A11: Setting Variable Types"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a12-cross-tabulations",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a12-cross-tabulations",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.12 Step A12: Cross-tabulations",
    "text": "2.12 Step A12: Cross-tabulations"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-1",
    "href": "lab-uofg-01/lab-uofg-01.html#step-1",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "3.1 Step 1:",
    "text": "3.1 Step 1:"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a2-creating-or-loading-the-dataset",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a2-creating-or-loading-the-dataset",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.2 Step A2: Creating or Loading the Dataset",
    "text": "2.2 Step A2: Creating or Loading the Dataset\nFor practice purposes, try both options so you familiarise yourself with creating and loading datasets in R.\n\n2.2.1 Option 1: Create your Dataset\nIn base R, we will create our vectors and combine them into a data frame. Use the following code to create your variables:\n# Create vectors for our data\nid &lt;- 1:30\n\n# Create age bands with labels\nage_bands &lt;- factor(\n  c(1,3,2,4,2,5,5,2,3,1,4,1,3,2,4,2,5,5,2,3,1,4,2,4,2,5,5,2,3,1),\n  levels = 1:5,\n  labels = c(\"&lt;21\", \"21-30\", \"31-40\", \"41-50\", \"&gt;50\")\n)\n\n# Create gender categories with labels\ngender &lt;- factor(\n  c(0,1,1,0,0,0,1,1,1,0,9,0,2,1,0,0,1,1,0,0,1,0,0,0,1,1,1,0,9,9),\n  levels = c(0,1,2,9),\n  labels = c(\"Male\", \"Female\", \"Other\", \"Prefer not to say\")\n)\n\n\n\n\n\n\nNote\n\n\n\nIn R, we use factor() to create categorical variables. This is similar to value labels in SPSS. The levels argument specifies the underlying codes, while labels provides the human-readable labels.\n\n\nWe now combine the variables that we created in the previous step into a data.frame.\n# Combine into a data frame\nsurvey_data &lt;- data.frame(\n  ID = id,\n  AgeBand = age_bands,\n  Gender = gender\n)\nYou can easily explore and check the basic structure of your data and get a summary:\n# View the first few rows using head()\nhead(survey_data)\n\n# Examine the structure\nstr(survey_data)\n\n# Get basic summary statistics\nsummary(survey_data)\nWhen working with data in R, saving and reloading data efficiently is crucial for reproducibility and sharing. Two common file formats for saving data in R are .csv files and .rds files. While both serve the purpose of persisting data for future use, they have distinct differences in terms of structure, use cases, and functionality.\nYou can use the following code to save your dataset in either format. In line with the best practice around folder structures, the code below works only if you created the data folder within your project folder or working directory. For this tutorial, save your output as a .csv file (without row names).\n# Save as R data file\nsaveRDS(survey_data, \"data/survey_data_export.rds\")\n\n# Save as .csv\nwrite.csv(survey_data, \"data/survey_data_export_rows.csv\")\n\n# By default, the data is exported with row names. Now to export data without row names we simply have to pass row.names=FALSE as an argument in the write.csv() function.\nwrite.csv(survey_data, \"data/survey_data_export.csv\", row.names=FALSE)\nA .csv file (comma-separated values) is a plain text format commonly used for storing tabular data. Each row in the file corresponds to a row in the dataset, and columns are separated by commas. In general, .csv files are platform-independent, widely supported by software like Excel, and easily shared or imported into other programming environments.\nAn .rds file is a native R binary format used to store a single R object. Unlike .csv, .rds files preserve all attributes and data types, including factors, column classes, and even more complex structures like lists, models, or custom objects. The table below outlines the main differences between saving a data frame in each format.\n\n\n\nKey differences between .csv and .rds diles\n\n\nFeature\nCSV\nRDS\n\n\n\n\nFormat\nPlain text\nBinary (R-specific)\n\n\nPortability\nCross-platform and software-independent\nR-specific\n\n\nMetadata\nDoes not retain R-specific attributes\nRetains all R-specific attributes\n\n\nComplex objects\nSupports tabular data only\nSupports any R object\n\n\nHuman-readable\nYes\nNo\n\n\nEfficiency\nSlower for large datasets\nFaster and more compact\n\n\nUse case\nSharing data with non-R users or if the data will be processed in other tools like Excel or Python\nStoring and reloading your data with all its R-specific features, particularly suitable for storing large datasets or complex objects that need to be efficiently loaded\n\n\n\n\n\n\n\n\n\n2.2.2 Option 2: Load your Dataset\nAs an alternative to creating your own dataset, you can download the dataset. Copy this file into your data folder and then run the following code:\n# Load the CSV file stored in the \"data\" folder\nsurvey_data &lt;- read.csv(\"data/lab1-exercise-a.csv\")\nYou can easily explore and check the basic structure of your data and get a summary:\n# View the first few rows using head()\nhead(survey_data)\n\n# Examine the structure\nstr(survey_data)\n\n# Get basic summary statistics\nsummary(survey_data)\nThe imported dataset contain only the numerical values. We will use factor() again transform this into categorical variables with levels specifying the underlying codes and labels providing the human-readable labels.\n# Assign labels for \"AgeBand\"\nsurvey_data$AgeBand &lt;- factor(\n  survey_data$AgeBand,\n  levels = c(1, 2, 3, 4, 5),\n  labels = c(\"&lt;21\", \"21-30\", \"31-40\", \"41-50\", \"&gt;50\")\n)\n\n# Assign labels for \"Gender\"\nsurvey_data$Gender &lt;- factor(\n  survey_data$Gender,\n  levels = c(0,1,2,9),\n  labels = c(\"Male\", \"Female\", \"Other\", \"Prefer not to say\")\n)"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a3-frequency-tables-basic-exploration-with-summary-statistics",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a3-frequency-tables-basic-exploration-with-summary-statistics",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.4 Step A3: Frequency Tables (Basic Exploration with Summary Statistics)",
    "text": "2.4 Step A3: Frequency Tables (Basic Exploration with Summary Statistics)\nCreate frequency tables using base R functions:\n# Age Band frequencies\nage_freq &lt;- table(survey_data$AgeBand)\nage_prop &lt;- prop.table(age_freq) * 100\n\n# Combine frequencies and percentages\nage_summary &lt;- cbind(\n  Frequency = age_freq,\n  Percentage = round(age_prop, 1)\n)\n\n# Display the results\nprint(\"Age Band Distribution:\")\nprint(age_summary)\n# Gender frequencies\ngender_freq &lt;- table(survey_data$Gender)\ngender_prop &lt;- prop.table(gender_freq) * 100\n\n# Combine frequencies and percentages\ngender_summary &lt;- cbind(\n  Frequency = gender_freq,\n  Percentage = round(gender_prop, 1)\n)\n\n# Display the results\nprint(\"Gender Distribution:\")\nprint(gender_summary)"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a4-cross-tabulation",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a4-cross-tabulation",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.5 Step A4: Cross-Tabulation",
    "text": "2.5 Step A4: Cross-Tabulation\nCross-tabulations, also known as contingency tables, are a powerful tool in data analysis for examining the relationship between two or more categorical variables. They provide a matrix of frequency counts that show how categories of one variable are distributed across categories of another. Cross-tabulations are widely used in business analytics, such as comparing demographics (e.g., age and gender) or tracking customer behavior across segments.\nThis guide delves deeper into cross-tabulations using the survey_data data frame, illustrating how to create, interpret, and enhance these tables with additional insights.\n\n2.5.1 When and Why to Use Cross Tabulations\nCross-tabulations are particularly useful when:\n\nYou want to compare distributions of one variable across levels of another.\nYou need to detect patterns or relationships between categorical variables.\nYou aim to summarize multivariate data for clear communication and decision-making.\nYou are preparing data for visualization (e.g., stacked bar charts or heatmaps).\n\nFor example, in a survey analysis, you might want to compare how age groups are distributed by gender.\n\n\n2.5.2 Creating a Cross Tabulation\nIn R, the table() function is used to create cross-tabulations. For example, to examine the distribution of participants by AgeBand and Gender:\n# Create a cross-tabulation of AgeBand and Gender\nage_gender_table &lt;- table(survey_data$AgeBand, survey_data$Gender)\nprint(age_gender_table)\nThe resulting table displays the frequency counts for each combination of AgeBand and Gender. For instance:\n\nThe value at the intersection of &lt;21 and Male represents the number of participants who are under 21 and identify as male.\nThe totals for each row or column provide marginal counts (see Marginal Totals below).\n\n\n\n2.5.3 Adding Proportions to Cross Tabulations\nFrequency counts can be converted to proportions to better understand relative distributions. The prop.table() function is used for this purpose.\nProportions for the Entire Table\n# Proportions for the entire table\nage_gender_prop &lt;- prop.table(age_gender_table)\nprint(round(age_gender_prop * 100, 2))\nHere, each value represents the percentage of the total participants in that specific category combination.\nRow-Wise Proportions\nTo see proportions within each row (e.g., the percentage of each gender within an age band):\n# Row-wise proportions\nrow_prop &lt;- prop.table(age_gender_table, margin = 1)\nprint(round(row_prop * 100, 2))\nThis output helps answer questions like, “What percentage of individuals in the 31-40 age group identify as Female?”\nColumn-Wise Proportions\nTo see proportions within each column (e.g., the percentage of each age band within a gender):\n# Column-wise proportions\ncol_prop &lt;- prop.table(age_gender_table, margin = 2)\nprint(round(col_prop * 100, 2))\nThis output helps answer questions like, “What percentage of individuals identifying as Male are in the 41-50 age band?”\n\n\n2.5.4 Marginal Totals\nAdding row and column totals to a cross-tabulation provides a comprehensive overview of the data. Use the addmargins() function to include these totals:\n# Add row and column totals to the table\nage_gender_with_totals &lt;- addmargins(age_gender_table)\nprint(age_gender_with_totals)\nThe row totals show the distribution of participants across age bands, while the column totals display the distribution across gender categories.\n\n\n2.5.5 Customizing Cross Tabulation Output\nFor clearer interpretation, you can customize the table’s appearance using descriptive labels for rows and columns. Use dimnames() to update labels:\n# Customize row and column names\ndimnames(age_gender_table) &lt;- list(\n  AgeGroup = levels(survey_data$AgeBand),\n  GenderCategory = levels(survey_data$Gender)\n)\nprint(age_gender_table)\n\n\n2.5.6 Detecting Relationships in Cross Tabulations\nCross-tabulations provide a foundation for detecting relationships between variables. While frequency counts and proportions are descriptive, statistical tests such as the Chi-Square Test can quantify the association between variables.\n# Perform a Chi-Square Test of Independence\nchi_test &lt;- chisq.test(age_gender_table)\nprint(chi_test)\nThe test evaluates whether there is a significant association between AgeBand and Gender. A p-value less than 0.05 suggests that the relationship is statistically significant.\n\n\n2.5.7 Summary\nCross-tabulations are a versatile tool for analyzing the relationship between categorical variables. Mastering cross-tabulations equips you with the ability to summarize and interpret categorical data effectively, a crucial skill in business research and data analysis. In R, you can:\n\nUse table() to create cross-tabulations.\nAdd proportions with prop.table() for a deeper understanding of relative distributions.\nInclude totals with addmargins() for a complete summary.\nCustomize, export, or extend your analysis with statistical tests."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a5-saving-your-work",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a5-saving-your-work",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.6 Step A5: Saving your Work",
    "text": "2.6 Step A5: Saving your Work"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-b1-setup",
    "href": "lab-uofg-01/lab-uofg-01.html#step-b1-setup",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "3.1 Step B1: Setup",
    "text": "3.1 Step B1: Setup\nYou can continue working with the same project or working directory (depending on which option you chose in Step A1). To get started with this exercise, please do the following:\n\nPlease download the dataset and save it in the data folder within your project folder or working directory.\nCreate a new R script: Go to File &gt; New File &gt; R Script.\nSave the script in the scripts folder within your project folder or working directory with an appropriate name, e.g., Lab1_Exercise_B_C.R. (Note: For simplicity, we combine Exercises B and C into one script as they are based on the same data, but you can also create separate scripts for each exercise.)\n\n\n\n\n\n\n\nNote\n\n\n\nYou can either work through the following steps and copy/paste the respective code into the Lab_Exercise_B_C.R file that you created or download the R script for Exercises B and C, save the downloaded file in the scripts folder, and run the respective code snippets according to the instructions below."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-b2",
    "href": "lab-uofg-01/lab-uofg-01.html#step-b2",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "3.2 Step B2:",
    "text": "3.2 Step B2:"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a3-modifying-your-dataset",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a3-modifying-your-dataset",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.3 Step A3: Modifying your Dataset",
    "text": "2.3 Step A3: Modifying your Dataset\n\n\n\n\n\n\nNote\n\n\n\nThis step is not needed, the dataset that you created with the code (Step A2, option 1) or downloaded (Step A2, option 2) are already correct, but have a look and get an overview of what you can do with R.\nWe create a copy of the data frame that we use for the remainder of the lab. Please run the following code before experimenting with possible modifications:\nsurvey_data_copy &lt;- survey_data\n\n\nData frames are among the most commonly used data structures in R, especially for storing and analyzing tabular data. Once a data frame is loaded or created, it is often necessary to modify it to suit specific analytical needs. Common modifications include editing specific values, adding or removing columns and rows, and renaming variables. These operations can be performed efficiently using base R, without the need for additional packages. Understanding these basic techniques is essential for working effectively with data in R.\n\n2.3.1 Editing Specific Values\nYou can directly access and modify specific elements of a data frame using indexing with square brackets [ , ]. The format is data[row, column], where you specify the row and column to edit. You can also use column names for clarity.\n# Edit the Gender of the participant with ID 15\nsurvey_data_copy[survey_data_copy$ID == 15, \"Gender\"] &lt;- \"Female\"\nprint(survey_data_copy[survey_data_copy$ID == 15, ])\nHere, the gender for the participant with ID 15 is updated to “Female.”\n\n\n2.3.2 Adding a Column\nTo add a new column to a data frame, use the $ operator or specify the new column name within square brackets.\n# Add a new column indicating if the participant is above 30 based on AgeBand\nsurvey_data_copy$Above30 &lt;- survey_data_copy$AgeBand %in% c(\"31-40\", \"41-50\", \"&gt;50\")\nprint(head(survey_data_copy))\nThis new column indicates whether each participant belongs to an age group over 30.\n\n\n2.3.3 Adding a Row\nTo append a new row, use the rbind() function, which binds rows together.\n# Add a new participant to the data frame\nnew_row &lt;- data.frame(ID = 31, AgeBand = \"&lt;21\", Gender = \"Other\", Above30 = FALSE)\nsurvey_data_copy &lt;- rbind(survey_data_copy, new_row)\nprint(tail(survey_data_copy))\n\n\n2.3.4 Removing a Column\nYou can remove a column by setting it to NULL or by subsetting the data frame without that column.\n# Remove the \"Above30\" column\nsurvey_data_copy$Above30 &lt;- NULL\nprint(head(survey_data_copy))\n\n\n2.3.5 Removing a Row\nTo remove a row, subset the data frame, excluding the unwanted row.\n# Remove the row where ID is 10\nsurvey_data_copy &lt;- survey_data_copy[survey_data_copy$ID != 10, ]\nprint(head(survey_data_copy))\n\n\n2.3.6 Renaming Columns\nRenaming columns can be done by directly modifying the names() of the data frame.\n# Rename columns\nnames(survey_data_copy) &lt;- c(\"ParticipantID\", \"AgeGroup\", \"GenderIdentity\")\nprint(head(survey_data_copy))\n\n\n2.3.7 Combining Data Frames\nYou can merge two data frames using merge() to combine them based on a common column.\n# Create another data frame with additional information\nadditional_data &lt;- data.frame(\n  ParticipantID = c(1, 2, 3, 4, 5),\n  CompletedSurvey = c(TRUE, TRUE, FALSE, TRUE, FALSE)\n)\n\n# Merge data frames by the \"ParticipantID\" column\nsurvey_data_copy &lt;- merge(survey_data_copy, additional_data, by = \"ParticipantID\", all.x = TRUE)\nprint(head(survey_data_copy))\n\n\n2.3.8 Summary\nThese are some of the most common operations for modifying data frames in base R. Mastering these techniques will allow you to efficiently manipulate data frames and tailor them to your analytical needs:\n\nEdit specific values: Modify elements using data[row, column].\nAdd a column: Use $ or square brackets.\nAdd a row: Use rbind().\nRemove a column: Set it to NULL or subset the data frame.\nRemove a row: Subset the data frame excluding the row.\nRename columns: Modify names() directly.\nCombine data frames: Use merge()."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a4-frequency-tables-basic-exploration-with-summary-statistics",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a4-frequency-tables-basic-exploration-with-summary-statistics",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.4 Step A4: Frequency Tables (Basic Exploration with Summary Statistics)",
    "text": "2.4 Step A4: Frequency Tables (Basic Exploration with Summary Statistics)\nCreate frequency tables using base R functions:\n# Age Band frequencies\nage_freq &lt;- table(survey_data$AgeBand)\nage_prop &lt;- prop.table(age_freq) * 100\n\n# Combine frequencies and percentages\nage_summary &lt;- cbind(\n  Frequency = age_freq,\n  Percentage = round(age_prop, 1)\n)\n\n# Display the results\nprint(\"Age Band Distribution:\")\nprint(age_summary)\n# Gender frequencies\ngender_freq &lt;- table(survey_data$Gender)\ngender_prop &lt;- prop.table(gender_freq) * 100\n\n# Combine frequencies and percentages\ngender_summary &lt;- cbind(\n  Frequency = gender_freq,\n  Percentage = round(gender_prop, 1)\n)\n\n# Display the results\nprint(\"Gender Distribution:\")\nprint(gender_summary)"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a4-frequency-tables-summary-statistics",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a4-frequency-tables-summary-statistics",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.4 Step A4: Frequency Tables (Summary Statistics)",
    "text": "2.4 Step A4: Frequency Tables (Summary Statistics)\nFrequency tables are a fundamental tool in data analysis for summarizing and understanding the distribution of categorical variables. They show how often each category appears in a dataset, helping analysts quickly grasp patterns and trends. In business research, frequency tables are commonly used to analyze survey results, customer demographics, or product categories. In R, base functions like table() and prop.table() provide a straightforward way to create and analyze frequency tables.\nThis guide introduces frequency tables using the survey_data data frame and demonstrates their creation and interpretation.\n\n2.4.1 When and Why to Use Frequency Tables\nFrequency tables are particularly useful when:\n\nYou need to summarize categorical data (e.g., age groups, gender, product categories).\nYou want to identify dominant categories or patterns in responses.\nYou need a quick check for data quality (e.g., missing values or unexpected categories).\nYou are preparing data for visualization or further statistical analysis.\n\nBy condensing raw data into an easy-to-read format, frequency tables simplify decision-making and analysis.\n\n\n2.4.2 Creating a Basic Frequency Table\nThe table() function in R generates frequency counts for one or more variables. For example, to count the number of participants in each age band and for each gender:\n# Frequency table for AgeBand\nage_band_freq &lt;- table(survey_data$AgeBand)\n\n# Frequency table for Gender\ngender_freq &lt;- table(survey_data$Gender)\n\n# Display the results\nprint(\"Frequency table for AgeBand:\")\nprint(age_band_freq)\nprint(\"Frequency table for Gender:\")\nprint(gender_freq)\nThis table displays the count of participants in each age group.\n\n\n2.4.3 Adding Proportions\nProportions show the relative frequency of each category as a percentage of the total. Use the prop.table() function to calculate proportions from a frequency table:\n# Proportions for AgeBand\nage_band_prop &lt;- prop.table(age_band_freq)\nprint(age_band_prop)\nThe output shows the proportion of participants in each age group. To display percentages, multiply by 100:\n# Proportions as percentages\nage_band_percent &lt;- round(prop.table(age_band_freq) * 100, 2)\nprint(age_band_percent)\nThis provides a clear picture of the distribution of age groups as percentages. You can also combine the basic frequency table with the proportions and print the combined results:\n# Frequency table for AgeBand\nage_band_freq &lt;- table(survey_data$AgeBand)\n# Proportions as percentages for AgeBand\nage_band_percent &lt;- round(prop.table(age_band_freq) * 100, 2)\n\n# Combine frequencies and percentages\nage_summary &lt;- cbind(\n  Frequency = age_band_freq,\n  Percentage = age_band_percent\n)\n\n# Display the results\nprint(\"AgeBand Distribution:\")\nprint(age_summary)\n\n\n2.4.4 Summary Statistics for Frequency Tables\nOnce you have created a frequency table, you might want to extract specific insights:\n\nMode: The category with the highest frequency.\nRare categories: Categories with very low frequencies.\n\n# Find the most frequent AgeBand\nmost_frequent_age_band &lt;- names(age_band_freq[which.max(age_band_freq)])\nprint(paste(\"Most frequent age band:\", most_frequent_age_band))\n\n# Identify rare categories (frequency &lt;= 2)\nrare_categories &lt;- names(age_band_freq[age_band_freq &lt;= 2])\nprint(paste(\"Rare categories:\", paste(rare_categories, collapse = \", \")))\n\n\n2.4.5 Handling Missing or Unexpected Values\nFrequency tables are also useful for spotting missing or unexpected values. For instance:\n# Check for missing or unusual values in Gender\ngender_freq &lt;- table(survey_data$Gender, useNA = \"ifany\")\nprint(gender_freq)\nThe useNA argument ensures that missing values (if any) are included in the table."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a5-saving-frequency-tables-and-cross-tabulations",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a5-saving-frequency-tables-and-cross-tabulations",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.6 Step A5: Saving Frequency Tables and Cross-Tabulations",
    "text": "2.6 Step A5: Saving Frequency Tables and Cross-Tabulations\nWhen analyzing data, frequency tables and cross-tabulations provide valuable insights into categorical variables and their relationships. To share or store these tables for reporting or further analysis, you can save them as CSV files or directly export them in a human-readable format. This guide demonstrates both methods, using survey_data for examples.\n\n2.6.1 Saving Frequency Tables\nFrequency tables summarize the distribution of a single categorical variable, and you can save them as a CSV file or export them as plain text.\nSaving as a CSV File\nTo save a frequency table as a CSV file, first convert it into a data frame using as.data.frame():\n# Create a frequency table for AgeBand\nage_band_freq &lt;- table(survey_data$AgeBand)\n\n# Convert the frequency table to a data frame\nage_band_df &lt;- as.data.frame(age_band_freq)\n\n# Save the data frame to a CSV file\nwrite.csv(age_band_df, \"age_band_frequency.csv\", row.names = FALSE)\nThis saves the frequency table as a CSV file named age_band_frequency.csv. Each row in the CSV represents a category and its corresponding frequency.\nExporting to Plain Text\nFor a more human-readable format, you can save the table directly as plain text using capture.output():\n# Export the frequency table to a text file\ncapture.output(age_band_freq, file = \"age_band_frequency.txt\")\nThe output file, age_band_frequency.txt, contains the frequency table as it appears in the R console.\n\n\n2.6.2 Saving Cross-Tabulations\nCross-tabulations summarize relationships between two categorical variables. Saving them involves similar steps to frequency tables, with additional considerations for row and column labels.\nSaving as a CSV File\nLike frequency tables, cross-tabulations can be converted into a data frame for CSV export:\n# Create a cross-tabulation of AgeBand and Gender\nage_gender_table &lt;- table(survey_data$AgeBand, survey_data$Gender)\n\n# Convert the cross-tabulation to a data frame\nage_gender_df &lt;- as.data.frame(age_gender_table)\n\n# Save the cross-tabulation to a CSV file\nwrite.csv(age_gender_df, \"age_gender_cross_tabulation.csv\", row.names = FALSE)\nThis saves the cross-tabulation as a CSV file named age_gender_cross_tabulation.csv. Each row in the CSV represents a unique combination of AgeBand and Gender, along with its frequency.\nExporting to Plain Text\nTo save a formatted version of the cross-tabulation, use capture.output():\n# Export the cross-tabulation to a text file\ncapture.output(age_gender_table, file = \"age_gender_cross_tabulation.txt\")\nThe file age_gender_cross_tabulation.txt will display the table as it appears in the R console, retaining its tabular structure.\nAdding Totals Before Export\nAdding marginal totals to cross-tabulations can make them more informative before saving:\n# Add row and column totals\nage_gender_with_totals &lt;- addmargins(age_gender_table)\n\n# Save the table with totals as plain text\ncapture.output(age_gender_with_totals, file = \"age_gender_with_totals.txt\")\nThis ensures that row and column totals are included in the exported table for comprehensive analysis.\n\n\n2.6.3 Saving Proportions\nProportions provide additional insights and can be saved in the same way as frequency counts. For example:\n# Calculate proportions for AgeBand\nage_band_prop &lt;- prop.table(age_band_freq)\n\n# Convert to a data frame and save as CSV\nage_band_prop_df &lt;- as.data.frame(age_band_prop)\nwrite.csv(age_band_prop_df, \"age_band_proportions.csv\", row.names = FALSE)\nSimilarly, cross-tabulation proportions can be saved:\n# Calculate proportions for the cross-tabulation\nage_gender_prop &lt;- prop.table(age_gender_table)\n\n# Convert to a data frame and save as CSV\nage_gender_prop_df &lt;- as.data.frame(age_gender_prop)\nwrite.csv(age_gender_prop_df, \"age_gender_proportions.csv\", row.names = FALSE)\n\n\n2.6.4 Summary\nTo save frequency tables and cross-tabulations for reporting or analysis:\n\nAs CSV files: Use as.data.frame() and write.csv() to export structured data.\nAs plain text: Use capture.output() for human-readable formats.\nWith proportions: Save proportions using similar methods to enhance insights.\nWith totals: Add marginal totals before exporting for a complete overview.\n\nThese techniques ensure your tables are accessible for external use, whether for sharing with colleagues, integrating into reports, or storing for reproducibility."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-a6-saving-frequency-tables-and-cross-tabulations",
    "href": "lab-uofg-01/lab-uofg-01.html#step-a6-saving-frequency-tables-and-cross-tabulations",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.6 Step A6: Saving Frequency Tables and Cross-Tabulations",
    "text": "2.6 Step A6: Saving Frequency Tables and Cross-Tabulations\nWhen analyzing data, frequency tables and cross-tabulations provide valuable insights into categorical variables and their relationships. To share or store these tables for reporting or further analysis, you can save them as CSV files or directly export them in a human-readable format. This guide demonstrates both methods, using survey_data for examples.\n\n2.6.1 Saving Frequency Tables\nFrequency tables summarize the distribution of a single categorical variable, and you can save them as a CSV file or export them as plain text.\nSaving as a CSV File\nTo save a frequency table as a CSV file, first convert it into a data frame using as.data.frame():\n# Create a frequency table for AgeBand\nage_band_freq &lt;- table(survey_data$AgeBand)\n\n# Convert the frequency table to a data frame\nage_band_df &lt;- as.data.frame(age_band_freq)\n\n# Save the data frame to a CSV file\nwrite.csv(age_band_df, \"output/tables/age_band_frequency.csv\", row.names = FALSE)\nThis saves the frequency table as a CSV file named age_band_frequency.csv. Each row in the CSV represents a category and its corresponding frequency.\nExporting to Plain Text\nFor a more human-readable format, you can save the table directly as plain text using capture.output():\n# Export the frequency table to a text file\ncapture.output(age_band_freq, file = \"output/tables/age_band_frequency.txt\")\nThe output file, age_band_frequency.txt, contains the frequency table as it appears in the R console.\n\n\n2.6.2 Saving Cross-Tabulations\nCross-tabulations summarize relationships between two categorical variables. Saving them involves similar steps to frequency tables, with additional considerations for row and column labels.\nSaving as a CSV File\nLike frequency tables, cross-tabulations can be converted into a data frame for CSV export:\n# Create a cross-tabulation of AgeBand and Gender\nage_gender_table &lt;- table(survey_data$AgeBand, survey_data$Gender)\n\n# Convert the cross-tabulation to a data frame\nage_gender_df &lt;- as.data.frame(age_gender_table)\n\n# Save the cross-tabulation to a CSV file\nwrite.csv(age_gender_df, \"output/tables/age_gender_cross_tabulation.csv\", row.names = FALSE)\nThis saves the cross-tabulation as a CSV file named age_gender_cross_tabulation.csv. Each row in the CSV represents a unique combination of AgeBand and Gender, along with its frequency.\nExporting to Plain Text\nTo save a formatted version of the cross-tabulation, use capture.output():\n# Export the cross-tabulation to a text file\ncapture.output(age_gender_table, file = \"output/tables/age_gender_cross_tabulation.txt\")\nThe file age_gender_cross_tabulation.txt will display the table as it appears in the R console, retaining its tabular structure.\nAdding Totals Before Export\nAdding marginal totals to cross-tabulations can make them more informative before saving:\n# Add row and column totals\nage_gender_with_totals &lt;- addmargins(age_gender_table)\n\n# Save the table with totals as plain text\ncapture.output(age_gender_with_totals, file = \"output/tables/age_gender_with_totals.txt\")\nThis ensures that row and column totals are included in the exported table for comprehensive analysis.\n\n\n2.6.3 Saving Proportions\nProportions provide additional insights and can be saved in the same way as frequency counts. For example:\n# Calculate proportions for AgeBand\nage_band_prop &lt;- prop.table(age_band_freq)\n\n# Convert to a data frame and save as CSV\nage_band_prop_df &lt;- as.data.frame(age_band_prop)\nwrite.csv(age_band_prop_df, \"output/tables/age_band_proportions.csv\", row.names = FALSE)\nSimilarly, cross-tabulation proportions can be saved:\n# Calculate proportions for the cross-tabulation\nage_gender_prop &lt;- prop.table(age_gender_table)\n\n# Convert to a data frame and save as CSV\nage_gender_prop_df &lt;- as.data.frame(age_gender_prop)\nwrite.csv(age_gender_prop_df, \"output/tables/age_gender_proportions.csv\", row.names = FALSE)\n\n\n2.6.4 Summary\nTo save frequency tables and cross-tabulations for reporting or analysis:\n\nAs CSV files: Use as.data.frame() and write.csv() to export structured data.\nAs plain text: Use capture.output() for human-readable formats.\nWith proportions: Save proportions using similar methods to enhance insights.\nWith totals: Add marginal totals before exporting for a complete overview.\n\nThese techniques ensure your tables are accessible for external use, whether for sharing with colleagues, integrating into reports, or storing for reproducibility.\n\n\n\n\n\n\nBeautiful, customizable tables with export options with gt\n\n\n\n\n\nThe gt package is a powerful tool for creating beautiful, publication-quality tables directly in R. It provides an intuitive and flexible workflow for generating summary tables, including frequency tables and cross-tabulations, with advanced formatting options for customization. The gt package is particularly well-suited for reports, presentations, and dashboards.\nCreating and Saving Cross-Tabulation\n# Install package\ninstall.packages(\"gt\")\ninstall.packages(\"dplyr\")\n\n# Load janitor package\nlibrary(gt)\nlibrary(dplyr)\n\n# Create a cross-tabulation\nage_gender_table &lt;- table(survey_data$AgeBand, survey_data$Gender)\n\n# Convert the table to a data frame\nage_gender_df &lt;- as.data.frame(age_gender_table)\n\n# Create a gt table\ngt_table &lt;- gt(data = age_gender_df) %&gt;%\n  tab_header(\n    title = \"Cross-Tabulation of Age Band and Gender\",\n    subtitle = \"Frequency Distribution\"\n  ) %&gt;%\n  cols_label(\n    Var1 = \"Age Band\",\n    Var2 = \"Gender\",\n    Freq = \"Count\"\n  ) %&gt;%\n  fmt_number(\n    columns = c(Freq),\n    decimals = 0\n  ) %&gt;%\n  tab_source_note(\n    source_note = \"Data Source: Survey Data\"\n  )\n\n# Save the table as an HTML file\ngtsave(gt_table, filename = \"output/tables/age_gender_cross_tabulation.html\")\nAdvantages:\n\nGenerating publication-ready tables with advanced customization.\nProducing interactive HTML tables for dashboards or web-based reports.\n\n\n\n\n\n\n\n\n\n\nCleaning and Tabulating Data with janitor\n\n\n\n\n\nThe janitor package offers functions like tabyl() for creating frequency tables and cross-tabulations, with options to directly save them as data frames for further analysis or export.\nCreating and Saving Frequency Tables\n# Install package\ninstall.packages(\"janitor\")\ninstall.packages(\"dplyr\")\n\n# Load janitor package\nlibrary(janitor)\nlibrary(dplyr)\n\n# Frequency table for AgeBand\nage_band_freq &lt;- survey_data %&gt;%\n  tabyl(AgeBand)\n\n# Save as CSV\nwrite.csv(age_band_freq, \"output/tables/age_band_frequency.csv\", row.names = FALSE)\nCreating and Saving Cross-Tabulation\n# Make sure that the package is installed and loaded\n\n# Cross-tabulation of AgeBand and Gender\nage_gender_table &lt;- survey_data %&gt;%\n  tabyl(AgeBand, Gender)\n\n# Save as CSV\nwrite.csv(age_gender_table, \"output/tables/age_gender_cross_tabulation.csv\", row.names = FALSE)\nAdvantages:\n\nAutomatically includes proportions and percentages in the output.\nProvides a clean and readable tabular output.\n\n\n\n\n\n\n\n\n\n\nPublication-Ready Tables with gtsummary\n\n\n\n\n\nThe gtsummary package is great for creating cross-tabulations with enhanced formatting and export options.\nCreating and Saving Cross-Tabulation\n# Install package\ninstall.packages(\"gtsummary\")\ninstall.packages(\"dplyr\")\n\n# Load package\nlibrary(gtsummary)\nlibrary(dplyr)\n\n\n# Create a cross-tabulation table\nage_gender_table &lt;- survey_data %&gt;%\n  tbl_cross(\n    row = AgeBand,\n    col = Gender\n  )\n\n# Save as a CSV or Word document\nas_gt(age_gender_table) %&gt;%\n  gt::gtsave(\"output/tables/age_gender_cross_tabulation.html\")\nAdvantages:\n\nProduces beautifully formatted tables.\nSupports export to multiple formats (e.g., HTML, Word, PDF).\n\n\n\n\n\n\n\n\n\n\nCustomizable Table Formatting with flextable\n\n\n\n\n\nThe flextable package is ideal for customizing tables for reports and presentations such as Word/PowerPoint outputs.\nFormatting and Saving a Cross-Tabulation\n# Install package\ninstall.packages(\"flextable\")\ninstall.packages(\"dplyr\")\n\n# Load package\nlibrary(flextable)\nlibrary(dplyr)\n\n# Convert a cross-tabulation to a flextable\nage_gender_table &lt;- table(survey_data$AgeBand, survey_data$Gender) %&gt;%\n  as.data.frame()\n\nft &lt;- flextable(age_gender_table)\n\n# Save as Word document\nsave_as_docx(ft, path = \"output/tables/age_gender_cross_tabulation.docx\")\n# Save as PowerPoint document\nsave_as_pptx(ft, path = \"output/tables/age_gender_cross_tabulation.pptx\")\n# Save as image\nsave_as_image(ft, path = \"output/tables/age_gender_cross_tabulation.png\")\nAdvantages:\n\nHighly customizable appearance.\nExport to Word, PowerPoint, or HTML formats."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-b2-loading-the-data",
    "href": "lab-uofg-01/lab-uofg-01.html#step-b2-loading-the-data",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "3.2 Step B2: Loading the Data",
    "text": "3.2 Step B2: Loading the Data\nCopy the code below into the Lab_Exercise_B.R script and run it:\n# Load the CSV file stored in the \"data\" folder\nsurvey_data_full &lt;- read.csv(\"data/lab1-survey.csv\")\nYou can easily explore and check the basic structure of your data and get a summary:\n# View the first few rows using head()\nhead(survey_data_full)\n\n# Examine the structure\nstr(survey_data_full)\n\n# Get basic summary statistics\nsummary(survey_data_full)\nBefore moving on to the analysis, we want to take a look at demographic variables. Demographic variables are fundamental in empirical research as they capture key characteristics of individuals or populations, such as age, gender, marital status, education level, and socioeconomic background. These variables provide essential context for understanding behaviors, preferences, and outcomes, allowing researchers to analyze patterns, identify trends, and draw meaningful comparisons across groups. In business and social science research, demographic variables are often used to segment data, control for confounding factors, and explore relationships between characteristics and dependent variables. Their inclusion ensures a more comprehensive and nuanced understanding of research findings, enabling the development of targeted strategies and policies.\nWe want to assign labels to the demographic variables in the survey_data_full data frame using factors with labeled levels. This method ensures the data remains categorical but with human-readable labels for easier interpretation and analysis.\n# Convert demographic variables to factors with labeled levels\n\n# Assign labels for \"sex\"\nsurvey_data_full$sex &lt;- factor(\n  survey_data_full$sex,\n  levels = c(1, 2),\n  labels = c(\"Male\", \"Female\")\n)\n\n# Assign labels for \"marital\"\nsurvey_data_full$marital &lt;- factor(\n  survey_data_full$marital,\n  levels = c(1, 2, 3, 4, 5, 6, 7, 8),\n  labels = c(\n    \"Single\", \"Steady relationship\", \"Living with partner\",\n    \"Married first time\", \"Remarried\", \"Separated\",\n    \"Divorced\", \"Widowed\"\n  )\n)\n\n# Assign labels for \"child\"\nsurvey_data_full$child &lt;- factor(\n  survey_data_full$child,\n  levels = c(1, 2),\n  labels = c(\"Yes\", \"No\")\n)\n\n# Assign labels for \"educ\"\nsurvey_data_full$educ &lt;- factor(\n  survey_data_full$educ,\n  levels = c(1, 2, 3, 4, 5, 6),\n  labels = c(\n    \"Primary\", \"Some secondary\", \"Completed high school\",\n    \"Some additional training\", \"Completed undergraduate\",\n    \"Postgraduate completed\"\n  )\n)\n\n# Assign labels for \"source\"\nsurvey_data_full$source &lt;- factor(\n  survey_data_full$source,\n  levels = c(1, 2, 3, 4, 5, 6, 7, 8, 9),\n  labels = c(\n    \"Work\", \"Spouse or partner\", \"Relationships\", \"Children\",\n    \"Family\", \"Health/illness\", \"Life in general\",\n    \"Money/finances\", \"Lack of time, too much to do\"\n  )\n)\n\n# Assign labels for \"smoke\"\nsurvey_data_full$smoke &lt;- factor(\n  survey_data_full$smoke,\n  levels = c(1, 2),\n  labels = c(\"Yes\", \"No\")\n)\nThe summary() function can be used to confirm that the labels have been applied correctly to the variables.\n# Verify changes by printing a summary\nsummary(survey_data_full)"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-b3-exploring-your-data",
    "href": "lab-uofg-01/lab-uofg-01.html#step-b3-exploring-your-data",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "3.3 Step B3: Exploring your Data",
    "text": "3.3 Step B3: Exploring your Data\nExploring the frequencies of demographic variables is a fundamental step in descriptive analysis, offering a clear understanding of the sample composition. By combining table() and prop.table(), we can compute both raw counts and relative proportions, providing a detailed overview of variables like gender, marital status, and education. These insights form the foundation for deeper analyses, such as segmentation or hypothesis testing, ensuring a strong start to any empirical research.\nGender (sex)\nThe sex variable captures the gender distribution of the sample. To compute and display the frequency table:\n# Frequency table for Gender\ngender_freq &lt;- table(survey_data_full$sex)\nprint(gender_freq)\n\n# Proportions and percentages\ngender_prop &lt;- prop.table(gender_freq)\ngender_percent &lt;- round(gender_prop * 100, 2)\nprint(gender_percent)\nThis output shows the count and percentage of participants who identify as Male or Female.\nMarital Status (marital)\nThe marital variable indicates the participants’ marital status. To compute and display the frequency table:\n# Frequency table for Marital Status\nmarital_freq &lt;- table(survey_data_full$marital)\nprint(marital_freq)\n\n# Proportions and percentages\nmarital_prop &lt;- prop.table(marital_freq)\nmarital_percent &lt;- round(marital_prop * 100, 2)\nprint(marital_percent)\nThis analysis highlights the most common marital statuses in the sample, such as Single or Married first time.\nParental Status (child)\nThe child variable records whether participants have children. Frequency analysis provides an overview of parental distribution:\n# Frequency table for Parental Status\nchild_freq &lt;- table(survey_data_full$child)\nprint(child_freq)\n\n# Proportions and percentages\nchild_prop &lt;- prop.table(child_freq)\nchild_percent &lt;- round(child_prop * 100, 2)\nprint(child_percent)\nThis reveals the proportion of participants who have children versus those who do not.\nEducation Level (educ)\nThe educ variable reflects participants’ highest level of education. To understand the distribution:\n# Frequency table for Education Level\neduc_freq &lt;- table(survey_data_full$educ)\nprint(educ_freq)\n\n# Proportions and percentages\neduc_prop &lt;- prop.table(educ_freq)\neduc_percent &lt;- round(educ_prop * 100, 2)\nprint(educ_percent)\nThis breakdown identifies the most common educational backgrounds, such as Completed undergraduate or Postgraduate completed.\nPrimary Source of Stress (source)\nThe source variable represents participants’ reported primary source of stress. Analyse the distribution as follows:\n# Frequency table for Primary Source of Stress\nsource_freq &lt;- table(survey_data_full$source)\nprint(source_freq)\n\n# Proportions and percentages\nsource_prop &lt;- prop.table(source_freq)\nsource_percent &lt;- round(source_prop * 100, 2)\nprint(source_percent)\nThis provides insights into stress sources, such as Work, Family, or Lack of time.\nSmoking Status (smoke)\nThe smoke variable indicates participants’ smoking habits. Use the following code to analyze:\n# Frequency table for Smoking Status\nsmoke_freq &lt;- table(survey_data_full$smoke)\nprint(smoke_freq)\n\n# Proportions and percentages\nsmoke_prop &lt;- prop.table(smoke_freq)\nsmoke_percent &lt;- round(smoke_prop * 100, 2)\nprint(smoke_percent)\nThis reveals the proportion of participants who smoke versus those who do not.\nSummarising Frequencies\nTo summarise all frequency tables and proportions in a single view, you can use a structured approach like the code below. This produces a consolidated view of the frequencies and percentages for all demographic variables, making it easier to compare distributions. (Note: This requires that you created the individual frequencies and percentages for all variables previously.)\n# Combine frequency tables into a list for easy viewing\nfrequency_summary &lt;- list(\n  Gender = list(Count = gender_freq, Percent = gender_percent),\n  MaritalStatus = list(Count = marital_freq, Percent = marital_percent),\n  ParentalStatus = list(Count = child_freq, Percent = child_percent),\n  EducationLevel = list(Count = educ_freq, Percent = educ_percent),\n  StressSource = list(Count = source_freq, Percent = source_percent),\n  SmokingStatus = list(Count = smoke_freq, Percent = smoke_percent)\n)\n\n# Print the summary\nprint(frequency_summary)"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-c1-setup",
    "href": "lab-uofg-01/lab-uofg-01.html#step-c1-setup",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "4.1 Step C1: Setup",
    "text": "4.1 Step C1: Setup\nYou can continue working in the same script that you created in Step B1 (the exemplary script that you can download also combined both exercises) or create a new scipt now. For the latter, review Step B1 and save new the script in the scripts folder within your project folder or working directory with an appropriate name, e.g., Lab1_Exercise_C.R.\n\n\n\n\n\n\nUsing ggplot2 for Data Visualization\n\n\n\n\n\nWhile base R plotting functions are straightforward and sufficient for creating simple visualizations, the ggplot2 package offers a more powerful, flexible, and consistent approach to data visualization. Developed as part of the tidyverse, ggplot2 is built on the grammar of graphics, enabling users to layer graphical components (e.g., data, aesthetics, and geoms) to create complex and customizable plots. Compared to base R, ggplot2 excels in:\n\nCustomization: Allows fine-tuning of colors, themes, scales, and labels for polished, publication-ready graphics.\nConsistency: Provides a unified framework for visualizing different types of data without requiring separate functions for each type of plot.\nExtensibility: Supports advanced visualizations and easy integration with other tidyverse tools.\n\nFor example, while base R may require multiple lines of code to create and customize a bar plot, ggplot2 simplifies the process, making it both more readable and more intuitive for creating layered, reusable visualizations.\nTo begin using ggplot2 for data visualization in R, you need to ensure the package is installed and loaded into your R session. Follow these simple steps to get started:\n1. Install the ggplot2 Package\nIf you haven’t already installed ggplot2, you can do so using the install.packages() function. This only needs to be done once for your system. The command below downloads and installs the package from CRAN (the Comprehensive R Archive Network).\n# Install ggplot2\ninstall.packages(\"ggplot2\")\n2. Load the ggplot2 Package\nOnce installed, you need to load the package into your R session using the library() function. This step must be repeated each time you start a new R session and makes all the ggplot2 functions available for use in your current R session.\n# Load ggplot2\nlibrary(ggplot2)\n3. Exploring Help and Resources (optional)\nYou can access detailed documentation and examples for ggplot2 by using the help system or exploring online resources. The ggplot2 package has extensive documentation and a supportive community, making it easy to learn and apply its powerful tools.\n# Access the ggplot2 documentation\nhelp(package = \"ggplot2\")"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-b4-exploring-participants-age",
    "href": "lab-uofg-01/lab-uofg-01.html#step-b4-exploring-participants-age",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "3.4 Step B4: Exploring Participants’ Age",
    "text": "3.4 Step B4: Exploring Participants’ Age\nFrequencies are a powerful tool for summarizing categorical variables, but they are less meaningful for continuous or numeric variables like age. In a dataset, age values can range widely, and each unique value may appear only once or a few times, leading to sparse and uninformative frequency tables. For example, a table showing the frequency of exact ages (e.g., 23, 24, 25) provides limited insight into age distribution because it does not group participants into broader, interpretable categories. Instead, grouping numeric variables into ranges (bands) transforms continuous data into an ordinal variable, making frequencies more meaningful and enabling comparisons across age groups.\nTo better analyze and summarize age-related data, we can create a new variable called AgeBand that groups ages into meaningful ranges. Here, we will define six age bands: - &lt;21, 21-30, 31-40, 41-50, 51-60, and &gt;60.\nThe new variable will be ordinal, meaning the age bands have a natural order, which is useful for analysis and visualization.\n# Creating an AgeBand variable\nsurvey_data_full$AgeBand &lt;- cut(\n  survey_data_full$age, \n  breaks = c(-Inf, 20, 30, 40, 50, 60, Inf), \n  labels = c(\"&lt;21\", \"21-30\", \"31-40\", \"41-50\", \"51-60\", \"&gt;60\"), \n  right = TRUE\n)\n\n# Verify the new AgeBand variable\n\n# Frequency table for AgeBand\nAgeBand_freq &lt;- table(survey_data_full$AgeBand)\nprint(AgeBand_freq)\n\n# Percentages for AgeBand\nAgeBand_prop &lt;- prop.table(AgeBand_freq)\nAgeBand_percent &lt;- round(AgeBand_prop * 100, 2)\nprint(AgeBand_percent)\nThe code above includes some new fucntions, which are explained below:\n\ncut(): Converts the numeric age variable into an ordinal factor.\nbreaks: Specifies the boundaries for the age bands. -Inf and Inf ensure all ages are included.\nlabels: Assigns descriptive names to each age band."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-b4-cross-tabulations",
    "href": "lab-uofg-01/lab-uofg-01.html#step-b4-cross-tabulations",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "3.5 Step B4: Cross-Tabulations",
    "text": "3.5 Step B4: Cross-Tabulations\nIn this task, we first analyse the relationship between marital status (marital) and parental status (child). This provides insights into how having children is distributed across different marital statuses.\n# Create a cross-tabulation of Marital Status by Parental Status\nmarital_child_table &lt;- table(survey_data_full$marital, survey_data_full$child)\n\n# Print the cross-tabulation\nprint(marital_child_table)\nTo further analyze the table, we calculate proportions and percentages. These help interpret the relative distribution of parental status within each marital status group or across the entire sample.\n# Proportions for the entire table\nmarital_child_prop &lt;- prop.table(marital_child_table)\nprint(round(marital_child_prop * 100, 2))\n\n# Row-wise proportions (within marital status groups)\nmarital_child_row_prop &lt;- prop.table(marital_child_table, margin = 1)\nprint(round(marital_child_row_prop * 100, 2))\n\n# Column-wise proportions (within parental status groups)\nmarital_child_col_prop &lt;- prop.table(marital_child_table, margin = 2)\nprint(round(marital_child_col_prop * 100, 2))\nWe can also add marginal totals. Including row and column totals provides additional context for the distribution.\n# Add marginal totals to the table\nmarital_child_with_totals &lt;- addmargins(marital_child_table)\nprint(marital_child_with_totals)\nCross-tabulating marital and child provides a detailed view of the relationship between marital status and parental status. By combining raw counts and proportions, we can identify meaningful patterns in the data, supporting deeper insights into family composition and relationships.\nOver to you: use the code above as a blue print and analyse the relationship between other variables."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-c2-histograms",
    "href": "lab-uofg-01/lab-uofg-01.html#step-c2-histograms",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "4.2 Step C2: Histograms",
    "text": "4.2 Step C2: Histograms\nA histogram is a fundamental tool for visualizing the distribution of a continuous variable. It provides a graphical representation of the frequency or density of data values, divided into intervals (bins). Histograms help identify patterns, such as skewness, multimodality, or outliers, and give insight into the overall shape of the data distribution.\nCompared to base R, ggplot2 offers greater flexibility and customization for creating histograms. You can easily adjust the number of bins, add labels, and style the plot to make it more informative and visually appealing.\n\n4.2.1 Creating a Histogram for tpstress**\nIn this example, we will create a histogram for the variable tpstress from the survey_data_full dataset. This variable is continuous, making it ideal for a histogram. Run the code below and examine the output, before reading on about the variables and choices that we made here.\n# Create a histogram for tpstress\nhistogram_tpstress &lt;- ggplot(data = survey_data_full, aes(x = tpstress)) +\n  geom_histogram(binwidth = 5, fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Distribution of Perceived Stress Levels\",\n    x = \"Perceived Stress Score (tpstress)\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()\n\n# Show plot\nhistogram_tpstress\n\n# Save plot\nggsave(\"output/figures/histogram_tpstress.pdf\", width = 8, height = 5)\nNote: If you run the code above, you will get the warning message below. This warning occurs because some values in your variable are non-finite (i.e., they contain NA, NaN, or Inf values), and ggplot2 automatically removes them when trying to create the histogram. If you inspect the data, the variable tpstress has six missing values. The warning doesn’t stop the plot from rendering, but it alerts you that data is being removed and you should investigate the reason behind the warning and decide how to handle it appropriately (e.g., filtering, replacing, or imputing missing values if necessary).\nWarning message:\nRemoved 6 rows containing non-finite outside the scale range (`stat_bin()`). \nExplanation of the Code\n\nggplot(): Specifies the dataset (survey_data_full) and the mapping of variables to aesthetics (aes()), with tpstress assigned to the x-axis.\ngeom_histogram(): Adds a histogram layer to the plot.\nbinwidth: Sets the width of each bin (adjustable depending on the range of your data - more informationa bout this below).\nfill and color: Customize the fill color of the bars and the border color.\nlabs(): Adds descriptive labels for the title, x-axis, and y-axis to make the plot clear.\ntheme_minimal(): Applies a clean and simple theme for better aesthetics.\n\nAdjusting Bins\nThe number of bins can significantly affect the visualization. For finer or coarser groupings, adjust the binwidth parameter. For example:\n\nUse a smaller binwidth (e.g., binwidth = 2) for detailed distributions.\nUse a larger binwidth (e.g., binwidth = 10) for a summarized view.\n\nInterpretation of the Graphs\nThe histogram will display the distribution of the tpstress variable (Figure 1), showing the frequency of scores within each bin. This can help answer questions like:\n\nAre most participants experiencing low, moderate, or high stress?\nDoes the data appear skewed or normally distributed?\n\n\n\n\n\n\n\nFigure 1: Histogram of tpstress\n\n\n\n\n\n\n\n\n\nSaving Plots with ggsave in ggplot2\n\n\n\n\n\nWhen creating visualizations in R, you often need to save your plots for reports, presentations, or further analysis. The ggsave() function in ggplot2 provides an easy and flexible way to save plots to various file formats with high quality.\nOverview of ggsave\n\nAutomatically saves the last plot created in your R session, or a specified plot object.\nSupports various file formats such as PNG, JPEG, PDF, and SVG.\nAllows customization of file size, resolution, and aspect ratio.\n\nBasic Syntax\nggsave(filename, plot = last_plot(), width = 20, height = 15, units = \"cm\", dpi = 300)\nWhere:\n\nfilename: The name of the file, including the desired extension (e.g., \"plot.png\" or \"plot.pdf\").\nplot: Specifies which plot to save. Defaults to the most recent plot (last_plot()).\nwidth and height: Specify the dimensions of the plot in inches (default units).\nunits: supports custom units for dimensions (default is inches when not specified).\ndpi: Sets the resolution of the plot (dots per inch). Higher values (e.g., 300) produce print-quality images.\n\nFormats\nWe can save the histogram for tpstress in different formats, depending on the purpose.\nPNG: For lossless, high-quality images suitable for both web use and presentations.\nggsave(\"histogram_tpstress.png\", plot = scatter_plot, width = 8, height = 6)\nPDF: For vector-based, high-quality graphics suitable for printing.\nggsave(\"histogram_tpstress.pdf\", plot = scatter_plot, width = 8, height = 6)\nJPEG: For compressed images with smaller file sizes (useful for web).\nggsave(\"histogram_tpstress.pdf\", plot = scatter_plot, width = 8, height = 6, dpi = 300)\nSVG: For scalable vector graphics, ideal for interactive web applications.\nggsave(\"histogram_tpstress.pdf\", plot = scatter_plot, width = 8, height = 6)\n\n\n\n\n\n4.2.2 Compare Groups Using Histograms**\nWhen comparing distributions between groups, it’s often useful to visualize them side by side or stacked for easier comparison. In R, this can be achieved using facets in ggplot2, which allow you to create separate subplots for different levels of a categorical variable. In this example, we compare the variable tpstress between males and females (grouped by sex) on separate histograms.\nPanelled Histograms\nFacets in ggplot2 replicate the SPSS functionality of splitting graphs by groups:\n\nSide-by-side graphs allow for direct visual comparison between groups.\nStacked graphs present the distributions on top of each other for easier alignment.\n\nCode to Compare tpstress by sex\nHere’s the code to create separate histograms for males and females:\n# Panelled histograms for tpstress by sex\nhistogram_tpstress_gender &lt;- ggplot(data = survey_data_full, aes(x = tpstress)) +\n  geom_histogram(binwidth = 5, fill = \"lightblue\", color = \"black\") +\n  facet_wrap(~ sex, ncol = 2) +  # Creates separate panels for each group\n  labs(\n    title = \"Comparison of Perceived Stress Levels by Gender\",\n    x = \"Perceived Stress Score (tpstress)\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()\n\n# Show plot\nhistogram_tpstress_gender\n\n# Save plot\nggsave(\"output/figures/histogram_tpstress_gender.pdf\", width = 8, height = 5)\nExplanation of the Code\n\nfacet_wrap(~ sex): Splits the histogram into separate panels for each level of the sex variable (Male and Female). The ncol = 2 argument specifies that the graphs should be placed side by side.\ngeom_histogram(): Creates histograms with a consistent binwidth for comparison.\nlabs(): Adds clear labels to describe the plot.\ntheme_minimal(): Ensures a clean and professional appearance.\n\nHandling Missing Values\nBy default, ggplot2 excludes cases with missing values in the grouping variable (sex) or the variable being plotted (tpstress). This mirrors SPSS functionality where cases with missing values are excluded on a variable-by-variable basis.\nTo explicitly confirm exclusions, use the na.omit() function to clean the dataset:\n# Remove cases with missing values in tpstress or sex\nsurvey_data_filtered &lt;- na.omit(survey_data_full[, c(\"tpstress\", \"sex\")])\nAlternative Layout: Stacked Panels\nTo stack the graphs vertically instead of placing them side by side, use facet_wrap() with ncol = 1:\n# Stacked histograms for tpstress by sex\nhistogram_tpstress_gender_stack &lt;- ggplot(data = survey_data_full, aes(x = tpstress)) +\n  geom_histogram(binwidth = 5, fill = \"lightblue\", color = \"black\") +\n  facet_wrap(~ sex, ncol = 1) +  # Stacks panels vertically\n  labs(\n    title = \"Comparison of Perceived Stress Levels by Gender (Stacked)\",\n    x = \"Perceived Stress Score (tpstress)\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()\n\n# Show plot\nhistogram_tpstress_gender_stack\n\n# Save plot\nggsave(\"output/figures/histogram_tpstress_gender_stack.pdf\", width = 8, height = 5)\nInterpretation of the Graphs\nThe panelled (Figure 2) and stacked histograms (Figure 2) show the distribution of perceived stress scores (tpstress) for males and females:\n\nLook for differences in the shape, spread, and center of the distributions.\nIdentify patterns such as skewness or concentration of values in specific ranges.\n\n\n\n\n\n\n\nFigure 2: Panelled histograms for tpstress by sex\n\n\n\n\n\n\n\n\n\nFigure 3: Stacked histograms for tpstress by sex"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-c3-bar-charts",
    "href": "lab-uofg-01/lab-uofg-01.html#step-c3-bar-charts",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "4.3 Step C3: Bar Charts",
    "text": "4.3 Step C3: Bar Charts\nA bar chart is one of the most basic and widely used tools for visualizing categorical data. It shows the frequencies or counts of different categories, making it ideal for identifying dominant groups, comparing categories, and providing a quick summary of data distributions. Bar charts are especially useful when you want to:\n\nDisplay the distribution of a single categorical variable.\nCompare the relative size of categories.\nHighlight which categories are most or least common.\n\nBar charts are most effective for categorical or ordinal variables, such as:\n\nDemographic variables (e.g., gender, marital status, education level).\nGrouping variables (e.g., age bands, product categories).\nSummarizing discrete counts (e.g., survey responses, preference rankings).\n\nBar charts are not suitable for continuous variables (e.g., tpstress) since these are better visualized using histograms or boxplots.\n\n4.3.1 Creating a Simple Bar Chart\nIn this example, we create a simple bar chart for the variable sex, which represents gender.\n# Simple bar chart for Gender\nbar_gender &lt;- ggplot(data = survey_data_full, aes(x = sex)) +\n  geom_bar(fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Gender Distribution\",\n    x = \"Gender\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n  \n# Show plot\nbar_gender\n\n# Save plot\nggsave(\"output/figures/bar_gender.pdf\", width = 8, height = 5)\nExplanation of the Code\n\nggplot(): Specifies the dataset (survey_data_full) and maps the variable sex to the x-axis using aes(x = sex).\ngeom_bar(): Creates a bar chart. Since no y aesthetic is specified, geom_bar() automatically counts the number of occurrences of each category in sex. fill specifies the color of the bars, while color adds a border around each bar.\nlabs(): Adds descriptive labels to the title, x-axis, and y-axis for clarity.\ntheme_minimal(): Applies a clean, minimal theme for better aesthetics.\n\nInterpretation of the Graphs\nRunning the above code will produce a simple bar chart showing the distribution of males and females in the dataset (Figure 4). The y-axis represents the count of participants in each gender category.\n\n\n\n\n\n\nFigure 4: Simple bar chart for sex\n\n\n\n\n\n4.3.2 Creating a Clustered Bar Chart\nIn this exercise, we replicate the functionality of SPSS’ Clustered Bar Chart, where:\n\nA categorical variable (e.g., agegp3) is plotted on the x-axis.\nA grouping variable (e.g., sex) determines the clusters (represented by different colors).\nA continuous variable (tpstress) is used to calculate the mean for each combination of the categorical variables.\n\nggplot2 in R provides powerful tools to create clustered bar charts with error bars to visualize group-level summaries clearly.\nWe will create a clustered bar chart where: - X-axis: Represents categories of agegp3 (age groups in this example). - Groups: Clusters represent sex (males and females), distinguished by colors. - Y-axis: Displays the mean of the continuous variable (tpstress) for each group. - Error Bars: Represent variability (e.g., standard errors) to give context to the mean values.\nPreparing the Data in Base R\nBefore creating the chart, we summarize the data to calculate the mean and standard error for tpstress within each combination of agegp3 and sex:\nFirst, we need to calculate the group means. The aggregate() function in base R allows you to compute the mean of a continuous variable (tpstress) for each combination of agegp3 and sex.\n# Calculate group means using aggregate()\ngroup_means &lt;- aggregate(\n  tpstress ~ agegp3 + sex,\n  data = survey_data_full,\n  FUN = mean,\n  na.rm = TRUE\n)\n\n# Display the group means\nprint(group_means)\nHere:\n\ntpstress ~ agegp3 + sex specifies the grouping variables (agegp3 and sex).\nFUN = mean calculates the mean of tpstress for each group.\nna.rm = TRUE ensures missing values are excluded.\n\nSecond, we need to calculate group standard errors. To compute standard errors, use aggregate() again for the standard deviation, then calculate the standard error manually.\n# Calculate group standard deviations\ngroup_sd &lt;- aggregate(\n  tpstress ~ agegp3 + sex,\n  data = survey_data_full,\n  FUN = sd,\n  na.rm = TRUE\n)\n\n# Add a column for group sizes\ngroup_counts &lt;- aggregate(\n  tpstress ~ agegp3 + sex,\n  data = survey_data_full,\n  FUN = length\n)\n\n# Merge the results into a single data frame\ngroup_stats &lt;- merge(group_means, group_sd, by = c(\"agegp3\", \"sex\"))\ngroup_stats &lt;- merge(group_stats, group_counts, by = c(\"agegp3\", \"sex\"))\n\n# Rename columns for clarity\ncolnames(group_stats) &lt;- c(\"agegp3\", \"sex\", \"mean_tpstress\", \"sd_tpstress\", \"n\")\n\n# Calculate standard errors\ngroup_stats$se_tpstress &lt;- group_stats$sd_tpstress / sqrt(group_stats$n)\n\n# Display the final data frame\nprint(group_stats)\nOur final data frame group_stats contains:\n\nagegp3: Age group.\nsex: Gender group.\nmean_tpstress: Mean perceived stress score.\nsd_tpstress: Standard deviation of stress scores.\nn: Number of participants in each group.\nse_tpstress: Standard error of the mean.\n\nCreating the Clustered Bar Chart\nUsing the prepared group_stats data, you can now create the clustered bar chart with ggplot2.\n# Clustered bar chart using the prepared data\nbar_gender_age &lt;- ggplot(data = group_stats, aes(x = agegp3, y = mean_tpstress, fill = sex)) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.8), color = \"black\") +\n  geom_errorbar(\n    aes(ymin = mean_tpstress - se_tpstress, ymax = mean_tpstress + se_tpstress),\n    position = position_dodge(width = 0.8),\n    width = 0.2\n  ) +\n  labs(\n    title = \"Mean Perceived Stress by Age Group and Gender\",\n    x = \"Age Group\",\n    y = \"Mean Perceived Stress Score (tpstress)\",\n    fill = \"Gender\"\n  ) +\n  theme_minimal()\n\n# Show plot\nbar_gender_age\n\n# Save plot\nggsave(\"output/figures/bar_gender_age.pdf\", width = 8, height = 5)\nExplanation of the Code\n\nggplot(): Specifies the dataset (group_stats) and defines mappings between variables and aesthetics (aes()). fill = sex Uses the sex variable (gender) to determine the color of the bars.\ngeom_bar(): Creates the bar chart. stat = \"identity\" plots the actual values of mean_tpstress instead of counting occurrences (default behavior). position = position_dodge(width = 0.8) separates the bars into clusters by sex, leaving a small gap between groups. color = \"black\" adds a black border around each bar to enhance visual distinction.\ngeom_errorbar(): Adds error bars to the bars. ymin and ymax define the range of the error bars (mean ± standard error). width = 0.2 controls the width of the error bar caps.\nlabs() adds a descriptive title, axis labels, and a legend title.\ntheme_minimal() ensures a clean and professional look.\n\n\n\n\n\n\n\nAlternative using dplyr package\n\n\n\n\n\nA simpler way to prepare the data is to use the `dplyr’ package.\nPreparing the Data\nBefore creating the chart, we summarize the data to calculate the mean and standard error for tpstress within each combination of agegp3 and sex:\n# Install dplyr\ninstall.packages(\"dplyr\")\n\n# Load library\nlibrary(dplyr)\n\n# Summarize the data\nsurvey_summary &lt;- survey_data_full %&gt;%\n  group_by(agegp3, sex) %&gt;%\n  summarise(\n    mean_tpstress = mean(tpstress, na.rm = TRUE),\n    se_tpstress = sd(tpstress, na.rm = TRUE) / sqrt(n())\n  )\n\n# Display the summarized data\nprint(survey_summary)\nCreating the Clustered Bar Chart\nUsing the summarized data, we can create a clustered bar chart with error bars:\n# Create a clustered bar chart with ggplot2\nbar_gender_age2 &lt;- ggplot(data = survey_summary, aes(x = agegp3, y = mean_tpstress, fill = sex)) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.8), color = \"black\") +\n  geom_errorbar(aes(ymin = mean_tpstress - se_tpstress, ymax = mean_tpstress + se_tpstress),\n                position = position_dodge(width = 0.8), width = 0.2) +\n  labs(\n    title = \"Mean Perceived Stress by Age Group and Gender\",\n    x = \"Age Group\",\n    y = \"Mean Perceived Stress Score (tpstress)\",\n    fill = \"Gender\"\n  ) +\n  theme_minimal()\n\n# Show plot\nbar_gender_age2\n\n# Save plot\nggsave(\"output/figures/bar_gender_age2.pdf\", width = 8, height = 5)\nExplanation of the Code\n\nThe dplyr package is used to calculate the mean (mean_tpstress) and standard error (se_tpstress) of tpstress grouped by agegp3 and sex.\ngeom_bar(): Creates the bar chart. stat = \"identity\" specifies that the heights of the bars represent the actual values (means in this case). position = position_dodge(width = 0.8) separates the bars into clusters by sex.\ngeom_errorbar(): Adds error bars to the bars. ymin and ymax define the range of the error bars (mean ± standard error). width = 0.2 controls the width of the error bar caps.\naes(fill = sex) assigns colors to sex groups.\nlabs() adds a descriptive title, axis labels, and a legend title.\ntheme_minimal() ensures a clean and professional look.\n\n\n\n\nInterpretation of the Chart\nThe clustered bar chart (Figure 5) allows us to compare:\n\nDifferences in mean perceived stress (tpstress) across age groups (agegp3).\nHow stress levels differ between males and females (sex) within each age group.\nThe size of the error bars provides insight into variability within each group.\n\n\n\n\n\n\n\nFigure 5: Clustered bar chart for tpstress by sex"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-c4-line-graphs",
    "href": "lab-uofg-01/lab-uofg-01.html#step-c4-line-graphs",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "4.4 Step C4: Line Graphs",
    "text": "4.4 Step C4: Line Graphs\nLine graphs are a versatile tool for visualizing trends and relationships between variables. They are particularly useful for examining how a continuous variable changes across categories or over time. In this example, we use tpstress (perceived stress) as the continuous variable on the y-axis and agegp5 (age group) as the categorical variable on the x-axis. We create two versions:\n\nA simple line graph.\nA multi-line graph with separate lines for males and females (sex).\n\n\n4.4.1 Creating a Simple Line Graph\nA simple line graph shows how the average tpstress score changes across age groups (agegp5).\n# Calculate the mean tpstress for each age group\nsimple_line_data &lt;- aggregate(\n  tpstress ~ agegp5,\n  data = survey_data_full,\n  FUN = mean,\n  na.rm = TRUE\n)\n\n# Create the line graph\nline_stress_age &lt;- ggplot(data = simple_line_data, aes(x = agegp5, y = tpstress, group = 1)) +\n  geom_line(color = \"blue\", linewidth = 1) +\n  geom_point(color = \"blue\", size = 2) +\n  labs(\n    title = \"Mean Perceived Stress by Age Group\",\n    x = \"Age Group\",\n    y = \"Mean Perceived Stress Score\"\n  ) +\n  theme_minimal()\n\n# Show plot\nline_stress_age\n\n# Save plot\nggsave(\"output/figures/line_stress_age.pdf\", width = 8, height = 5)\nExplanation of the Code\n\naggregate() calculates the mean tpstress for each agegp5 group while excluding missing values (na.rm = TRUE).\nggplot(): Specifies the data (simple_line_data) and maps agegp5 to the x-axis and tpstress (mean perceived stress) to the y-axis.\ngeom_line(): Creates the line connecting the points. color = \"blue\" specifies the color of the line. size = 1 adjusts the line thickness.\ngeom_point(): Adds individual points for each age group. color = \"blue\" matches the line color. size = 2 makes the points more visible.\nlabs() adds a descriptive title, axis labels, and a legend title.\ntheme_minimal() ensures a clean and professional look.\n\nInterpretation of the Graphs\nIn the simple line graph (Figure 6), the x-axis represents age groups (agegp5), and the y-axis shows the mean perceived stress scores (tpstress). The points connected by the line indicate how stress levels change across age groups.\nKey questions to consider:\n\nOverall Trend: Do stress levels increase, decrease, or remain stable across age groups?\nPeaks and Valleys: Are there specific age groups with notably higher or lower stress levels?\nOutliers: Are there unexpected jumps or drops in the graph that may warrant further investigation?\n\n\n\n\n\n\n\nFigure 6: Simple line graph for age groups (agegp5) and tpstress\n\n\n\n\n\n4.4.2 Creating a Multi-Line Graph\nTo show separate lines for males and females, we include the sex variable as a grouping and color aesthetic.\n# Calculate the mean tpstress for each combination of age group and gender\nmulti_line_data &lt;- aggregate(\n  tpstress ~ agegp5 + sex,\n  data = survey_data_full,\n  FUN = mean,\n  na.rm = TRUE\n)\n\n# Create the multi-line graph\nline_stress_age_gender &lt;- ggplot(data = multi_line_data, aes(x = agegp5, y = tpstress, color = sex, group = sex)) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 2) +\n  labs(\n    title = \"Mean Perceived Stress by Age Group and Gender\",\n    x = \"Age Group\",\n    y = \"Mean Perceived Stress Score\",\n    color = \"Gender\"\n  ) +\n  theme_minimal()\n\n# Show plot\nline_stress_age_gender\n\n# Save plot\nggsave(\"output/figures/line_stress_age_gender.pdf\", width = 8, height = 5)\nExplanation of the Code\n\naggregate() calculates the mean tpstress for each combination of agegp5 and sex.\nggplot(): Specifies the data (multi_line_data) and maps agegp5 to the x-axis, tpstress (mean perceived stress) to the y-axis, sex to the color aesthetic for distinct line colors, and group = sex ensures separate lines for each gender.\ngeom_line(): Creates the line connecting the points. The color aesthetic from aes() applies distinct colors to the lines. size = 1 adjusts the line thickness.\ngeom_point(): Adds individual points for each age group. color = \"blue\" matches the line color. size = 2 makes the points more visible.\nlabs() adds a descriptive title, axis labels, and a legend title.\ntheme_minimal() ensures a clean and professional look.\n\nInterpretation of the Graphs\nThe multi-line graph adds a layer of complexity by splitting the line into separate paths for males and females (Figure 7). Each gender has its own line, distinguished by color. This allows for a direct comparison of stress levels between genders across age groups.\nKey questions to consider:\n\nGender Differences: Do males and females have similar or diverging patterns of stress across age groups?\nCrossovers: Do the lines for males and females intersect at any point, indicating shifts in which gender reports higher stress?\nParallel Trends: Are the lines generally parallel, suggesting consistent gender differences across age groups?\n\n\n\n\n\n\n\nFigure 7: Multi-line graph for age groups (agegp5) and tpstress grouped by sex\n\n\n\nIn general, both line graphs (simple and multi-line) are useful for identifying:\n\nPatterns in Stress Levels: Are there general trends across age groups?\nGroup Comparisons: How do males and females differ in perceived stress levels?\nActionable Insights: Insights from these graphs can inform targeted interventions or further analysis.\n\nBy examining the overall shape and relationship of the lines, you can derive meaningful conclusions about the data and identify areas for further exploration."
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-c4-scatterplots",
    "href": "lab-uofg-01/lab-uofg-01.html#step-c4-scatterplots",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "4.5 Step C4: Scatterplots",
    "text": "4.5 Step C4: Scatterplots\nScatterplots are essential for visualizing the relationship between two continuous variables. They help identify trends, correlations, and potential outliers. By adding categorical grouping and labeling points, scatterplots become even more informative, allowing for deeper insights into patterns within subgroups.\nIn this exercise, we create three scatterplots using the survey_data_full dataset:\n\nA simple scatterplot with tpstress as the dependent variable (y-axis) and tpcoiss as the independent variable (x-axis).\nA scatterplot with color-coded points based on sex (categorical grouping).\nThe same scatterplot as above, but with point labels based on the id variable.\n\n\n4.5.1 Simple Scatterplot\nThe first scatterplot shows the relationship between tpstress (perceived stress) and tpcoiss (control over internal states).\n# Simple scatterplot\nscatter_stress_control &lt;- ggplot(data = survey_data_full, aes(x = tpcoiss, y = tpstress)) +\n  geom_point(color = \"blue\", size = 2) +\n  labs(\n    title = \"Scatterplot of Perceived Stress vs Coping Strategies\",\n    x = \"Coping Strategies (tpcoiss)\",\n    y = \"Perceived Stress (tpstress)\"\n  ) +\n  theme_minimal()\n\n# Show plot\nscatter_stress_control\n\n# Save plot\nggsave(\"output/figures/scatter_stress_control.pdf\", width = 8, height = 5)\nExplanation of the Code\n\nggplot() specifies the dataset (survey_data_full) and maps tpcoiss to the x-axis and tpstress to the y-axis.\ngeom_point() adds scatterplot points. color = \"blue\" sets the color of all points. size = 2 adjusts the point size for better visibility.\nlabs() adds a title, x-axis label, and y-axis label for clarity.\ntheme_minimal() ensures a clean and professional appearance.\n\nInterpretation of the Graphs\nThe simple scatterplot shows the relationship between tpstress (perceived stress) and tpcoiss (coping strategies) across all participants.\nKey points to consider:\n\nDirection of the relationship:\n\nA positive trend (points sloping upward) suggests that higher coping strategies are associated with higher perceived stress.\nA negative trend (points sloping downward) suggests that higher coping strategies are associated with lower perceived stress.\nA flat trend (points scattered without a clear pattern) suggests no apparent relationship between the variables.\n\nStrength of the relationship:\n\nPoints clustered tightly along an imaginary line indicate a strong relationship.\nPoints scattered widely indicate a weaker relationship or greater variability.\n\nOutliers:\n\nPoints far from the general trend or clustering might indicate participants with unusual scores (e.g., very high stress despite low coping strategies).\n\n\nIf the scatterplot shows a positive trend, this could suggest that participants reporting higher coping strategies are experiencing higher levels of stress, which might reflect maladaptive coping mechanisms.\nADD FIGURE HERE\n\n\n4.5.2 Scatterplot with Categorical Grouping\nTo differentiate points by gender, we map the sex variable to the color aesthetic. This helps identify potential differences in the relationship between tpstress and tpcoiss for males and females.\n# Scatterplot with grouping by sex\nscatter_stress_control_gender &lt;- ggplot(data = survey_data_full, aes(x = tpcoiss, y = tpstress, color = sex)) +\n  geom_point(size = 2) +\n  labs(\n    title = \"Scatterplot of Perceived Stress vs Coping Strategies by Gender\",\n    x = \"Coping Strategies (tpcoiss)\",\n    y = \"Perceived Stress (tpstress)\",\n    color = \"Gender\"\n  ) +\n  theme_minimal()\n\n# Show plot\nscatter_stress_control_gender\n\n# Save plot\nggsave(\"output/figures/scatter_stress_control_gender.pdf\", width = 8, height = 5)\nExplanation of the Code\n\nggplot() specifies the dataset (survey_data_full) and maps tpcoiss to the x-axis and tpstress to the y-axis, color = sex assigns different colors to males and females.\ngeom_point() adds scatterplot points. color = \"blue\" sets the color of all points. size = 2 adjusts the point size for better visibility.\nlabs() adds a title, x-axis label, and y-axis label for clarity. color = \"Gender\" labels the legend as “Gender” for clarity.\ntheme_minimal() ensures a clean and professional appearance.\n\nInterpretation of the Graphs\nThe grouped scatterplot adds a layer of complexity by differentiating the points based on sex (males and females) using color coding. This allows for subgroup comparisons.\nKey points to consider:\n\nComparing trends between groups:\n\nLook for differences in the direction, strength, or spread of points for each group.\nParallel trends suggest that the relationship between tpstress and tpcoiss is consistent across genders.\nDiverging or crossing trends may indicate that the relationship differs between males and females.\n\nClustering patterns:\n\nAre males and females clustered in similar regions of the plot, or are they spread differently?\nFor example, one group may predominantly occupy the lower tpcoiss range while the other spans the full range.\n\nGroup-specific outliers:\n\nOutliers can be identified separately for each group, helping to explore whether certain groups have more extreme responses.\n\n\nIf males show a stronger positive trend compared to females, it might suggest gender differences in how coping strategies are related to perceived stress.\nADD FIGURE HERE\n\n\n4.5.3 Scatterplot with Point Labels\nAdding point labels based on the id variable allows us to identify individual data points in the scatterplot. This is similar to the “Point ID label” feature in SPSS.\n# Scatterplot with point labels\nscatter_stress_control_gender_id &lt;- ggplot(data = survey_data_full, aes(x = tpcoiss, y = tpstress, color = sex)) +\n  geom_point(size = 2) +\n  geom_text(aes(label = id), hjust = 0, vjust = -0.5, size = 3) +\n  labs(\n    title = \"Scatterplot of Perceived Stress vs Coping Strategies with Point Labels\",\n    x = \"Coping Strategies (tpcoiss)\",\n    y = \"Perceived Stress (tpstress)\",\n    color = \"Gender\"\n  ) +\n  theme_minimal()\n\n# Show plot\nscatter_stress_control_gender_id\n\n# Save plot\nggsave(\"output/figures/scatter_stress_control_gender_id.pdf\", width = 8, height = 5)\nExplanation of the Code (only difference to the previous code)\n\ngeom_text() adds labels to each point. aes(label = id) specifies that each point is labeled with the id variable. hjust = 0, vjust = -0.5 adjusts the position of the labels relative to the points. size = 3 sets the text size for readability.\nThe rest of the code is similar to the grouped scatterplot, with points color-coded by gender.\n\nInterpretation of the Graphs\nThe labeled scatterplot builds on the grouped scatterplot by adding participant identifiers (id) as point labels. This is useful for identifying specific data points and exploring individual-level patterns.\nKey points to consider:\n\nIdentifying specific participants:\n\nOutliers or points of interest can now be linked to specific participants using their id.\nFor example, if a participant shows very high tpstress despite low tpcoiss, their id can be used to investigate their survey responses further.\n\nLabel clustering:\n\nOverlapping labels can indicate regions with many participants sharing similar scores.\nSparse labels suggest regions with fewer participants, highlighting gaps in the data.\n\nPotential for follow-up:\n\nBy identifying participants with unusual scores, researchers can delve deeper into qualitative responses or additional variables to better understand these cases.\n\n\nIf a specific participant shows extreme stress levels (tpstress) with high coping strategies (tpcoiss), their behavior might warrant further investigation to understand coping efficacy or survey anomalies.\nADD FIGURE HERE"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-b5-cross-tabulations",
    "href": "lab-uofg-01/lab-uofg-01.html#step-b5-cross-tabulations",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "3.5 Step B5: Cross-Tabulations",
    "text": "3.5 Step B5: Cross-Tabulations\nIn this task, we first analyse the relationship between marital status (marital) and parental status (child). This provides insights into how having children is distributed across different marital statuses.\n# Create a cross-tabulation of Marital Status by Parental Status\nmarital_child_table &lt;- table(survey_data_full$marital, survey_data_full$child)\n\n# Print the cross-tabulation\nprint(marital_child_table)\nTo further analyze the table, we calculate proportions and percentages. These help interpret the relative distribution of parental status within each marital status group or across the entire sample.\n# Proportions for the entire table\nmarital_child_prop &lt;- prop.table(marital_child_table)\nprint(round(marital_child_prop * 100, 2))\n\n# Row-wise proportions (within marital status groups)\nmarital_child_row_prop &lt;- prop.table(marital_child_table, margin = 1)\nprint(round(marital_child_row_prop * 100, 2))\n\n# Column-wise proportions (within parental status groups)\nmarital_child_col_prop &lt;- prop.table(marital_child_table, margin = 2)\nprint(round(marital_child_col_prop * 100, 2))\nWe can also add marginal totals. Including row and column totals provides additional context for the distribution.\n# Add marginal totals to the table\nmarital_child_with_totals &lt;- addmargins(marital_child_table)\nprint(marital_child_with_totals)\nCross-tabulating marital and child provides a detailed view of the relationship between marital status and parental status. By combining raw counts and proportions, we can identify meaningful patterns in the data, supporting deeper insights into family composition and relationships.\nOver to you: use the code above as a blue print and analyse the relationship between other variables."
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html",
    "href": "lab-uofg-02/lab-uofg-02.html",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "",
    "text": "This lab is the same as the SPSS Lab 2 for MGT4018 and MGT4090. We use base R functions as the default. While there are many R packages available, understanding base R operations provides a strong foundation for data analysis.\n\n\n\n\n\n\nAlternatives using R packages\n\n\n\n\n\nAlternatives for achieving the same outcomes using different R packages are provided in green boxes. If you want to explore these alternatives, each box will introduce the respective package, how to install and use it, and the outputs it can produce."
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-a1-setup",
    "href": "lab-uofg-02/lab-uofg-02.html#step-a1-setup",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.1 Step A1: Setup",
    "text": "2.1 Step A1: Setup\nBefore starting any work in R, it is important to organize your files. This ensures that your scripts, datasets, and outputs are easy to manage and reproducible. Projects are strongly recommended for better organization and reproducibility, but setting a working directory is an alternative if needed (see also the respective section in 0. Getting Started).\n\n\n\n\n\n\nNote\n\n\n\nYou can either work through the following steps and copy/paste the respective code into the Lab_Exercise_A.R file that you will create in Step 1 or download the R script for Exercise A and follow the instructions below and save the downloaded file in the scripts folder that you will create.\n\n\n\n2.1.1 Option 1: Create a Project\nThe best way to organize your work is to create an RStudio project. This keeps all related files in a single folder. Follow these steps:\n\nOpen RStudio.\nGo to File &gt; New Project.\nSelect New Directory and then New Project.\nChoose a location on your computer and give the project a name, e.g., ResearchMethodsLab. Avoid spaces in folder and file names.\nClick Create Project. RStudio will open a new session within the project folder.\nIt is good practice to not have you files in this main folder, but create a set of subfolders similar to the following. Navigate to your project folder and create the following subfolders:\n\nResearchMethodsLab/\n├── data/\n├── scripts/\n├── output/\n│   ├── figures/\n│   └── tables/\n├── docs/\n└── Lab1.Rproj\n\nCreate a new R script: Go to File &gt; New File &gt; R Script.\nSave the script in your scripts folder with an appropriate name, e.g., Lab1_Exercise_A.R.\n\nNow you are ready to begin your work in R and continue with Step A2!\n\n\n2.1.2 Option 2: Set Working Directory Manually\nIf you are not using a project, you will need to set a working directory manually. The working directory is the folder where R looks for files and saves outputs.\n\nIn your Finder (Mac) or Explorer (Windows), create a new folder for the R Labs (e.g., ResearchMethodsLab) as well as the subfolder structure below. Avoid spaces in folder and file names.\n\nResearchMethodsLab/\n├── data/\n├── scripts/\n├── output/\n│   ├── figures/\n│   └── tables/\n└── docs/\n\nOpen RStudio.\nCreate a new R script: Go to File &gt; New File &gt; R Script.\nSave the script in the scripts folder that you previously created with an appropriate name, e.g., Lab_Exercise_A.R.\nSet the working directory in your script using the setwd() function. Copy the following code into your script, change the path to the older that you created, and execute the script.\n\nsetwd(\"path/to/your/folder\")\nYou can check whether the working directory is set to the folder that you want to by using the following code:\n# Display the current working directory\ngetwd()\nNow you are ready to begin your work in R and continue with Step A2!"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-a2-creating-or-loading-the-dataset",
    "href": "lab-uofg-02/lab-uofg-02.html#step-a2-creating-or-loading-the-dataset",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.2 Step A2: Creating or Loading the Dataset",
    "text": "2.2 Step A2: Creating or Loading the Dataset\nFor practice purposes, try both options so you familiarise yourself with creating and loading datasets in R.\n\n2.2.1 Option 1: Create your Dataset\nIn base R, we will create our vectors and combine them into a data frame. Use the following code to create your variables:\n# Create vectors for our data\nid &lt;- 1:30\n\n# Create age bands with labels\nage_bands &lt;- factor(\n  c(1,3,2,4,2,5,5,2,3,1,4,1,3,2,4,2,5,5,2,3,1,4,2,4,2,5,5,2,3,1),\n  levels = 1:5,\n  labels = c(\"&lt;21\", \"21-30\", \"31-40\", \"41-50\", \"&gt;50\")\n)\n\n# Create gender categories with labels\ngender &lt;- factor(\n  c(0,1,1,0,0,0,1,1,1,0,9,0,2,1,0,0,1,1,0,0,1,0,0,0,1,1,1,0,9,9),\n  levels = c(0,1,2,9),\n  labels = c(\"Male\", \"Female\", \"Other\", \"Prefer not to say\")\n)\n\n\n\n\n\n\nNote\n\n\n\nIn R, we use factor() to create categorical variables. This is similar to value labels in SPSS. The levels argument specifies the underlying codes, while labels provides the human-readable labels.\n\n\nWe now combine the variables that we created in the previous step into a data.frame.\n# Combine into a data frame\nsurvey_data &lt;- data.frame(\n  ID = id,\n  AgeBand = age_bands,\n  Gender = gender\n)\nYou can easily explore and check the basic structure of your data and get a summary:\n# View the first few rows using head()\nhead(survey_data)\n\n# Examine the structure\nstr(survey_data)\n\n# Get basic summary statistics\nsummary(survey_data)\nWhen working with data in R, saving and reloading data efficiently is crucial for reproducibility and sharing. Two common file formats for saving data in R are .csv files and .rds files. While both serve the purpose of persisting data for future use, they have distinct differences in terms of structure, use cases, and functionality.\nYou can use the following code to save your dataset in either format. In line with the best practice around folder structures, the code below works only if you created the data folder within your project folder or working directory. For this tutorial, save your output as a .csv file (without row names).\n# Save as R data file\nsaveRDS(survey_data, \"data/survey_data_export.rds\")\n\n# Save as .csv\nwrite.csv(survey_data, \"data/survey_data_export_rows.csv\")\n\n# By default, the data is exported with row names. Now to export data without row names we simply have to pass row.names=FALSE as an argument in the write.csv() function.\nwrite.csv(survey_data, \"data/survey_data_export.csv\", row.names=FALSE)\nA .csv file (comma-separated values) is a plain text format commonly used for storing tabular data. Each row in the file corresponds to a row in the dataset, and columns are separated by commas. In general, .csv files are platform-independent, widely supported by software like Excel, and easily shared or imported into other programming environments.\nAn .rds file is a native R binary format used to store a single R object. Unlike .csv, .rds files preserve all attributes and data types, including factors, column classes, and even more complex structures like lists, models, or custom objects. The table below outlines the main differences between saving a data frame in each format.\n\n\n\nKey differences between .csv and .rds diles\n\n\nFeature\nCSV\nRDS\n\n\n\n\nFormat\nPlain text\nBinary (R-specific)\n\n\nPortability\nCross-platform and software-independent\nR-specific\n\n\nMetadata\nDoes not retain R-specific attributes\nRetains all R-specific attributes\n\n\nComplex objects\nSupports tabular data only\nSupports any R object\n\n\nHuman-readable\nYes\nNo\n\n\nEfficiency\nSlower for large datasets\nFaster and more compact\n\n\nUse case\nSharing data with non-R users or if the data will be processed in other tools like Excel or Python\nStoring and reloading your data with all its R-specific features, particularly suitable for storing large datasets or complex objects that need to be efficiently loaded\n\n\n\n\n\n\n\n\n\n2.2.2 Option 2: Load your Dataset\nAs an alternative to creating your own dataset, you can download the dataset. Copy this file into your data folder and then run the following code:\n# Load the CSV file stored in the \"data\" folder\nsurvey_data &lt;- read.csv(\"data/lab1-exercise-a.csv\")\nYou can easily explore and check the basic structure of your data and get a summary:\n# View the first few rows using head()\nhead(survey_data)\n\n# Examine the structure\nstr(survey_data)\n\n# Get basic summary statistics\nsummary(survey_data)\nThe imported dataset contain only the numerical values. We will use factor() again transform this into categorical variables with levels specifying the underlying codes and labels providing the human-readable labels.\n# Assign labels for \"AgeBand\"\nsurvey_data$AgeBand &lt;- factor(\n  survey_data$AgeBand,\n  levels = c(1, 2, 3, 4, 5),\n  labels = c(\"&lt;21\", \"21-30\", \"31-40\", \"41-50\", \"&gt;50\")\n)\n\n# Assign labels for \"Gender\"\nsurvey_data$Gender &lt;- factor(\n  survey_data$Gender,\n  levels = c(0,1,2,9),\n  labels = c(\"Male\", \"Female\", \"Other\", \"Prefer not to say\")\n)"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-a3-modifying-your-dataset",
    "href": "lab-uofg-02/lab-uofg-02.html#step-a3-modifying-your-dataset",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.3 Step A3: Modifying your Dataset",
    "text": "2.3 Step A3: Modifying your Dataset\n\n\n\n\n\n\nNote\n\n\n\nThis step is not needed, the dataset that you created with the code (Step A2, option 1) or downloaded (Step A2, option 2) are already correct, but have a look and get an overview of what you can do with R.\nWe create a copy of the data frame that we use for the remainder of the lab. Please run the following code before experimenting with possible modifications:\nsurvey_data_copy &lt;- survey_data\n\n\nData frames are among the most commonly used data structures in R, especially for storing and analyzing tabular data. Once a data frame is loaded or created, it is often necessary to modify it to suit specific analytical needs. Common modifications include editing specific values, adding or removing columns and rows, and renaming variables. These operations can be performed efficiently using base R, without the need for additional packages. Understanding these basic techniques is essential for working effectively with data in R.\n\n2.3.1 Editing Specific Values\nYou can directly access and modify specific elements of a data frame using indexing with square brackets [ , ]. The format is data[row, column], where you specify the row and column to edit. You can also use column names for clarity.\n# Edit the Gender of the participant with ID 15\nsurvey_data_copy[survey_data_copy$ID == 15, \"Gender\"] &lt;- \"Female\"\nprint(survey_data_copy[survey_data_copy$ID == 15, ])\nHere, the gender for the participant with ID 15 is updated to “Female.”\n\n\n2.3.2 Adding a Column\nTo add a new column to a data frame, use the $ operator or specify the new column name within square brackets.\n# Add a new column indicating if the participant is above 30 based on AgeBand\nsurvey_data_copy$Above30 &lt;- survey_data_copy$AgeBand %in% c(\"31-40\", \"41-50\", \"&gt;50\")\nprint(head(survey_data_copy))\nThis new column indicates whether each participant belongs to an age group over 30.\n\n\n2.3.3 Adding a Row\nTo append a new row, use the rbind() function, which binds rows together.\n# Add a new participant to the data frame\nnew_row &lt;- data.frame(ID = 31, AgeBand = \"&lt;21\", Gender = \"Other\", Above30 = FALSE)\nsurvey_data_copy &lt;- rbind(survey_data_copy, new_row)\nprint(tail(survey_data_copy))\n\n\n2.3.4 Removing a Column\nYou can remove a column by setting it to NULL or by subsetting the data frame without that column.\n# Remove the \"Above30\" column\nsurvey_data_copy$Above30 &lt;- NULL\nprint(head(survey_data_copy))\n\n\n2.3.5 Removing a Row\nTo remove a row, subset the data frame, excluding the unwanted row.\n# Remove the row where ID is 10\nsurvey_data_copy &lt;- survey_data_copy[survey_data_copy$ID != 10, ]\nprint(head(survey_data_copy))\n\n\n2.3.6 Renaming Columns\nRenaming columns can be done by directly modifying the names() of the data frame.\n# Rename columns\nnames(survey_data_copy) &lt;- c(\"ParticipantID\", \"AgeGroup\", \"GenderIdentity\")\nprint(head(survey_data_copy))\n\n\n2.3.7 Combining Data Frames\nYou can merge two data frames using merge() to combine them based on a common column.\n# Create another data frame with additional information\nadditional_data &lt;- data.frame(\n  ParticipantID = c(1, 2, 3, 4, 5),\n  CompletedSurvey = c(TRUE, TRUE, FALSE, TRUE, FALSE)\n)\n\n# Merge data frames by the \"ParticipantID\" column\nsurvey_data_copy &lt;- merge(survey_data_copy, additional_data, by = \"ParticipantID\", all.x = TRUE)\nprint(head(survey_data_copy))\n\n\n2.3.8 Summary\nThese are some of the most common operations for modifying data frames in base R. Mastering these techniques will allow you to efficiently manipulate data frames and tailor them to your analytical needs:\n\nEdit specific values: Modify elements using data[row, column].\nAdd a column: Use $ or square brackets.\nAdd a row: Use rbind().\nRemove a column: Set it to NULL or subset the data frame.\nRemove a row: Subset the data frame excluding the row.\nRename columns: Modify names() directly.\nCombine data frames: Use merge()."
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-a4-frequency-tables-summary-statistics",
    "href": "lab-uofg-02/lab-uofg-02.html#step-a4-frequency-tables-summary-statistics",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.4 Step A4: Frequency Tables (Summary Statistics)",
    "text": "2.4 Step A4: Frequency Tables (Summary Statistics)\nFrequency tables are a fundamental tool in data analysis for summarizing and understanding the distribution of categorical variables. They show how often each category appears in a dataset, helping analysts quickly grasp patterns and trends. In business research, frequency tables are commonly used to analyze survey results, customer demographics, or product categories. In R, base functions like table() and prop.table() provide a straightforward way to create and analyze frequency tables.\nThis guide introduces frequency tables using the survey_data data frame and demonstrates their creation and interpretation.\n\n2.4.1 When and Why to Use Frequency Tables\nFrequency tables are particularly useful when:\n\nYou need to summarize categorical data (e.g., age groups, gender, product categories).\nYou want to identify dominant categories or patterns in responses.\nYou need a quick check for data quality (e.g., missing values or unexpected categories).\nYou are preparing data for visualization or further statistical analysis.\n\nBy condensing raw data into an easy-to-read format, frequency tables simplify decision-making and analysis.\n\n\n2.4.2 Creating a Basic Frequency Table\nThe table() function in R generates frequency counts for one or more variables. For example, to count the number of participants in each age bandn and for each gender:\n# Frequency table for AgeBand\nage_band_freq &lt;- table(survey_data$AgeBand)\n\n# Frequency table for Gender\ngender_freq &lt;- table(survey_data$Gender)\n\n# Display the results\nprint(\"Frequency table for AgeBand:\")\nprint(age_band_freq)\nprint(\"Frequency table for Gender:\")\nprint(gender_freq)\nThis table displays the count of participants in each age group.\n\n\n2.4.3 Adding Proportions\nProportions show the relative frequency of each category as a percentage of the total. Use the prop.table() function to calculate proportions from a frequency table:\n# Proportions for AgeBand\nage_band_prop &lt;- prop.table(age_band_freq)\nprint(age_band_prop)\nThe output shows the proportion of participants in each age group. To display percentages, multiply by 100:\n# Proportions as percentages\nage_band_percent &lt;- round(prop.table(age_band_freq) * 100, 2)\nprint(age_band_percent)\nThis provides a clear picture of the distribution of age groups as percentages. You can also combine the basic frequency table with the proportions and print the combined results:\n# Frequency table for AgeBand\nage_band_freq &lt;- table(survey_data$AgeBand)\n# Proportions as percentages for AgeBand\nage_band_percent &lt;- round(prop.table(age_band_freq) * 100, 2)\n\n# Combine frequencies and percentages\nage_summary &lt;- cbind(\n  Frequency = age_band_freq,\n  Percentage = age_band_percent\n)\n\n# Display the results\nprint(\"AgeBand Distribution:\")\nprint(age_summary)\n\n\n2.4.4 Summary Statistics for Frequency Tables\nOnce you have created a frequency table, you might want to extract specific insights:\n\nMode: The category with the highest frequency.\nRare categories: Categories with very low frequencies.\n\n# Find the most frequent AgeBand\nmost_frequent_age_band &lt;- names(age_band_freq[which.max(age_band_freq)])\nprint(paste(\"Most frequent age band:\", most_frequent_age_band))\n\n# Identify rare categories (frequency &lt;= 2)\nrare_categories &lt;- names(age_band_freq[age_band_freq &lt;= 2])\nprint(paste(\"Rare categories:\", paste(rare_categories, collapse = \", \")))\n\n\n2.4.5 Handling Missing or Unexpected Values\nFrequency tables are also useful for spotting missing or unexpected values. For instance:\n# Check for missing or unusual values in Gender\ngender_freq &lt;- table(survey_data$Gender, useNA = \"ifany\")\nprint(gender_freq)\nThe useNA argument ensures that missing values (if any) are included in the table."
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-a5-cross-tabulation",
    "href": "lab-uofg-02/lab-uofg-02.html#step-a5-cross-tabulation",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.5 Step A5: Cross-Tabulation",
    "text": "2.5 Step A5: Cross-Tabulation\nCross-tabulations, also known as contingency tables, are a powerful tool in data analysis for examining the relationship between two or more categorical variables. They provide a matrix of frequency counts that show how categories of one variable are distributed across categories of another. Cross-tabulations are widely used in business analytics, such as comparing demographics (e.g., age and gender) or tracking customer behavior across segments.\nThis guide delves deeper into cross-tabulations using the survey_data data frame, illustrating how to create, interpret, and enhance these tables with additional insights.\n\n2.5.1 When and Why to Use Cross Tabulations\nCross-tabulations are particularly useful when:\n\nYou want to compare distributions of one variable across levels of another.\nYou need to detect patterns or relationships between categorical variables.\nYou aim to summarize multivariate data for clear communication and decision-making.\nYou are preparing data for visualization (e.g., stacked bar charts or heatmaps).\n\nFor example, in a survey analysis, you might want to compare how age groups are distributed by gender.\n\n\n2.5.2 Creating a Cross Tabulation\nIn R, the table() function is used to create cross-tabulations. For example, to examine the distribution of participants by AgeBand and Gender:\n# Create a cross-tabulation of AgeBand and Gender\nage_gender_table &lt;- table(survey_data$AgeBand, survey_data$Gender)\nprint(age_gender_table)\nThe resulting table displays the frequency counts for each combination of AgeBand and Gender. For instance:\n\nThe value at the intersection of &lt;21 and Male represents the number of participants who are under 21 and identify as male.\nThe totals for each row or column provide marginal counts (see Marginal Totals below).\n\n\n\n2.5.3 Adding Proportions to Cross Tabulations\nFrequency counts can be converted to proportions to better understand relative distributions. The prop.table() function is used for this purpose.\nProportions for the Entire Table\n# Proportions for the entire table\nage_gender_prop &lt;- prop.table(age_gender_table)\nprint(round(age_gender_prop * 100, 2))\nHere, each value represents the percentage of the total participants in that specific category combination.\nRow-Wise Proportions\nTo see proportions within each row (e.g., the percentage of each gender within an age band):\n# Row-wise proportions\nrow_prop &lt;- prop.table(age_gender_table, margin = 1)\nprint(round(row_prop * 100, 2))\nThis output helps answer questions like, “What percentage of individuals in the 31-40 age group identify as Female?”\nColumn-Wise Proportions\nTo see proportions within each column (e.g., the percentage of each age band within a gender):\n# Column-wise proportions\ncol_prop &lt;- prop.table(age_gender_table, margin = 2)\nprint(round(col_prop * 100, 2))\nThis output helps answer questions like, “What percentage of individuals identifying as Male are in the 41-50 age band?”\n\n\n2.5.4 Marginal Totals\nAdding row and column totals to a cross-tabulation provides a comprehensive overview of the data. Use the addmargins() function to include these totals:\n# Add row and column totals to the table\nage_gender_with_totals &lt;- addmargins(age_gender_table)\nprint(age_gender_with_totals)\nThe row totals show the distribution of participants across age bands, while the column totals display the distribution across gender categories.\n\n\n2.5.5 Customizing Cross Tabulation Output\nFor clearer interpretation, you can customize the table’s appearance using descriptive labels for rows and columns. Use dimnames() to update labels:\n# Customize row and column names\ndimnames(age_gender_table) &lt;- list(\n  AgeGroup = levels(survey_data$AgeBand),\n  GenderCategory = levels(survey_data$Gender)\n)\nprint(age_gender_table)\n\n\n2.5.6 Detecting Relationships in Cross Tabulations\nCross-tabulations provide a foundation for detecting relationships between variables. While frequency counts and proportions are descriptive, statistical tests such as the Chi-Square Test can quantify the association between variables.\n# Perform a Chi-Square Test of Independence\nchi_test &lt;- chisq.test(age_gender_table)\nprint(chi_test)\nThe test evaluates whether there is a significant association between AgeBand and Gender. A p-value less than 0.05 suggests that the relationship is statistically significant.\nNote: R might show a warning Chi-squared approximation may be incorrect, which indicates that the conditions for the Chi-Square test’s validity may not be fully met. Specifically, the test assumes that expected frequencies in each cell of the contingency table are sufficiently large. Typically, the rule of thumb is that each expected cell frequency should be at least 5. You can check the expected frequencies by using the expected attribute of the test result:\n# View the expected frequencies\nchi_test$expected\n\n\n2.5.7 Summary\nCross-tabulations are a versatile tool for analyzing the relationship between categorical variables. Mastering cross-tabulations equips you with the ability to summarize and interpret categorical data effectively, a crucial skill in business research and data analysis. In R, you can:\n\nUse table() to create cross-tabulations.\nAdd proportions with prop.table() for a deeper understanding of relative distributions.\nInclude totals with addmargins() for a complete summary.\nCustomize, export, or extend your analysis with statistical tests."
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-a6-saving-frequency-tables-and-cross-tabulations",
    "href": "lab-uofg-02/lab-uofg-02.html#step-a6-saving-frequency-tables-and-cross-tabulations",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "2.6 Step A6: Saving Frequency Tables and Cross-Tabulations",
    "text": "2.6 Step A6: Saving Frequency Tables and Cross-Tabulations\nWhen analyzing data, frequency tables and cross-tabulations provide valuable insights into categorical variables and their relationships. To share or store these tables for reporting or further analysis, you can save them as CSV files or directly export them in a human-readable format. This guide demonstrates both methods, using survey_data for examples.\n\n2.6.1 Saving Frequency Tables\nFrequency tables summarize the distribution of a single categorical variable, and you can save them as a CSV file or export them as plain text.\nSaving as a CSV File\nTo save a frequency table as a CSV file, first convert it into a data frame using as.data.frame():\n# Create a frequency table for AgeBand\nage_band_freq &lt;- table(survey_data$AgeBand)\n\n# Convert the frequency table to a data frame\nage_band_df &lt;- as.data.frame(age_band_freq)\n\n# Save the data frame to a CSV file\nwrite.csv(age_band_df, \"output/tables/age_band_frequency.csv\", row.names = FALSE)\nThis saves the frequency table as a CSV file named age_band_frequency.csv. Each row in the CSV represents a category and its corresponding frequency.\nExporting to Plain Text\nFor a more human-readable format, you can save the table directly as plain text using capture.output():\n# Export the frequency table to a text file\ncapture.output(age_band_freq, file = \"output/tables/age_band_frequency.txt\")\nThe output file, age_band_frequency.txt, contains the frequency table as it appears in the R console.\n\n\n2.6.2 Saving Cross-Tabulations\nCross-tabulations summarize relationships between two categorical variables. Saving them involves similar steps to frequency tables, with additional considerations for row and column labels.\nSaving as a CSV File\nLike frequency tables, cross-tabulations can be converted into a data frame for CSV export:\n# Create a cross-tabulation of AgeBand and Gender\nage_gender_table &lt;- table(survey_data$AgeBand, survey_data$Gender)\n\n# Convert the cross-tabulation to a data frame\nage_gender_df &lt;- as.data.frame(age_gender_table)\n\n# Save the cross-tabulation to a CSV file\nwrite.csv(age_gender_df, \"output/tables/age_gender_cross_tabulation.csv\", row.names = FALSE)\nThis saves the cross-tabulation as a CSV file named age_gender_cross_tabulation.csv. Each row in the CSV represents a unique combination of AgeBand and Gender, along with its frequency.\nExporting to Plain Text\nTo save a formatted version of the cross-tabulation, use capture.output():\n# Export the cross-tabulation to a text file\ncapture.output(age_gender_table, file = \"output/tables/age_gender_cross_tabulation.txt\")\nThe file age_gender_cross_tabulation.txt will display the table as it appears in the R console, retaining its tabular structure.\nAdding Totals Before Export\nAdding marginal totals to cross-tabulations can make them more informative before saving:\n# Add row and column totals\nage_gender_with_totals &lt;- addmargins(age_gender_table)\n\n# Save the table with totals as plain text\ncapture.output(age_gender_with_totals, file = \"output/tables/age_gender_with_totals.txt\")\nThis ensures that row and column totals are included in the exported table for comprehensive analysis.\n\n\n2.6.3 Saving Proportions\nProportions provide additional insights and can be saved in the same way as frequency counts. For example:\n# Calculate proportions for AgeBand\nage_band_prop &lt;- prop.table(age_band_freq)\n\n# Convert to a data frame and save as CSV\nage_band_prop_df &lt;- as.data.frame(age_band_prop)\nwrite.csv(age_band_prop_df, \"output/tables/age_band_proportions.csv\", row.names = FALSE)\nSimilarly, cross-tabulation proportions can be saved:\n# Calculate proportions for the cross-tabulation\nage_gender_prop &lt;- prop.table(age_gender_table)\n\n# Convert to a data frame and save as CSV\nage_gender_prop_df &lt;- as.data.frame(age_gender_prop)\nwrite.csv(age_gender_prop_df, \"output/tables/age_gender_proportions.csv\", row.names = FALSE)\n\n\n2.6.4 Summary\nTo save frequency tables and cross-tabulations for reporting or analysis:\n\nAs CSV files: Use as.data.frame() and write.csv() to export structured data.\nAs plain text: Use capture.output() for human-readable formats.\nWith proportions: Save proportions using similar methods to enhance insights.\nWith totals: Add marginal totals before exporting for a complete overview.\n\nThese techniques ensure your tables are accessible for external use, whether for sharing with colleagues, integrating into reports, or storing for reproducibility.\n\n\n\n\n\n\nBeautiful, customizable tables with export options with gt\n\n\n\n\n\nThe gt package is a powerful tool for creating beautiful, publication-quality tables directly in R. It provides an intuitive and flexible workflow for generating summary tables, including frequency tables and cross-tabulations, with advanced formatting options for customization. The gt package is particularly well-suited for reports, presentations, and dashboards.\nCreating and Saving Cross-Tabulation\n# Install package\ninstall.packages(\"gt\")\n\n# Load janitor package\nlibrary(gt)\n\n# Create a cross-tabulation\nage_gender_table &lt;- table(survey_data$AgeBand, survey_data$Gender)\n\n# Convert the table to a data frame\nage_gender_df &lt;- as.data.frame(age_gender_table)\n\n# Create a gt table\ngt_table &lt;- gt(data = age_gender_df) %&gt;%\n  tab_header(\n    title = \"Cross-Tabulation of Age Band and Gender\",\n    subtitle = \"Frequency Distribution\"\n  ) %&gt;%\n  cols_label(\n    Var1 = \"Age Band\",\n    Var2 = \"Gender\",\n    Freq = \"Count\"\n  ) %&gt;%\n  fmt_number(\n    columns = vars(Freq),\n    decimals = 0\n  ) %&gt;%\n  tab_source_note(\n    source_note = \"Data Source: Survey Data\"\n  )\n\n# Save the table as an HTML file\ngtsave(gt_table, filename = \"output/tables/age_gender_cross_tabulation.html\")\nAdvantages:\n\nGenerating publication-ready tables with advanced customization.\nProducing interactive HTML tables for dashboards or web-based reports.\n\n\n\n\n\n\n\n\n\n\nCleaning and Tabulating Data with janitor\n\n\n\n\n\nThe janitor package offers functions like tabyl() for creating frequency tables and cross-tabulations, with options to directly save them as data frames for further analysis or export.\nCreating and Saving Frequency Tables\n# Install package\ninstall.packages(\"janitor\")\n\n# Load janitor package\nlibrary(janitor)\n\n# Frequency table for AgeBand\nage_band_freq &lt;- survey_data %&gt;%\n  tabyl(AgeBand)\n\n# Save as CSV\nwrite.csv(age_band_freq, \"output/tables/age_band_frequency.csv\", row.names = FALSE)\nCreating and Saving Cross-Tabulation\n# Make sure that the package is installed and loaded\n\n# Cross-tabulation of AgeBand and Gender\nage_gender_table &lt;- survey_data %&gt;%\n  tabyl(AgeBand, Gender)\n\n# Save as CSV\nwrite.csv(age_gender_table, \"output/tables/age_gender_cross_tabulation.csv\", row.names = FALSE)\nAdvantages:\n\nAutomatically includes proportions and percentages in the output.\nProvides a clean and readable tabular output.\n\n\n\n\n\n\n\n\n\n\nPublication-Ready Tables with gtsummary\n\n\n\n\n\nThe gtsummary package is great for creating cross-tabulations with enhanced formatting and export options.\nCreating and Saving Cross-Tabulation\n# Install package\ninstall.packages(\"gtsummary\")\n\n# Load package\nlibrary(gtsummary)\n\n# Create a cross-tabulation table\nage_gender_table &lt;- survey_data %&gt;%\n  tbl_cross(\n    row = AgeBand,\n    col = Gender\n  )\n\n# Save as a CSV or Word document\nas_gt(age_gender_table) %&gt;%\n  gtsave(\"output/tables/age_gender_cross_tabulation.html\")\nAdvantages:\n\nProduces beautifully formatted tables.\nSupports export to multiple formats (e.g., HTML, Word, PDF).\n\n\n\n\n\n\n\n\n\n\nCustomizable Table Formatting with flextable\n\n\n\n\n\nThe flextable package is ideal for customizing tables for reports and presentations such as Word/PowerPoint outputs.\nFormatting and Saving a Cross-Tabulation\n# Install package\ninstall.packages(\"flextable\")\n\n# Load package\nlibrary(flextable)\n\n# Convert a cross-tabulation to a flextable\nage_gender_table &lt;- table(survey_data$AgeBand, survey_data$Gender) %&gt;%\n  as.data.frame()\n\nft &lt;- flextable(age_gender_table)\n\n# Save as Word document\nsave_as_docx(ft, path = \"output/tables/age_gender_cross_tabulation.docx\")\nsave_as_pptx(ft, path = \"output/tables/age_gender_cross_tabulation.pptx\")\nsave_as_image(ft, path = \"output/tables/age_gender_cross_tabulation.png\")\nAdvantages:\n\nHighly customizable appearance.\nExport to Word, PowerPoint, or HTML formats."
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-b1-setup",
    "href": "lab-uofg-02/lab-uofg-02.html#step-b1-setup",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "3.1 Step B1: Setup",
    "text": "3.1 Step B1: Setup\nYou can continue working with the same project or working directory (depending on which option you chose in Step A1). To get started with this exercise, please do the following:\n\nPlease download the dataset and save it in the data folder within your project folder or working directory .\nCreate a new R script: Go to File &gt; New File &gt; R Script.\nSave the script in the scripts folder within your project folder or working directory with an appropriate name, e.g., Lab1_Exercise_B_C.R. (Note: For simplicity, we combine Exercises B and C into one script as they are based on the same data, but you can also create separate scripts for each exercise.)\n\n\n\n\n\n\n\nNote\n\n\n\nYou can either work through the following steps and copy/paste the respective code into the Lab_Exercise_B_C.R file that you created or download the R script for Exercises B and C, save the downloaded file in the scripts folder, and run the respective code snippets according to the instructions below."
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-b2-loading-the-data",
    "href": "lab-uofg-02/lab-uofg-02.html#step-b2-loading-the-data",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "3.2 Step B2: Loading the Data",
    "text": "3.2 Step B2: Loading the Data\nCopy the code below into the Lab_Exercise_B.R script and run it:\n# Load the CSV file stored in the \"data\" folder\nsurvey_data_full &lt;- read.csv(\"data/lab1-survey.csv\")\nYou can easily explore and check the basic structure of your data and get a summary:\n# View the first few rows using head()\nhead(survey_data_full)\n\n# Examine the structure\nstr(survey_data_full)\n\n# Get basic summary statistics\nsummary(survey_data_full)\nBefore moving on to the analysis, we want to take a look at demographic variables. Demographic variables are fundamental in empirical research as they capture key characteristics of individuals or populations, such as age, gender, marital status, education level, and socioeconomic background. These variables provide essential context for understanding behaviors, preferences, and outcomes, allowing researchers to analyze patterns, identify trends, and draw meaningful comparisons across groups. In business and social science research, demographic variables are often used to segment data, control for confounding factors, and explore relationships between characteristics and dependent variables. Their inclusion ensures a more comprehensive and nuanced understanding of research findings, enabling the development of targeted strategies and policies.\nWe want to assign labels to the demographic variables in the survey_data_full data frame using factors with labeled levels. This method ensures the data remains categorical but with human-readable labels for easier interpretation and analysis.\n# Convert demographic variables to factors with labeled levels\n\n# Assign labels for \"sex\"\nsurvey_data_full$sex &lt;- factor(\n  survey_data_full$sex,\n  levels = c(1, 2),\n  labels = c(\"Male\", \"Female\")\n)\n\n# Assign labels for \"marital\"\nsurvey_data_full$marital &lt;- factor(\n  survey_data_full$marital,\n  levels = c(1, 2, 3, 4, 5, 6, 7, 8),\n  labels = c(\n    \"Single\", \"Steady relationship\", \"Living with partner\",\n    \"Married first time\", \"Remarried\", \"Separated\",\n    \"Divorced\", \"Widowed\"\n  )\n)\n\n# Assign labels for \"child\"\nsurvey_data_full$child &lt;- factor(\n  survey_data_full$child,\n  levels = c(1, 2),\n  labels = c(\"Yes\", \"No\")\n)\n\n# Assign labels for \"educ\"\nsurvey_data_full$educ &lt;- factor(\n  survey_data_full$educ,\n  levels = c(1, 2, 3, 4, 5, 6),\n  labels = c(\n    \"Primary\", \"Some secondary\", \"Completed high school\",\n    \"Some additional training\", \"Completed undergraduate\",\n    \"Postgraduate completed\"\n  )\n)\n\n# Assign labels for \"source\"\nsurvey_data_full$source &lt;- factor(\n  survey_data_full$source,\n  levels = c(1, 2, 3, 4, 5, 6, 7, 8, 9),\n  labels = c(\n    \"Work\", \"Spouse or partner\", \"Relationships\", \"Children\",\n    \"Family\", \"Health/illness\", \"Life in general\",\n    \"Money/finances\", \"Lack of time, too much to do\"\n  )\n)\n\n# Assign labels for \"smoke\"\nsurvey_data_full$smoke &lt;- factor(\n  survey_data_full$smoke,\n  levels = c(1, 2),\n  labels = c(\"Yes\", \"No\")\n)\nThe summary() function can be used to confirm that the labels have been applied correctly to the variables.\n# Verify changes by printing a summary\nsummary(survey_data_full)"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-b3-exploring-your-data",
    "href": "lab-uofg-02/lab-uofg-02.html#step-b3-exploring-your-data",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "3.3 Step B3: Exploring your Data",
    "text": "3.3 Step B3: Exploring your Data\nExploring the frequencies of demographic variables is a fundamental step in descriptive analysis, offering a clear understanding of the sample composition. By combining table() and prop.table(), we can compute both raw counts and relative proportions, providing a detailed overview of variables like gender, marital status, and education. These insights form the foundation for deeper analyses, such as segmentation or hypothesis testing, ensuring a strong start to any empirical research.\nGender (sex)\nThe sex variable captures the gender distribution of the sample. To compute and display the frequency table:\n# Frequency table for Gender\ngender_freq &lt;- table(survey_data_full$sex)\nprint(gender_freq)\n\n# Proportions and percentages\ngender_prop &lt;- prop.table(gender_freq)\ngender_percent &lt;- round(gender_prop * 100, 2)\nprint(gender_percent)\nThis output shows the count and percentage of participants who identify as Male or Female.\nMarital Status (marital)\nThe marital variable indicates the participants’ marital status. To compute and display the frequency table:\n# Frequency table for Marital Status\nmarital_freq &lt;- table(survey_data_full$marital)\nprint(marital_freq)\n\n# Proportions and percentages\nmarital_prop &lt;- prop.table(marital_freq)\nmarital_percent &lt;- round(marital_prop * 100, 2)\nprint(marital_percent)\nThis analysis highlights the most common marital statuses in the sample, such as Single or Married first time.\nParental Status (child)\nThe child variable records whether participants have children. Frequency analysis provides an overview of parental distribution:\n# Frequency table for Parental Status\nchild_freq &lt;- table(survey_data_full$child)\nprint(child_freq)\n\n# Proportions and percentages\nchild_prop &lt;- prop.table(child_freq)\nchild_percent &lt;- round(child_prop * 100, 2)\nprint(child_percent)\nThis reveals the proportion of participants who have children versus those who do not.\nEducation Level (educ)\nThe educ variable reflects participants’ highest level of education. To understand the distribution:\n# Frequency table for Education Level\neduc_freq &lt;- table(survey_data_full$educ)\nprint(educ_freq)\n\n# Proportions and percentages\neduc_prop &lt;- prop.table(educ_freq)\neduc_percent &lt;- round(educ_prop * 100, 2)\nprint(educ_percent)\nThis breakdown identifies the most common educational backgrounds, such as Completed undergraduate or Postgraduate completed.\nPrimary Source of Stress (source)\nThe source variable represents participants’ reported primary source of stress. Analyse the distribution as follows:\n# Frequency table for Primary Source of Stress\nsource_freq &lt;- table(survey_data_full$source)\nprint(source_freq)\n\n# Proportions and percentages\nsource_prop &lt;- prop.table(source_freq)\nsource_percent &lt;- round(source_prop * 100, 2)\nprint(source_percent)\nThis provides insights into stress sources, such as Work, Family, or Lack of time.\nSmoking Status (smoke)\nThe smoke variable indicates participants’ smoking habits. Use the following code to analyze:\n# Frequency table for Smoking Status\nsmoke_freq &lt;- table(survey_data_full$smoke)\nprint(smoke_freq)\n\n# Proportions and percentages\nsmoke_prop &lt;- prop.table(smoke_freq)\nsmoke_percent &lt;- round(smoke_prop * 100, 2)\nprint(smoke_percent)\nThis reveals the proportion of participants who smoke versus those who do not.\nSummarising Frequencies\nTo summarise all frequency tables and proportions in a single view, you can use a structured approach like the code below. This produces a consolidated view of the frequencies and percentages for all demographic variables, making it easier to compare distributions. (Note: This requires that you created the individual frequencies and percentages for all variables previously.)\n# Combine frequency tables into a list for easy viewing\nfrequency_summary &lt;- list(\n  Gender = list(Count = gender_freq, Percent = gender_percent),\n  MaritalStatus = list(Count = marital_freq, Percent = marital_percent),\n  ParentalStatus = list(Count = child_freq, Percent = child_percent),\n  EducationLevel = list(Count = educ_freq, Percent = educ_percent),\n  StressSource = list(Count = source_freq, Percent = source_percent),\n  SmokingStatus = list(Count = smoke_freq, Percent = smoke_percent)\n)\n\n# Print the summary\nprint(frequency_summary)"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-b4-exploring-participants-age",
    "href": "lab-uofg-02/lab-uofg-02.html#step-b4-exploring-participants-age",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "3.4 Step B4: Exploring Participants’ Age",
    "text": "3.4 Step B4: Exploring Participants’ Age\nFrequencies are a powerful tool for summarizing categorical variables, but they are less meaningful for continuous or numeric variables like age. In a dataset, age values can range widely, and each unique value may appear only once or a few times, leading to sparse and uninformative frequency tables. For example, a table showing the frequency of exact ages (e.g., 23, 24, 25) provides limited insight into age distribution because it does not group participants into broader, interpretable categories. Instead, grouping numeric variables into ranges (bands) transforms continuous data into an ordinal variable, making frequencies more meaningful and enabling comparisons across age groups.\nTo better analyze and summarize age-related data, we can create a new variable called AgeBand that groups ages into meaningful ranges. Here, we will define six age bands: - &lt;21, 21-30, 31-40, 41-50, 51-60, and &gt;60.\nThe new variable will be ordinal, meaning the age bands have a natural order, which is useful for analysis and visualization.\n# Creating an AgeBand variable\nsurvey_data_full$AgeBand &lt;- cut(\n  survey_data_full$age, \n  breaks = c(-Inf, 20, 30, 40, 50, 60, Inf), \n  labels = c(\"&lt;21\", \"21-30\", \"31-40\", \"41-50\", \"51-60\", \"&gt;60\"), \n  right = TRUE\n)\n\n# Verify the new AgeBand variable\n\n# Frequency table for AgeBand\nAgeBand_freq &lt;- table(survey_data_full$AgeBand)\nprint(AgeBand_freq)\n\n# Percentages for AgeBand\nAgeBand_prop &lt;- prop.table(AgeBand_freq)\nAgeBand_percent &lt;- round(AgeBand_prop * 100, 2)\nprint(AgeBand_percent)\nThe code above includes some new fucntions, which are explained below:\n\ncut(): Converts the numeric age variable into an ordinal factor.\nbreaks: Specifies the boundaries for the age bands. -Inf and Inf ensure all ages are included.\nlabels: Assigns descriptive names to each age band."
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-b5-cross-tabulations",
    "href": "lab-uofg-02/lab-uofg-02.html#step-b5-cross-tabulations",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "3.5 Step B5: Cross-Tabulations",
    "text": "3.5 Step B5: Cross-Tabulations\nIn this task, we first analyse the relationship between marital status (marital) and parental status (child). This provides insights into how having children is distributed across different marital statuses.\n# Create a cross-tabulation of Marital Status by Parental Status\nmarital_child_table &lt;- table(survey_data_full$marital, survey_data_full$child)\n\n# Print the cross-tabulation\nprint(marital_child_table)\nTo further analyze the table, we calculate proportions and percentages. These help interpret the relative distribution of parental status within each marital status group or across the entire sample.\n# Proportions for the entire table\nmarital_child_prop &lt;- prop.table(marital_child_table)\nprint(round(marital_child_prop * 100, 2))\n\n# Row-wise proportions (within marital status groups)\nmarital_child_row_prop &lt;- prop.table(marital_child_table, margin = 1)\nprint(round(marital_child_row_prop * 100, 2))\n\n# Column-wise proportions (within parental status groups)\nmarital_child_col_prop &lt;- prop.table(marital_child_table, margin = 2)\nprint(round(marital_child_col_prop * 100, 2))\nWe can also add marginal totals. Including row and column totals provides additional context for the distribution.\n# Add marginal totals to the table\nmarital_child_with_totals &lt;- addmargins(marital_child_table)\nprint(marital_child_with_totals)\nCross-tabulating marital and child provides a detailed view of the relationship between marital status and parental status. By combining raw counts and proportions, we can identify meaningful patterns in the data, supporting deeper insights into family composition and relationships.\nOver to you: use the code above as a blue print and analyse the relationship between other variables."
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-c1-setup",
    "href": "lab-uofg-02/lab-uofg-02.html#step-c1-setup",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "4.1 Step C1: Setup",
    "text": "4.1 Step C1: Setup\nYou can continue working in the same script that you created in Step B1 (the exemplary script that you can download also combined both exercises) or create a new scipt now. For the latter, review Step B1 and save new the script in the scripts folder within your project folder or working directory with an appropriate name, e.g., Lab1_Exercise_C.R.\n\n\n\n\n\n\nUsing ggplot2 for Data Visualization\n\n\n\n\n\nWhile base R plotting functions are straightforward and sufficient for creating simple visualizations, the ggplot2 package offers a more powerful, flexible, and consistent approach to data visualization. Developed as part of the tidyverse, ggplot2 is built on the grammar of graphics, enabling users to layer graphical components (e.g., data, aesthetics, and geoms) to create complex and customizable plots. Compared to base R, ggplot2 excels in:\n\nCustomization: Allows fine-tuning of colors, themes, scales, and labels for polished, publication-ready graphics.\nConsistency: Provides a unified framework for visualizing different types of data without requiring separate functions for each type of plot.\nExtensibility: Supports advanced visualizations and easy integration with other tidyverse tools.\n\nFor example, while base R may require multiple lines of code to create and customize a bar plot, ggplot2 simplifies the process, making it both more readable and more intuitive for creating layered, reusable visualizations.\nTo begin using ggplot2 for data visualization in R, you need to ensure the package is installed and loaded into your R session. Follow these simple steps to get started:\n1. Install the ggplot2 Package\nIf you haven’t already installed ggplot2, you can do so using the install.packages() function. This only needs to be done once for your system. The command below downloads and installs the package from CRAN (the Comprehensive R Archive Network).\n# Install ggplot2\ninstall.packages(\"ggplot2\")\n2. Load the ggplot2 Package\nOnce installed, you need to load the package into your R session using the library() function. This step must be repeated each time you start a new R session and makes all the ggplot2 functions available for use in your current R session.\n# Load ggplot2\nlibrary(ggplot2)\n3. Exploring Help and Resources (optional)\nYou can access detailed documentation and examples for ggplot2 by using the help system or exploring online resources. The ggplot2 package has extensive documentation and a supportive community, making it easy to learn and apply its powerful tools.\n# Access the ggplot2 documentation\nhelp(package = \"ggplot2\")"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-c2-histograms",
    "href": "lab-uofg-02/lab-uofg-02.html#step-c2-histograms",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "4.2 Step C2: Histograms",
    "text": "4.2 Step C2: Histograms\nA histogram is a fundamental tool for visualizing the distribution of a continuous variable. It provides a graphical representation of the frequency or density of data values, divided into intervals (bins). Histograms help identify patterns, such as skewness, multimodality, or outliers, and give insight into the overall shape of the data distribution.\nCompared to base R, ggplot2 offers greater flexibility and customization for creating histograms. You can easily adjust the number of bins, add labels, and style the plot to make it more informative and visually appealing.\n\n4.2.1 Creating a Histogram for tpstress**\nIn this example, we will create a histogram for the variable tpstress from the survey_data_full dataset. This variable is continuous, making it ideal for a histogram. Run the code below and examine the output, before reading on about the variables and choices that we made here.\n# Create a histogram for tpstress\nhistogram_tpstress &lt;- ggplot(data = survey_data_full, aes(x = tpstress)) +\n  geom_histogram(binwidth = 5, fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Distribution of Perceived Stress Levels\",\n    x = \"Perceived Stress Score (tpstress)\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()\n\n# Show plot\nhistogram_tpstress\n\n# Save plot\nggsave(\"output/figures/histogram_tpstress.pdf\", width = 8, height = 5)\nExplanation of the Code\n\nggplot(): Specifies the dataset (survey_data_full) and the mapping of variables to aesthetics (aes()), with tpstress assigned to the x-axis.\ngeom_histogram(): Adds a histogram layer to the plot.\nbinwidth: Sets the width of each bin (adjustable depending on the range of your data - more informationa bout this below).\nfill and color: Customize the fill color of the bars and the border color.\nlabs(): Adds descriptive labels for the title, x-axis, and y-axis to make the plot clear.\ntheme_minimal(): Applies a clean and simple theme for better aesthetics.\n\nAdjusting Bins\nThe number of bins can significantly affect the visualization. For finer or coarser groupings, adjust the binwidth parameter. For example:\n\nUse a smaller binwidth (e.g., binwidth = 2) for detailed distributions.\nUse a larger binwidth (e.g., binwidth = 10) for a summarized view.\n\nInterpretation of the Graphs\nThe histogram will display the distribution of the tpstress variable, showing the frequency of scores within each bin. This can help answer questions like:\n\nAre most participants experiencing low, moderate, or high stress?\nDoes the data appear skewed or normally distributed?\n\nADD FIGURE HERE\n\n\n\n\n\n\nSaving Plots with ggsave in ggplot2\n\n\n\n\n\nWhen creating visualizations in R, you often need to save your plots for reports, presentations, or further analysis. The ggsave() function in ggplot2 provides an easy and flexible way to save plots to various file formats with high quality.\nOverview of ggsave\n\nAutomatically saves the last plot created in your R session, or a specified plot object.\nSupports various file formats such as PNG, JPEG, PDF, and SVG.\nAllows customization of file size, resolution, and aspect ratio.\n\nBasic Syntax\nggsave(filename, plot = last_plot(), width = 20, height = 15, units = \"cm\", dpi = 300)\nWhere:\n\nfilename: The name of the file, including the desired extension (e.g., \"plot.png\" or \"plot.pdf\").\nplot: Specifies which plot to save. Defaults to the most recent plot (last_plot()).\nwidth and height: Specify the dimensions of the plot in inches (default units).\nunits: supports custom units for dimensions (default is inches when not specified).\ndpi: Sets the resolution of the plot (dots per inch). Higher values (e.g., 300) produce print-quality images.\n\nFormats\nWe can save the histogram for tpstress in different formats, depending on the purpose.\nPNG: For lossless, high-quality images suitable for both web use and presentations.\nggsave(\"histogram_tpstress.png\", plot = scatter_plot, width = 8, height = 6)\nPDF: For vector-based, high-quality graphics suitable for printing.\nggsave(\"histogram_tpstress.pdf\", plot = scatter_plot, width = 8, height = 6)\nJPEG: For compressed images with smaller file sizes (useful for web).\nggsave(\"histogram_tpstress.pdf\", plot = scatter_plot, width = 8, height = 6, dpi = 300)\nSVG: For scalable vector graphics, ideal for interactive web applications.\nggsave(\"histogram_tpstress.pdf\", plot = scatter_plot, width = 8, height = 6)\n\n\n\n\n\n4.2.2 Compare Groups Using Histograms**\nWhen comparing distributions between groups, it’s often useful to visualize them side by side or stacked for easier comparison. In R, this can be achieved using facets in ggplot2, which allow you to create separate subplots for different levels of a categorical variable. In this example, we compare the variable tpstress between males and females (grouped by sex) on separate histograms.\nPanelled Histograms\nFacets in ggplot2 replicate the SPSS functionality of splitting graphs by groups:\n\nSide-by-side graphs allow for direct visual comparison between groups.\nStacked graphs present the distributions on top of each other for easier alignment.\n\nCode to Compare tpstress by sex\nHere’s the code to create separate histograms for males and females:\n# Panelled histograms for tpstress by sex\nhistogram_tpstress_gender &lt;- ggplot(data = survey_data_full, aes(x = tpstress)) +\n  geom_histogram(binwidth = 5, fill = \"lightblue\", color = \"black\") +\n  facet_wrap(~ sex, ncol = 2) +  # Creates separate panels for each group\n  labs(\n    title = \"Comparison of Perceived Stress Levels by Gender\",\n    x = \"Perceived Stress Score (tpstress)\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()\n\n# Show plot\nhistogram_tpstress_gender\n\n# Save plot\nggsave(\"output/figures/histogram_tpstress_gender.pdf\", width = 8, height = 5)\nExplanation of the Code\n\nfacet_wrap(~ sex): Splits the histogram into separate panels for each level of the sex variable (Male and Female). The ncol = 2 argument specifies that the graphs should be placed side by side.\ngeom_histogram(): Creates histograms with a consistent binwidth for comparison.\nlabs(): Adds clear labels to describe the plot.\ntheme_minimal(): Ensures a clean and professional appearance.\n\nHandling Missing Values\nBy default, ggplot2 excludes cases with missing values in the grouping variable (sex) or the variable being plotted (tpstress). This mirrors SPSS functionality where cases with missing values are excluded on a variable-by-variable basis.\nTo explicitly confirm exclusions, use the na.omit() function to clean the dataset:\n# Remove cases with missing values in tpstress or sex\nsurvey_data_filtered &lt;- na.omit(survey_data_full[, c(\"tpstress\", \"sex\")])\nAlternative Layout: Stacked Panels\nTo stack the graphs vertically instead of placing them side by side, use facet_wrap() with ncol = 1:\n# Stacked histograms for tpstress by sex\nhistogram_tpstress_gender_stack &lt;- ggplot(data = survey_data_full, aes(x = tpstress)) +\n  geom_histogram(binwidth = 5, fill = \"lightblue\", color = \"black\") +\n  facet_wrap(~ sex, ncol = 1) +  # Stacks panels vertically\n  labs(\n    title = \"Comparison of Perceived Stress Levels by Gender (Stacked)\",\n    x = \"Perceived Stress Score (tpstress)\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()\n\n# Show plot\nhistogram_tpstress_gender_stack\n\n# Save plot\nggsave(\"output/figures/histogram_tpstress_gender_stack.pdf\", width = 8, height = 5)\nInterpretation of the Graphs\nThe panelled histograms show the distribution of perceived stress scores (tpstress) for males and females:\n\nLook for differences in the shape, spread, and center of the distributions.\nIdentify patterns such as skewness or concentration of values in specific ranges.\n\nADD PANEL FIGURE HERE\nADD STACK FIGURE HERE"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-c3-bar-charts",
    "href": "lab-uofg-02/lab-uofg-02.html#step-c3-bar-charts",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "4.3 Step C3: Bar Charts",
    "text": "4.3 Step C3: Bar Charts\nA bar chart is one of the most basic and widely used tools for visualizing categorical data. It shows the frequencies or counts of different categories, making it ideal for identifying dominant groups, comparing categories, and providing a quick summary of data distributions. Bar charts are especially useful when you want to:\n\nDisplay the distribution of a single categorical variable.\nCompare the relative size of categories.\nHighlight which categories are most or least common.\n\nBar charts are most effective for categorical or ordinal variables, such as:\n\nDemographic variables (e.g., gender, marital status, education level).\nGrouping variables (e.g., age bands, product categories).\nSummarizing discrete counts (e.g., survey responses, preference rankings).\n\nBar charts are not suitable for continuous variables (e.g., tpstress) since these are better visualized using histograms or boxplots.\n\n4.3.1 Creating a Simple Bar Chart\nIn this example, we create a simple bar chart for the variable sex, which represents gender.\n# Simple bar chart for Gender\nbar_gender &lt;- ggplot(data = survey_data_full, aes(x = sex)) +\n  geom_bar(fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Gender Distribution\",\n    x = \"Gender\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n  \n# Show plot\nbar_gender\n\n# Save plot\nggsave(\"output/figures/bar_gender.pdf\", width = 8, height = 5)\nExplanation of the Code\n\nggplot(): Specifies the dataset (survey_data_full) and maps the variable sex to the x-axis using aes(x = sex).\ngeom_bar(): Creates a bar chart. Since no y aesthetic is specified, geom_bar() automatically counts the number of occurrences of each category in sex. fill specifies the color of the bars, while color adds a border around each bar.\nlabs(): Adds descriptive labels to the title, x-axis, and y-axis for clarity.\ntheme_minimal(): Applies a clean, minimal theme for better aesthetics.\n\nInterpretation of the Graphs\nRunning the above code will produce a simple bar chart showing the distribution of males and females in the dataset. The y-axis represents the count of participants in each gender category.\nADD FIGURE HERE\n\n\n4.3.2 Creating a Clustered Bar Chart\nIn this exercise, we replicate the functionality of SPSS’ Clustered Bar Chart, where:\n\nA categorical variable (e.g., agegp3) is plotted on the x-axis.\nA grouping variable (e.g., sex) determines the clusters (represented by different colors).\nA continuous variable (tpstress) is used to calculate the mean for each combination of the categorical variables.\n\nggplot2 in R provides powerful tools to create clustered bar charts with error bars to visualize group-level summaries clearly.\nWe will create a clustered bar chart where: - X-axis: Represents categories of agegp3 (age groups in this example). - Groups: Clusters represent sex (males and females), distinguished by colors. - Y-axis: Displays the mean of the continuous variable (tpstress) for each group. - Error Bars: Represent variability (e.g., standard errors) to give context to the mean values.\nPreparing the Data in Base R\nBefore creating the chart, we summarize the data to calculate the mean and standard error for tpstress within each combination of agegp3 and sex:\nFirst, we need to calculate the group means. The aggregate() function in base R allows you to compute the mean of a continuous variable (tpstress) for each combination of agegp3 and sex.\n# Calculate group means using aggregate()\ngroup_means &lt;- aggregate(\n  tpstress ~ agegp3 + sex,\n  data = survey_data_full,\n  FUN = mean,\n  na.rm = TRUE\n)\n\n# Display the group means\nprint(group_means)\nHere:\n\ntpstress ~ agegp3 + sex specifies the grouping variables (agegp3 and sex).\nFUN = mean calculates the mean of tpstress for each group.\nna.rm = TRUE ensures missing values are excluded.\n\nSecond, we need to calculate group standard errors. To compute standard errors, use aggregate() again for the standard deviation, then calculate the standard error manually.\n# Calculate group standard deviations\ngroup_sd &lt;- aggregate(\n  tpstress ~ agegp3 + sex,\n  data = survey_data_full,\n  FUN = sd,\n  na.rm = TRUE\n)\n\n# Add a column for group sizes\ngroup_counts &lt;- aggregate(\n  tpstress ~ agegp3 + sex,\n  data = survey_data_full,\n  FUN = length\n)\n\n# Merge the results into a single data frame\ngroup_stats &lt;- merge(group_means, group_sd, by = c(\"agegp3\", \"sex\"))\ngroup_stats &lt;- merge(group_stats, group_counts, by = c(\"agegp3\", \"sex\"))\n\n# Rename columns for clarity\ncolnames(group_stats) &lt;- c(\"agegp3\", \"sex\", \"mean_tpstress\", \"sd_tpstress\", \"n\")\n\n# Calculate standard errors\ngroup_stats$se_tpstress &lt;- group_stats$sd_tpstress / sqrt(group_stats$n)\n\n# Display the final data frame\nprint(group_stats)\nOur final data frame group_stats contains:\n\nagegp3: Age group.\nsex: Gender group.\nmean_tpstress: Mean perceived stress score.\nsd_tpstress: Standard deviation of stress scores.\nn: Number of participants in each group.\nse_tpstress: Standard error of the mean.\n\nCreating the Clustered Bar Chart\nUsing the prepared group_stats data, you can now create the clustered bar chart with ggplot2.\n# Clustered bar chart using the prepared data\nbar_gender_age &lt;- ggplot(data = group_stats, aes(x = agegp3, y = mean_tpstress, fill = sex)) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.8), color = \"black\") +\n  geom_errorbar(\n    aes(ymin = mean_tpstress - se_tpstress, ymax = mean_tpstress + se_tpstress),\n    position = position_dodge(width = 0.8),\n    width = 0.2\n  ) +\n  labs(\n    title = \"Mean Perceived Stress by Age Group and Gender\",\n    x = \"Age Group\",\n    y = \"Mean Perceived Stress Score (tpstress)\",\n    fill = \"Gender\"\n  ) +\n  theme_minimal()\n\n# Show plot\nbar_gender_age\n\n# Save plot\nggsave(\"output/figures/bar_gender_age.pdf\", width = 8, height = 5)\nExplanation of the Code\n\nggplot(): Specifies the dataset (group_stats) and defines mappings between variables and aesthetics (aes()). fill = sex Uses the sex variable (gender) to determine the color of the bars.\ngeom_bar(): Creates the bar chart. stat = \"identity\" plots the actual values of mean_tpstress instead of counting occurrences (default behavior). position = position_dodge(width = 0.8) separates the bars into clusters by sex, leaving a small gap between groups. color = \"black\" adds a black border around each bar to enhance visual distinction.\ngeom_errorbar(): Adds error bars to the bars. ymin and ymax define the range of the error bars (mean ± standard error). width = 0.2 controls the width of the error bar caps.\nlabs() adds a descriptive title, axis labels, and a legend title.\ntheme_minimal() ensures a clean and professional look.\n\n\n\n\n\n\n\nAlternative using dplyr package\n\n\n\n\n\nA simpler way to prepare the data is to use the `dplyr’ package.\nPreparing the Data\nBefore creating the chart, we summarize the data to calculate the mean and standard error for tpstress within each combination of agegp3 and sex:\n# Install dplyr\ninstall.packages(\"dplyr\")\n\n# Load library\nlibrary(dplyr)\n\n# Summarize the data\nsurvey_summary &lt;- survey_data_full %&gt;%\n  group_by(agegp3, sex) %&gt;%\n  summarise(\n    mean_tpstress = mean(tpstress, na.rm = TRUE),\n    se_tpstress = sd(tpstress, na.rm = TRUE) / sqrt(n())\n  )\n\n# Display the summarized data\nprint(survey_summary)\nCreating the Clustered Bar Chart\nUsing the summarized data, we can create a clustered bar chart with error bars:\n# Create a clustered bar chart with ggplot2\nbar_gender_age2 &lt;- ggplot(data = survey_summary, aes(x = agegp3, y = mean_tpstress, fill = sex)) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.8), color = \"black\") +\n  geom_errorbar(aes(ymin = mean_tpstress - se_tpstress, ymax = mean_tpstress + se_tpstress),\n                position = position_dodge(width = 0.8), width = 0.2) +\n  labs(\n    title = \"Mean Perceived Stress by Age Group and Gender\",\n    x = \"Age Group\",\n    y = \"Mean Perceived Stress Score (tpstress)\",\n    fill = \"Gender\"\n  ) +\n  theme_minimal()\n\n# Show plot\nbar_gender_age2\n\n# Save plot\nggsave(\"output/figures/bar_gender_age2.pdf\", width = 8, height = 5)\nExplanation of the Code\n\nThe dplyr package is used to calculate the mean (mean_tpstress) and standard error (se_tpstress) of tpstress grouped by agegp3 and sex.\ngeom_bar(): Creates the bar chart. stat = \"identity\" specifies that the heights of the bars represent the actual values (means in this case). position = position_dodge(width = 0.8) separates the bars into clusters by sex.\ngeom_errorbar(): Adds error bars to the bars. ymin and ymax define the range of the error bars (mean ± standard error). width = 0.2 controls the width of the error bar caps.\naes(fill = sex) assigns colors to sex groups.\nlabs() adds a descriptive title, axis labels, and a legend title.\ntheme_minimal() ensures a clean and professional look.\n\n\n\n\nInterpretation of the Chart\nThe clustered bar chart allows us to compare:\n\nDifferences in mean perceived stress (tpstress) across age groups (agegp3).\nHow stress levels differ between males and females (sex) within each age group.\nThe size of the error bars provides insight into variability within each group.\n\nADD FIGURE HERE"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-c4-line-graphs",
    "href": "lab-uofg-02/lab-uofg-02.html#step-c4-line-graphs",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "4.4 Step C4: Line Graphs",
    "text": "4.4 Step C4: Line Graphs\nLine graphs are a versatile tool for visualizing trends and relationships between variables. They are particularly useful for examining how a continuous variable changes across categories or over time. In this example, we use tpstress (perceived stress) as the continuous variable on the y-axis and agegp5 (age group) as the categorical variable on the x-axis. We create two versions:\n\nA simple line graph.\nA multi-line graph with separate lines for males and females (sex).\n\n\n4.4.1 Creating a Simple Line Graph\nA simple line graph shows how the average tpstress score changes across age groups (agegp5).\n# Calculate the mean tpstress for each age group\nsimple_line_data &lt;- aggregate(\n  tpstress ~ agegp5,\n  data = survey_data_full,\n  FUN = mean,\n  na.rm = TRUE\n)\n\n# Create the line graph\nline_stress_age &lt;- ggplot(data = simple_line_data, aes(x = agegp5, y = tpstress, group = 1)) +\n  geom_line(color = \"blue\", size = 1) +\n  geom_point(color = \"blue\", size = 2) +\n  labs(\n    title = \"Mean Perceived Stress by Age Group\",\n    x = \"Age Group\",\n    y = \"Mean Perceived Stress Score\"\n  ) +\n  theme_minimal()\n\n# Show plot\nline_stress_age\n\n# Save plot\nggsave(\"output/figures/line_stress_age.pdf\", width = 8, height = 5)\nExplanation of the Code\n\naggregate() calculates the mean tpstress for each agegp5 group while excluding missing values (na.rm = TRUE).\nggplot(): Specifies the data (simple_line_data) and maps agegp5 to the x-axis and tpstress (mean perceived stress) to the y-axis.\ngeom_line(): Creates the line connecting the points. color = \"blue\" specifies the color of the line. size = 1 adjusts the line thickness.\ngeom_point(): Adds individual points for each age group. color = \"blue\" matches the line color. size = 2 makes the points more visible.\nlabs() adds a descriptive title, axis labels, and a legend title.\ntheme_minimal() ensures a clean and professional look.\n\nInterpretation of the Graphs\nIn the simple line graph, the x-axis represents age groups (agegp5), and the y-axis shows the mean perceived stress scores (tpstress). The points connected by the line indicate how stress levels change across age groups.\nKey questions to consider:\n\nOverall Trend: Do stress levels increase, decrease, or remain stable across age groups?\nPeaks and Valleys: Are there specific age groups with notably higher or lower stress levels?\nOutliers: Are there unexpected jumps or drops in the graph that may warrant further investigation?\n\nFor example:\n\nA steadily increasing line may suggest that perceived stress tends to rise with age.\nA peak in one age group might indicate a period of heightened stress that could be explored further.\n\nADD FIGURE HERE\n\n\n4.4.2 Creating a Multi-Line Graph\nTo show separate lines for males and females, we include the sex variable as a grouping and color aesthetic.\n# Calculate the mean tpstress for each combination of age group and gender\nmulti_line_data &lt;- aggregate(\n  tpstress ~ agegp5 + sex,\n  data = survey_data_full,\n  FUN = mean,\n  na.rm = TRUE\n)\n\n# Create the multi-line graph\nline_stress_age_gender &lt;- ggplot(data = multi_line_data, aes(x = agegp5, y = tpstress, color = sex, group = sex)) +\n  geom_line(size = 1) +\n  geom_point(size = 2) +\n  labs(\n    title = \"Mean Perceived Stress by Age Group and Gender\",\n    x = \"Age Group\",\n    y = \"Mean Perceived Stress Score\",\n    color = \"Gender\"\n  ) +\n  theme_minimal()\n\n# Show plot\nline_stress_age_gender\n\n# Save plot\nggsave(\"output/figures/line_stress_age_gender.pdf\", width = 8, height = 5)\nExplanation of the Code\n\naggregate() calculates the mean tpstress for each combination of agegp5 and sex.\nggplot(): Specifies the data (multi_line_data) and maps agegp5 to the x-axis, tpstress (mean perceived stress) to the y-axis, sex to the color aesthetic for distinct line colors, and group = sex ensures separate lines for each gender.\ngeom_line(): Creates the line connecting the points. The color aesthetic from aes() applies distinct colors to the lines. size = 1 adjusts the line thickness.\ngeom_point(): Adds individual points for each age group. color = \"blue\" matches the line color. size = 2 makes the points more visible.\nlabs() adds a descriptive title, axis labels, and a legend title.\ntheme_minimal() ensures a clean and professional look.\n\nInterpretation of the Graphs\nThe multi-line graph adds a layer of complexity by splitting the line into separate paths for males and females. Each gender has its own line, distinguished by color. This allows for a direct comparison of stress levels between genders across age groups.\nKey questions to consider:\n\nGender Differences: Do males and females have similar or diverging patterns of stress across age groups?\nCrossovers: Do the lines for males and females intersect at any point, indicating shifts in which gender reports higher stress?\nParallel Trends: Are the lines generally parallel, suggesting consistent gender differences across age groups?\n\nFor example:\n\nIf the lines for males and females remain parallel, it may indicate consistent differences in stress levels regardless of age.\nIf the lines cross, it suggests age-specific variations in gender differences.\n\nADD FIGURE HERE\nIn general, both line graphs (simple and multi-line) are useful for identifying:\n\nPatterns in Stress Levels: Are there general trends across age groups?\nGroup Comparisons: How do males and females differ in perceived stress levels?\nActionable Insights: Insights from these graphs can inform targeted interventions or further analysis.\n\nBy examining the overall shape and relationship of the lines, you can derive meaningful conclusions about the data and identify areas for further exploration."
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-c4-scatterplots",
    "href": "lab-uofg-02/lab-uofg-02.html#step-c4-scatterplots",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "4.5 Step C4: Scatterplots",
    "text": "4.5 Step C4: Scatterplots\nScatterplots are essential for visualizing the relationship between two continuous variables. They help identify trends, correlations, and potential outliers. By adding categorical grouping and labeling points, scatterplots become even more informative, allowing for deeper insights into patterns within subgroups.\nIn this exercise, we create three scatterplots using the survey_data_full dataset:\n\nA simple scatterplot with tpstress as the dependent variable (y-axis) and tpcoiss as the independent variable (x-axis).\nA scatterplot with color-coded points based on sex (categorical grouping).\nThe same scatterplot as above, but with point labels based on the id variable.\n\n\n4.5.1 Simple Scatterplot\nThe first scatterplot shows the relationship between tpstress (perceived stress) and tpcoiss (control over internal states).\n# Simple scatterplot\nscatter_stress_control &lt;- ggplot(data = survey_data_full, aes(x = tpcoiss, y = tpstress)) +\n  geom_point(color = \"blue\", size = 2) +\n  labs(\n    title = \"Scatterplot of Perceived Stress vs Coping Strategies\",\n    x = \"Coping Strategies (tpcoiss)\",\n    y = \"Perceived Stress (tpstress)\"\n  ) +\n  theme_minimal()\n\n# Show plot\nscatter_stress_control\n\n# Save plot\nggsave(\"output/figures/scatter_stress_control.pdf\", width = 8, height = 5)\nExplanation of the Code\n\nggplot() specifies the dataset (survey_data_full) and maps tpcoiss to the x-axis and tpstress to the y-axis.\ngeom_point() adds scatterplot points. color = \"blue\" sets the color of all points. size = 2 adjusts the point size for better visibility.\nlabs() adds a title, x-axis label, and y-axis label for clarity.\ntheme_minimal() ensures a clean and professional appearance.\n\nInterpretation of the Graphs\nThe simple scatterplot shows the relationship between tpstress (perceived stress) and tpcoiss (coping strategies) across all participants.\nKey points to consider:\n\nDirection of the relationship:\n\nA positive trend (points sloping upward) suggests that higher coping strategies are associated with higher perceived stress.\nA negative trend (points sloping downward) suggests that higher coping strategies are associated with lower perceived stress.\nA flat trend (points scattered without a clear pattern) suggests no apparent relationship between the variables.\n\nStrength of the relationship:\n\nPoints clustered tightly along an imaginary line indicate a strong relationship.\nPoints scattered widely indicate a weaker relationship or greater variability.\n\nOutliers:\n\nPoints far from the general trend or clustering might indicate participants with unusual scores (e.g., very high stress despite low coping strategies).\n\n\nIf the scatterplot shows a positive trend, this could suggest that participants reporting higher coping strategies are experiencing higher levels of stress, which might reflect maladaptive coping mechanisms.\nADD FIGURE HERE\n\n\n4.5.2 Scatterplot with Categorical Grouping\nTo differentiate points by gender, we map the sex variable to the color aesthetic. This helps identify potential differences in the relationship between tpstress and tpcoiss for males and females.\n# Scatterplot with grouping by sex\nscatter_stress_control_gender &lt;- ggplot(data = survey_data_full, aes(x = tpcoiss, y = tpstress, color = sex)) +\n  geom_point(size = 2) +\n  labs(\n    title = \"Scatterplot of Perceived Stress vs Coping Strategies by Gender\",\n    x = \"Coping Strategies (tpcoiss)\",\n    y = \"Perceived Stress (tpstress)\",\n    color = \"Gender\"\n  ) +\n  theme_minimal()\n\n# Show plot\nscatter_stress_control_gender\n\n# Save plot\nggsave(\"output/figures/scatter_stress_control_gender.pdf\", width = 8, height = 5)\nExplanation of the Code\n\nggplot() specifies the dataset (survey_data_full) and maps tpcoiss to the x-axis and tpstress to the y-axis, color = sex assigns different colors to males and females.\ngeom_point() adds scatterplot points. color = \"blue\" sets the color of all points. size = 2 adjusts the point size for better visibility.\nlabs() adds a title, x-axis label, and y-axis label for clarity. color = \"Gender\" labels the legend as “Gender” for clarity.\ntheme_minimal() ensures a clean and professional appearance.\n\nInterpretation of the Graphs\nThe grouped scatterplot adds a layer of complexity by differentiating the points based on sex (males and females) using color coding. This allows for subgroup comparisons.\nKey points to consider:\n\nComparing trends between groups:\n\nLook for differences in the direction, strength, or spread of points for each group.\nParallel trends suggest that the relationship between tpstress and tpcoiss is consistent across genders.\nDiverging or crossing trends may indicate that the relationship differs between males and females.\n\nClustering patterns:\n\nAre males and females clustered in similar regions of the plot, or are they spread differently?\nFor example, one group may predominantly occupy the lower tpcoiss range while the other spans the full range.\n\nGroup-specific outliers:\n\nOutliers can be identified separately for each group, helping to explore whether certain groups have more extreme responses.\n\n\nIf males show a stronger positive trend compared to females, it might suggest gender differences in how coping strategies are related to perceived stress.\nADD FIGURE HERE\n\n\n4.5.3 Scatterplot with Point Labels\nAdding point labels based on the id variable allows us to identify individual data points in the scatterplot. This is similar to the “Point ID label” feature in SPSS.\n# Scatterplot with point labels\nscatter_stress_control_gender_id &lt;- ggplot(data = survey_data_full, aes(x = tpcoiss, y = tpstress, color = sex)) +\n  geom_point(size = 2) +\n  geom_text(aes(label = id), hjust = 0, vjust = -0.5, size = 3) +\n  labs(\n    title = \"Scatterplot of Perceived Stress vs Coping Strategies with Point Labels\",\n    x = \"Coping Strategies (tpcoiss)\",\n    y = \"Perceived Stress (tpstress)\",\n    color = \"Gender\"\n  ) +\n  theme_minimal()\n\n# Show plot\nscatter_stress_control_gender_id\n\n# Save plot\nggsave(\"output/figures/scatter_stress_control_gender_id.pdf\", width = 8, height = 5)\nExplanation of the Code (only difference to the previous code)\n\ngeom_text() adds labels to each point. aes(label = id) specifies that each point is labeled with the id variable. hjust = 0, vjust = -0.5 adjusts the position of the labels relative to the points. size = 3 sets the text size for readability.\nThe rest of the code is similar to the grouped scatterplot, with points color-coded by gender.\n\nInterpretation of the Graphs\nThe labeled scatterplot builds on the grouped scatterplot by adding participant identifiers (id) as point labels. This is useful for identifying specific data points and exploring individual-level patterns.\nKey points to consider:\n\nIdentifying specific participants:\n\nOutliers or points of interest can now be linked to specific participants using their id.\nFor example, if a participant shows very high tpstress despite low tpcoiss, their id can be used to investigate their survey responses further.\n\nLabel clustering:\n\nOverlapping labels can indicate regions with many participants sharing similar scores.\nSparse labels suggest regions with fewer participants, highlighting gaps in the data.\n\nPotential for follow-up:\n\nBy identifying participants with unusual scores, researchers can delve deeper into qualitative responses or additional variables to better understand these cases.\n\n\nIf a specific participant shows extreme stress levels (tpstress) with high coping strategies (tpcoiss), their behavior might warrant further investigation to understand coping efficacy or survey anomalies.\nADD FIGURE HERE"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-d1-setup",
    "href": "lab-uofg-02/lab-uofg-02.html#step-d1-setup",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "2.1 Step D1: Setup",
    "text": "2.1 Step D1: Setup\nYou can continue working in the same project (Step A1, Option 1) or working directory (Step A1, Option 2) that you created in the previous lab. You should, however, do the following:\n\nCreate a new R script: Go to File &gt; New File &gt; R Script.\nSave the script in your scripts folder with an appropriate name, e.g., Lab2_Exercise_D_E_F_G.R.\n\n\n\n\n\n\n\nNote\n\n\n\nYou can either work through the following steps and copy/paste the respective code into the Lab_Exercise_D_E_F_G.R file that you will create in Step D1 or download the R script for Exercises D, E, F, and G and follow the instructions below and save the downloaded file in the scripts folder that you will create.\n\n\nNow you are ready to begin your work in R and continue with Step D2!"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-d2-creating-or-loading-the-dataset",
    "href": "lab-uofg-02/lab-uofg-02.html#step-d2-creating-or-loading-the-dataset",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "2.2 Step D2: Creating or Loading the Dataset",
    "text": "2.2 Step D2: Creating or Loading the Dataset\nFor practice purposes, try both options so you familiarise yourself with creating and loading datasets in R."
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-d2-loading-the-dataset",
    "href": "lab-uofg-02/lab-uofg-02.html#step-d2-loading-the-dataset",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "2.2 Step D2: Loading the Dataset",
    "text": "2.2 Step D2: Loading the Dataset\nPlease download the dataset and save it in the data folder within your project folder or working directory.\n# Load the CSV file stored in the \"data\" folder\nsurvey_data_full &lt;- read.csv(\"data/lab2-survey.csv\")\nYou can easily explore and check the basic structure of your data and get a summary:\n# View the first few rows using head()\nhead(survey_data_full)\n\n# Examine the structure\nstr(survey_data_full)\n\n# Get basic summary statistics\nsummary(survey_data_full)\nSimilar to Exercises B and C in Lab 1, we want to assign labels to the demographic variables in the survey_data_full data frame using factors with labeled levels. This method ensures the data remains categorical but with human-readable labels for easier interpretation and analysis.\n# Convert demographic variables to factors with labeled levels\n\n# Assign labels for \"sex\"\nsurvey_data_full$sex &lt;- factor(\n  survey_data_full$sex,\n  levels = c(1, 2),\n  labels = c(\"Male\", \"Female\")\n)\n\n# Assign labels for \"marital\"\nsurvey_data_full$marital &lt;- factor(\n  survey_data_full$marital,\n  levels = c(1, 2, 3, 4, 5, 6, 7, 8),\n  labels = c(\n    \"Single\", \"Steady relationship\", \"Living with partner\",\n    \"Married first time\", \"Remarried\", \"Separated\",\n    \"Divorced\", \"Widowed\"\n  )\n)\n\n# Assign labels for \"child\"\nsurvey_data_full$child &lt;- factor(\n  survey_data_full$child,\n  levels = c(1, 2),\n  labels = c(\"Yes\", \"No\")\n)\n\n# Assign labels for \"educ\"\nsurvey_data_full$educ &lt;- factor(\n  survey_data_full$educ,\n  levels = c(1, 2, 3, 4, 5, 6),\n  labels = c(\n    \"Primary\", \"Some secondary\", \"Completed high school\",\n    \"Some additional training\", \"Completed undergraduate\",\n    \"Postgraduate completed\"\n  )\n)\n\n# Assign labels for \"source\"\nsurvey_data_full$source &lt;- factor(\n  survey_data_full$source,\n  levels = c(1, 2, 3, 4, 5, 6, 7, 8, 9),\n  labels = c(\n    \"Work\", \"Spouse or partner\", \"Relationships\", \"Children\",\n    \"Family\", \"Health/illness\", \"Life in general\",\n    \"Money/finances\", \"Lack of time, too much to do\"\n  )\n)\n\n# Assign labels for \"smoke\"\nsurvey_data_full$smoke &lt;- factor(\n  survey_data_full$smoke,\n  levels = c(1, 2),\n  labels = c(\"Yes\", \"No\")\n)\nThe summary() function can be used to confirm that the labels have been applied correctly to the variables.\n# Verify changes by printing a summary\nsummary(survey_data_full)"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-d3-correlation",
    "href": "lab-uofg-02/lab-uofg-02.html#step-d3-correlation",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "2.3 Step D3: Correlation",
    "text": "2.3 Step D3: Correlation\nCorrelation analysis helps us understand the relationship between two variables. Before we dive into the practical implementation, let’s understand some key concepts.\n\n2.3.1 What is Correlation?\nCorrelation measures the strength and direction of the relationship between two variables. The Pearson correlation coefficient (PCC), often denoted as r, is a statistical measure that quantifies the strength and direction of a linear relationship between two continuous variables. It is one of the most widely used correlation metrics.\nThe correlation coefficient (r) ranges from -1 to +1:\n\nr = +1: Perfect positive correlation\nr = 0: No linear correlation\nr = -1: Perfect negative correlation\n\nThe magnitude of r (how close it is to ±1) indicates the strength of the relationship, while the sign indicates the direction.\n\n\n\n\n\n\nNote\n\n\n\nThe correlation coefficient is standardized, meaning it’s independent of the units of measurement of the original variables. This makes it useful for comparing relationships between different pairs of variables.\n\n\n\n\n2.3.2 Assumptions for Pearson’s Correlation\nBefore calculating correlations, we should check these assumptions:\n\nVariables are measured at the interval or ratio level\nLinear relationship between variables\nNo significant outliers\nApproximate normal distribution of variables\nHomoscedasticity (equal variances)\n\n\n\n2.3.3 Visual Inspection: Scatterplots\nBefore calculating correlations, it’s important to visualize the relationships:\n# Install ggplot2 (NOTE: not needed if you completed the first lab)\ninstall.packages(\"ggplot2\")\n\n# Load ggplot2\nlibrary(ggplot2)\n\n# Simple scatterplot\nscatter_stress_control &lt;- ggplot(data = survey_data_full, aes(x = tpcoiss, y = tpstress)) +\n  geom_point(color = \"blue\", size = 2) +\n  labs(\n    title = \"Scatterplot of Perceived Stress vs Coping Strategies\",\n    x = \"Coping Strategies (tpcoiss)\",\n    y = \"Perceived Stress (tpstress)\"\n  ) +\n  theme_minimal()\n\n# Show plot\nscatter_stress_control\nNote: If you run the code above, you will get the warning message below. This warning occurs because the variables tpstress and tpcoiss have missing values. The warning doesn’t stop the plot from rendering, but it alerts you that data is being removed and you should investigate the reason behind the warning and decide how to handle it appropriately (e.g., filtering, replacing, or imputing missing values if necessary).\nWarning message:\nRemoved 13 rows containing missing values or values outside the scale range (`geom_point()`). \n\n\n2.3.4 Computing Correlations\nWe can calculate correlation. In the first instance, we focus on the two variables tpcoiss and tpstress. Afterwards, we will explore how to calculate correlations for all variables at once.\nSingle Correlation\nThe cor() function calculates the correlation coefficient:\n# Calculate correlation between tpcoiss and tpstress\ncor(survey_data_full$tpcoiss, survey_data_full$tpstress, use = \"complete.obs\")\n\n# Specify the method (default is Pearson, so this will return the same result)\ncor(survey_data_full$tpcoiss, survey_data_full$tpstress, use = \"complete.obs\", \n    method = \"pearson\")\nThe cor() function returns NA if any of the input values are missing, as it cannot compute the correlation because the missing values prevent pairwise comparisons. From the warning when creating the scatterplot, we know that there are 13 missing values across the two variables.\n\n\n\n\n\n\nNote\n\n\n\nBest Practices in Base R\n\nAlways visualize your data first\nCheck assumptions (e.g., normality):\n# Test for normality\nshapiro.test(x)\nshapiro.test(y1)\nConsider different correlation methods when appropriate:\n# Pearson correlation (default)\ncor(x, y1, method = \"pearson\")\n\n# Spearman correlation (for non-normal data)\ncor(x, y1, method = \"spearman\")\n\n# Kendall correlation (for ordinal data)\ncor(x, y1, method = \"kendall\")\nDeal with missing values appropriately.\n\nOption A: Handle missing values in cor() with different options for use:\n\n# Exclude all rows with one missing value.\n# Recommended in most cases and used for pairwise correlation.\ncor(x, y1, use = \"complete.obs\")\n\n# Uses all available pairwise data without dropping entire rows.\n# Works well when computing correlation matrices.\ncor(x, y1, use = \"pairwise.complete.obs\")\n\nOption B: Remove or replace missing values before calculating the correlations (note that replacing missing values will lead to different results):\n\n# You can filter the dataset if you prefer to remove missing values before \n# calculation.\nclean_data &lt;- na.omit(survey_data_full[, c(\"tpcoiss\", \"tpstress\")])\ncor(clean_data$tpcoiss, clean_data$tpstress)\n\n# Alternatively, you can replace missing values (e.g., using the mean).\nmodified_data &lt;- survey_data_full\nmodified_data$tpcoiss[is.na(modified_data$tpcoiss)] &lt;- mean(modified_data$tpcoiss, na.rm = TRUE)\nmodified_data$tpstress[is.na(modified_data$tpstress)] &lt;- mean(modified_data$tpstress, na.rm = TRUE)\n\ncor(modified_data$tpcoiss, modified_data$tpstress)\n\n\n\nCorrelation Matrix\nWe can calculate correlations for multiple variables at once.\nFirst, let’s create a smaller data frame with only continuous variables. We can do this in base R using the following code:\nsurvey_data_small &lt;- survey_data_full[, c(\"tpcoiss\", \"tpstress\", \"toptim\", \n                                   \"tposaff\", \"tnegaff\", \"tlifesat\", \n                                   \"tslfest\", \"tmarlow\")]\nNote: When subsetting the data above, we use survey_data_full[, c(\"tpcoiss\", .... The comma , in the square brackets explicitly indicates that you are subsetting columns from a data frame. This clarity can help prevent unintended behaviors when working with more complex subsetting tasks (e.g., selecting rows and columns simultaneously) and makes the code more readable to others. Although survey_data_full[c(\"tpcoiss\", ... (without the comma ,) often produces the same output when subsetting columns by name, using the comma notation adheres to standard R conventions for data frame indexing.\nYou can verify the structure of your new data frame using:\n# Check the structure of the new data frame\nstr(survey_data_small)\n\n# Or see the first few rows\nhead(survey_data_small)\n\n\n\n\n\n\nTidyverse alternative\n\n\n\n\n\nYou can also use the tidyverse package to accomplish the same result: a new data frame containing only these eight variables:\nlibrary(tidyverse)\n\nsurvey_data &lt;- survey_data_full %&gt;%\n  select(tpcoiss, tpstress, toptim, tposaff, \n         tnegaff, tlifesat, tslfest, tmarlow)\nYou can verify the structure of your new data frame using:\n# Check the structure of the new data frame\nstr(survey_data_small)\n\n# Or see the first few rows\nhead(survey_data_small)\n\n\n\n# Calculate correlation matrix\ncorrelation_matrix &lt;- cor(survey_data_small, use = \"pairwise.complete.obs\")\n\n# Round to 3 decimal places for clarity\nround(correlation_matrix, 3)\n\n\n2.3.5 Statistical Testing with cor.test()\nThe cor.test() function provides a full statistical test:\n# Perform correlation test\ncorrelation_test &lt;- cor.test(survey_data_full$tpcoiss, \n                             survey_data_full$tpstress, \n                             use = \"complete.obs\")\n\n# View complete results\nprint(correlation_test)\nThis output includes:\n\nThe correlation coefficient\nThe test statistic\nThe p-value\nThe confidence interval\n\n\n\n2.3.6 Interpreting Correlation Results\nWhen interpreting correlation results, consider:\n\nStrength: Common guidelines for absolute values:\n\n0.00 to 0.19: “very weak”\n0.20 to 0.39: “weak”\n0.40 to 0.59: “moderate”\n0.60 to 0.79: “strong”\n0.80 to 1.00: “very strong”\n\nDirection: Positive or negative relationship\nStatistical Significance: Check the p-value\n\np &lt; 0.05 typically indicates statistical significance\nConsider effect size, not just significance\n\nContext: What’s meaningful in your field?\n\n\n\n2.3.7 Common Pitfalls and Considerations\n\nCorrelation ≠ Causation: Correlation only indicates association, not causation\nOutliers: Can strongly influence correlation coefficients\nNon-linear Relationships: Pearson’s correlation only measures linear relationships\nMissing Data: Handle missing values appropriately"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#common-pitfalls-and-considerations",
    "href": "lab-uofg-02/lab-uofg-02.html#common-pitfalls-and-considerations",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "2.4 Common Pitfalls and Considerations",
    "text": "2.4 Common Pitfalls and Considerations\n\nCorrelation ≠ Causation: Correlation only indicates association, not causation\nOutliers: Can strongly influence correlation coefficients\nNon-linear Relationships: Pearson’s correlation only measures linear relationships\nMissing Data: Handle missing values appropriately"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-d4-linear-regression",
    "href": "lab-uofg-02/lab-uofg-02.html#step-d4-linear-regression",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "2.4 Step D4: Linear Regression",
    "text": "2.4 Step D4: Linear Regression\nRegression analysis helps us understand how one variable (the dependent variable) changes when another variable (the independent variable) changes. Before we dive into the practical implementation, let’s understand some key concepts.\n\n2.4.1 What is Linear Regression?\nLinear regression is one of the foundational techniques in statistics. Linear regression gives us a mathematical way to describe and predict the relationship between two variables.\nThink of linear regression like drawing a “best-fit” line through a cloud of data points. This line helps us:\n\nUnderstand the relationship between variables.\nPredict values for new observations.\nQuantify how strong the relationship is.\n\n\n\n2.4.2 Creating Our Linear Regression Model\nLet’s analyze the relationship between stress (tpstress) and sense of control (tpcoiss). We’ll first visualize the data, then create our regression model.\n# Create Scatterplot\nggplot(survey_data_full, aes(x = tpcoiss, y = tpstress)) +\n  geom_point(color = \"darkblue\", alpha = 0.7) +  # Scatterplot points\n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE, linewidth = 1.5) +  # Regression line\n  labs(\n    title = \"Relationship between Stress and Control\",\n    x = \"Sense of Control (tpcoiss)\",\n    y = \"Perceived Stress (tpstress)\"\n  ) +\n  theme_minimal()\nNote: When running the code above, we get the error below. The functions geom_smooth() (regression) and geom_point() (scatterplot) automatically exclude the rows with missing values, triggering the warning. Refer back to the correlation section for how to proactively deal with these issues.\n`geom_smooth()` using formula = 'y ~ x'\nWarning messages:\n1: Removed 13 rows containing non-finite outside the scale range (`stat_smooth()`). \n2: Removed 13 rows containing missing values or values outside the scale range (`geom_point()`). \nNow, let’s create our regression model using base R:\n# Create the linear regression model\nstress_model &lt;- lm(tpstress ~ tpcoiss, data = survey_data_full)\n\n# View the complete summary\nsummary(stress_model)\n\n\n2.4.3 Understanding the Results\nLet’s break down each part of the output to understand what it tells us:\n1. The Correlation Coefficient (R)\nIn our case, we can find the correlation coefficient (r) by taking the square root of R-squared. The negative or positive sign comes from the slope coefficient in our regression output.\n# Calculate r from our model\nr &lt;- sign(coef(stress_model)[2]) * sqrt(summary(stress_model)$r.squared)\ncat(\"Correlation coefficient (r):\", round(r, 3))\nThis value tells us:\n\nThe strength of the relationship (how close to -1 or 1)\nThe direction (positive or negative)\n\n2. The ANOVA Table\nThe ANOVA table helps us assess if our model is statistically significant:\n# Display the ANOVA table\nanova(stress_model)\nLooking at the p-value (Pr(&gt;F)), we can see if our relationship is statistically significant. A value less than 0.05 suggests strong evidence of a real relationship between our variables.\n3. The Regression Equation\nFrom our coefficients table, we can write our regression equation:\n# Display coefficients\ncoef(stress_model)\nOur regression equation is:\nStress = β₀ + β₁(Control)\nWhere:\n\nβ₀ is our intercept (constant)\nβ₁ is our slope coefficient\n\nLet’s fill in the actual values:\n# Extract coefficients\nintercept &lt;- coef(stress_model)[1]\nslope &lt;- coef(stress_model)[2]\n\ncat(\"Regression equation:\\n\")\ncat(\"Stress =\", round(intercept, 3), \"+\", round(slope, 3), \"× Control\")\nThis equation means:\n\nWhen Control = 0, predicted Stress = intercept\nFor each one-unit increase in Control, Stress changes by the slope amount\n\n4. R-squared (R²)\nR-squared tells us how much of the variation in stress can be explained by control:\n# Extract R-squared\nr_squared &lt;- summary(stress_model)$r.squared\ncat(\"R-squared:\", round(r_squared, 3))\nThis means that approximately {round(r_squared * 100, 1)}% of the variation in stress levels can be explained by a person’s sense of control.\n\n\n2.4.4 Making Predictions\nWe can use our model to predict stress levels for new values of control:\n# Create some example control values\nnew_control &lt;- data.frame(tpcoiss = c(20, 30, 40))\n\n# Make predictions\npredictions &lt;- predict(stress_model, newdata = new_control)\n\n# Display predictions\ncbind(Control = new_control, Predicted_Stress = round(predictions, 2))\n\n\n2.4.5 Checking Model Assumptions\nFor our regression to be valid, we should check certain assumptions:\n# Create diagnostic plots\npar(mfrow = c(2, 2))\nplot(stress_model)\nThese plots help us check:\n\nLinearity (Residuals vs Fitted)\nNormality (Normal Q-Q)\nHomoscedasticity (Scale-Location)\nInfluential points (Residuals vs Leverage)\n\n\n\n2.4.6 Interpretation Guide\nWhen interpreting your regression results, consider:\n\nStatistical Significance\n\nLook at the p-value in the ANOVA table\nA p-value &lt; 0.05 suggests a significant relationship\n\nPractical Significance\n\nLook at R-squared to understand how much variance is explained\nConsider the slope coefficient for practical impact\n\nDirection of Relationship\n\nA negative slope means as one variable increases, the other decreases\nA positive slope means both variables increase together\n\nModel Assumptions\n\nCheck diagnostic plots for violations\nConsider transformations if assumptions are violated\n\n\n\n\n\n\n\n\nLinear Regression Analysis with R Packages\n\n\n\n\n\nIntroduction While base R provides solid foundations for linear regression, modern R packages offer enhanced capabilities for analysis, visualization, and interpretation. We’ll use several powerful packages that make our analysis more intuitive and visually appealing:\n# Install packages if needed\ninstall.packages(c(\"tidyverse\", \"broom\", \"performance\", \"see\", \"ggpubr\", \"sjPlot\", \"sjmisc\", \"sjlabelled\"))\n\n# Load required packages\nlibrary(tidyverse)    # For data manipulation and visualization\nlibrary(broom)        # For tidying statistical objects\nlibrary(performance)  # For model performance metrics\nlibrary(see)          # For model visualization\nlibrary(ggpubr)       # For publication-ready plots\nlibrary(sjPlot)       # For model visualization and tables\nlibrary(sjmisc)       # For model visualization and tables\nlibrary(sjlabelled)   # For model visualization and tables\nData Preparation\nFirst, let’s prepare our data using tidyverse functions:\n# Create a focused dataset for analysis\nanalysis_data &lt;- survey_data_full %&gt;%\n  select(tpstress, tpcoiss) %&gt;%\n  drop_na()  # Remove any missing values\n\n# Quick summary of our variables\nsummary(analysis_data)\nVisual Exploration with ggplot2\nThe ggplot2 package (part of tidyverse) creates beautiful visualizations:\n# Create an enhanced scatter plot\nggplot(analysis_data, aes(x = tpcoiss, y = tpstress)) +\n  geom_point(alpha = 0.5, color = \"steelblue\") +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  labs(\n    title = \"Relationship between Stress and Control\",\n    subtitle = \"With linear regression line and 95% confidence interval\",\n    x = \"Sense of Control (tpcoiss)\",\n    y = \"Perceived Stress Level (tpstress)\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\nCreating the Regression Model\nWe’ll create our model and use modern packages to examine it:\n# Create the model\nmodel &lt;- lm(tpstress ~ tpcoiss, data = analysis_data)\n\n# Get a tidy summary using broom\ntidy_model &lt;- tidy(model, conf.int = TRUE)\nglance_model &lt;- glance(model)\n\n# Display tidy results\ntidy_model\nModel Diagnostics with performance\nThe performance package provides enhanced diagnostic tools:\n# Check model assumptions\ncheck_model(model)\n\n# Model performance metrics\nmodel_performance(model)\nCreating Publication-Ready Tables with sjPlot\nThe sjPlot, sjmisc, and sjlabelled packages creates beautiful HTML and Word-compatible tables:\n# Create regression table\ntab_model(model,\n          title = \"Linear Regression Results\",\n          dv.labels = \"Perceived Stress\",\n          pred.labels = c(\"(Intercept)\", \"Sense of Control\"))\n\n# Export tables in html or Word format\ntab_model(model, file = \"output/tables/regression_table.html\")\ntab_model(model, file = \"output/tables/regression_table.doc\")\nVisualizing Effects with ggeffects\nWe can visualize the relationship more clearly:\n# Plot predicted values\nplot_model(model, type = \"pred\") +\n  labs(\n    title = \"Predicted Stress Levels by Control\",\n    x = \"Sense of Control\",\n    y = \"Predicted Stress Level\"\n  )\nEnhanced Regression Diagnostics\nLet’s create more informative diagnostic plots using ggplot2:\n# Get augmented data (includes residuals, etc.)\nmodel_data &lt;- augment(model)\n\n# Create diagnostic plots\np1 &lt;- ggplot(model_data, aes(x = .fitted, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(title = \"Residuals vs Fitted\",\n       x = \"Fitted values\",\n       y = \"Residuals\") +\n  theme_minimal()\n\np2 &lt;- ggplot(model_data, aes(sample = .std.resid)) +\n  stat_qq() +\n  stat_qq_line() +\n  labs(title = \"Normal Q-Q Plot\") +\n  theme_minimal()\n\n# Arrange plots side by side\ndiagnostic_plots &lt;- ggarrange(p1, p2, ncol = 2)\n\n# Show combined plot\ndiagnostic_plots\n\n# Save combined plot as a pdf (change file ending for other formats)\nggsave(\"output/figures/diagnostic_plots.pdf\", plot = diagnostic_plots, width = 8, height = 5)\nMaking Predictions\nWe can use tidyverse functions for predictions:\n# Create new control values\nnew_control &lt;- tibble(tpcoiss = c(20, 30, 40))\n\n# Make predictions and bind results\npredictions &lt;- new_control %&gt;%\n  mutate(Predicted_Stress = predict(stress_model, newdata = .) %&gt;% round(2))\n\n# Display predictions\nprint(predictions)\nInteractive Model Summary\nWe can create an interactive summary of our model:\n# Create model summary\nsummary_stats &lt;- tibble(\n  Statistic = c(\"R-squared\", \"Adjusted R-squared\", \"F-statistic\", \"p-value\"),\n  Value = c(\n    glance_model$r.squared,\n    glance_model$adj.r.squared,\n    glance_model$statistic,\n    glance_model$p.value\n  )\n) %&gt;%\n  mutate(Value = round(Value, 3))\n\n# Display as a formatted table\nknitr::kable(summary_stats, \n             caption = \"Model Summary Statistics\")\nAdvantages of Using Modern Packages\nThese modern R packages offer several advantages over base R:\n\nBetter Visualization: ggplot2 creates publication-quality graphics\nTidy Output: broom makes statistical output easier to work with\nEnhanced Diagnostics: performance provides comprehensive model checking\nPublication-Ready Tables: sjPlot creates professional tables\nConsistent Interface: tidyverse provides a coherent framework"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#understanding-the-results",
    "href": "lab-uofg-02/lab-uofg-02.html#understanding-the-results",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "2.5 Understanding the Results",
    "text": "2.5 Understanding the Results\nLet’s break down each part of the output to understand what it tells us:\n\n2.5.1 1. The Correlation Coefficient (R)\nIn our case, we can find the correlation coefficient (r) by taking the square root of R-squared. The negative or positive sign comes from the slope coefficient in our regression output.\n# Calculate r from our model\nr &lt;- sign(coef(stress_model)[2]) * sqrt(summary(stress_model)$r.squared)\ncat(\"Correlation coefficient (r):\", round(r, 3))\nThis value tells us:\n\nThe strength of the relationship (how close to -1 or 1)\nThe direction (positive or negative)\n\n\n\n2.5.2 2. The ANOVA Table\nThe ANOVA table helps us assess if our model is statistically significant:\n# Display the ANOVA table\nanova(stress_model)\nLooking at the p-value (Pr(&gt;F)), we can see if our relationship is statistically significant. A value less than 0.05 suggests strong evidence of a real relationship between our variables.\n\n\n2.5.3 3. The Regression Equation\nFrom our coefficients table, we can write our regression equation:\n# Display coefficients\ncoef(stress_model)\nOur regression equation is:\nStress = β₀ + β₁(Control)\nWhere:\n\nβ₀ is our intercept (constant)\nβ₁ is our slope coefficient\n\nLet’s fill in the actual values:\n# Extract coefficients\nintercept &lt;- coef(stress_model)[1]\nslope &lt;- coef(stress_model)[2]\n\ncat(\"Regression equation:\\n\")\ncat(\"Stress =\", round(intercept, 3), \"+\", round(slope, 3), \"× Control\")\nThis equation means:\n\nWhen Control = 0, predicted Stress = intercept\nFor each one-unit increase in Control, Stress changes by the slope amount\n\n\n\n2.5.4 4. R-squared (R²)\nR-squared tells us how much of the variation in stress can be explained by control:\n# Extract R-squared\nr_squared &lt;- summary(stress_model)$r.squared\ncat(\"R-squared:\", round(r_squared, 3))\nThis means that approximately {round(r_squared * 100, 1)}% of the variation in stress levels can be explained by a person’s sense of control."
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#making-predictions",
    "href": "lab-uofg-02/lab-uofg-02.html#making-predictions",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "2.6 Making Predictions",
    "text": "2.6 Making Predictions\nWe can use our model to predict stress levels for new values of control:\n# Create some example control values\nnew_control &lt;- data.frame(tpcoiss = c(20, 30, 40))\n\n# Make predictions\npredictions &lt;- predict(stress_model, newdata = new_control)\n\n# Display predictions\ncbind(Control = new_control, Predicted_Stress = round(predictions, 2))"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#checking-model-assumptions",
    "href": "lab-uofg-02/lab-uofg-02.html#checking-model-assumptions",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "2.7 Checking Model Assumptions",
    "text": "2.7 Checking Model Assumptions\nFor our regression to be valid, we should check certain assumptions:\n# Create diagnostic plots\npar(mfrow = c(2, 2))\nplot(stress_model)\nThese plots help us check:\n\nLinearity (Residuals vs Fitted)\nNormality (Normal Q-Q)\nHomoscedasticity (Scale-Location)\nInfluential points (Residuals vs Leverage)"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#interpretation-guide",
    "href": "lab-uofg-02/lab-uofg-02.html#interpretation-guide",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "2.8 Interpretation Guide",
    "text": "2.8 Interpretation Guide\nWhen interpreting your regression results, consider:\n\nStatistical Significance\n\nLook at the p-value in the ANOVA table\nA p-value &lt; 0.05 suggests a significant relationship\n\nPractical Significance\n\nLook at R-squared to understand how much variance is explained\nConsider the slope coefficient for practical impact\n\nDirection of Relationship\n\nA negative slope means as one variable increases, the other decreases\nA positive slope means both variables increase together\n\nModel Assumptions\n\nCheck diagnostic plots for violations\nConsider transformations if assumptions are violated\n\n\n\n\n\n\n\n\nLinear Regression Analysis with R Packages\n\n\n\n\n\nIntroduction While base R provides solid foundations for linear regression, modern R packages offer enhanced capabilities for analysis, visualization, and interpretation. We’ll use several powerful packages that make our analysis more intuitive and visually appealing:\n# Install packages if needed\n# install.packages(c(\"tidyverse\", \"broom\", \"performance\", \"see\", \"ggpubr\", \"sjPlot\"))\n\n# Load required packages\nlibrary(tidyverse)    # For data manipulation and visualization\nlibrary(broom)        # For tidying statistical objects\nlibrary(performance)  # For model performance metrics\nlibrary(see)          # For model visualization\nlibrary(ggpubr)      # For publication-ready plots\nlibrary(sjPlot)      # For model visualization and tables\nData Preparation\nFirst, let’s prepare our data using tidyverse functions:\n# Create a focused dataset for analysis\nanalysis_data &lt;- survey_data_full %&gt;%\n  select(tpstress, tpcoiss) %&gt;%\n  drop_na()  # Remove any missing values\n\n# Quick summary of our variables\nsummary(analysis_data)\nVisual Exploration with ggplot2\nThe ggplot2 package (part of tidyverse) creates beautiful visualizations:\n# Create an enhanced scatter plot\nggplot(analysis_data, aes(x = tpcoiss, y = tpstress)) +\n  geom_point(alpha = 0.5, color = \"steelblue\") +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  labs(\n    title = \"Relationship between Stress and Control\",\n    subtitle = \"With linear regression line and 95% confidence interval\",\n    x = \"Sense of Control (PCOISS)\",\n    y = \"Perceived Stress Level\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\nCreating the Regression Model\nWe’ll create our model and use modern packages to examine it:\n# Create the model\nmodel &lt;- lm(tpstress ~ tpcoiss, data = analysis_data)\n\n# Get a tidy summary using broom\ntidy_model &lt;- tidy(model, conf.int = TRUE)\nglance_model &lt;- glance(model)\n\n# Display tidy results\ntidy_model\nModel Diagnostics with performance\nThe performance package provides enhanced diagnostic tools:\n# Check model assumptions\ncheck_model(model)\n\n# Model performance metrics\nmodel_performance(model)\nCreating Publication-Ready Tables with sjPlot\nThe sjPlot package creates beautiful HTML and Word-compatible tables:\n# Create regression table\ntab_model(model,\n          title = \"Linear Regression Results\",\n          dv.labels = \"Perceived Stress\",\n          pred.labels = c(\"(Intercept)\", \"Sense of Control\"))\nVisualizing Effects with ggeffects\nWe can visualize the relationship more clearly:\n# Plot predicted values\nplot_model(model, type = \"pred\") +\n  labs(\n    title = \"Predicted Stress Levels by Control\",\n    x = \"Sense of Control\",\n    y = \"Predicted Stress Level\"\n  )\nEnhanced Regression Diagnostics\nLet’s create more informative diagnostic plots using ggplot2:\n# Get augmented data (includes residuals, etc.)\nmodel_data &lt;- augment(model)\n\n# Create diagnostic plots\np1 &lt;- ggplot(model_data, aes(x = .fitted, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(title = \"Residuals vs Fitted\",\n       x = \"Fitted values\",\n       y = \"Residuals\") +\n  theme_minimal()\n\np2 &lt;- ggplot(model_data, aes(sample = .std.resid)) +\n  stat_qq() +\n  stat_qq_line() +\n  labs(title = \"Normal Q-Q Plot\") +\n  theme_minimal()\n\n# Arrange plots side by side\nggarrange(p1, p2, ncol = 2)\nMaking Predictions\nWe can use tidyverse functions for predictions:\n# Create new data for predictions\nnew_data %\n  bind_cols(predict(model, newdata = ., interval = \"confidence\"))\n\n# Plot predictions\nggplot(predictions, aes(x = tpcoiss)) +\n  geom_ribbon(aes(ymin = lwr, ymax = upr),\n              alpha = 0.2, fill = \"blue\") +\n  geom_line(aes(y = fit), color = \"blue\") +\n  geom_point(data = analysis_data,\n             aes(y = tpstress),\n             alpha = 0.5) +\n  labs(\n    title = \"Regression Line with Confidence Interval\",\n    x = \"Sense of Control\",\n    y = \"Stress Level\"\n  ) +\n  theme_minimal()\nInteractive Model Summary\nWe can create an interactive summary of our model:\n# Create model summary\nsummary_stats &lt;- tibble(\n  Statistic = c(\"R-squared\", \"Adjusted R-squared\", \"F-statistic\", \"p-value\"),\n  Value = c(\n    glance_model$r.squared,\n    glance_model$adj.r.squared,\n    glance_model$statistic,\n    glance_model$p.value\n  )\n) %&gt;%\n  mutate(Value = round(Value, 3))\n\n# Display as a formatted table\nknitr::kable(summary_stats, \n             caption = \"Model Summary Statistics\")\nAdvantages of Using Modern Packages\nThese modern R packages offer several advantages over base R:\n\nBetter Visualization: ggplot2 creates publication-quality graphics\nTidy Output: broom makes statistical output easier to work with\nEnhanced Diagnostics: performance provides comprehensive model checking\nPublication-Ready Tables: sjPlot creates professional tables\nConsistent Interface: tidyverse provides a coherent framework"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-e1-t-test",
    "href": "lab-uofg-02/lab-uofg-02.html#step-e1-t-test",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "3.1 Step E1: T-Test",
    "text": "3.1 Step E1: T-Test"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-e1-writing-up-results",
    "href": "lab-uofg-02/lab-uofg-02.html#step-e1-writing-up-results",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "3.2 Step E1: Writing Up Results",
    "text": "3.2 Step E1: Writing Up Results\nHere is an example for how to write up t-test results in APA format:\n\n“An independent-samples t-test was conducted to compare [variable] between males and females. There was a [significant/non-significant] difference in scores for males (M = XX.XX, SD = XX.XX) and females (M = XX.XX, SD = XX.XX); t(df) = XX.XX, p = .XXX. The magnitude of the differences in the means (mean difference = XX.XX, 95% CI: XX.XX to XX.XX) was [small/medium/large] (d = X.XX).”"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-h1-setup",
    "href": "lab-uofg-02/lab-uofg-02.html#step-h1-setup",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "6.1 Step H1: Setup",
    "text": "6.1 Step H1: Setup\nYou can continue working in the same project or working directory that you created in the previous lab and have been working in for the past exercises. You should, however, do the following:\n\nCreate a new R script: Go to File &gt; New File &gt; R Script.\nSave the script in your scripts folder with an appropriate name, e.g., Lab2_Exercise_H.R.\n\n\n\n\n\n\n\nNote\n\n\n\nTry to start with the empty script that you created above (Lab2_Exercise_H.R) and work through this exerise before looking at the solutions. But you can also download the R script for Exercise H and save the downloaded file in the scripts folder.\n\n\nNow you are ready to begin your work in R and continue with Step H2!"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-h2-frequency-tables",
    "href": "lab-uofg-02/lab-uofg-02.html#step-h2-frequency-tables",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "6.3 Step H2: Frequency Tables",
    "text": "6.3 Step H2: Frequency Tables\n\n\n\n\n\n\nWarning\n\n\n\n\n\nYellow/orange color with “!” icon"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-h3-hisogram",
    "href": "lab-uofg-02/lab-uofg-02.html#step-h3-hisogram",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "6.4 Step H3: Hisogram",
    "text": "6.4 Step H3: Hisogram"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-h4-cross-tabulation",
    "href": "lab-uofg-02/lab-uofg-02.html#step-h4-cross-tabulation",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "6.5 Step H4: Cross-Tabulation",
    "text": "6.5 Step H4: Cross-Tabulation"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-i1-setup",
    "href": "lab-uofg-02/lab-uofg-02.html#step-i1-setup",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "7.1 Step I1: Setup",
    "text": "7.1 Step I1: Setup\nYou can continue working in the same project or working directory that you created in the previous lab and have been working in for the past exercises. You should, however, do the following:\n\nCreate a new R script: Go to File &gt; New File &gt; R Script.\nSave the script in your scripts folder with an appropriate name, e.g., Lab2_Exercise_I.R.\n\n\n\n\n\n\n\nNote\n\n\n\nYou can either work through the following steps and copy/paste the respective code into the Lab_Exercise_I.R file that you will create in Step I1 or download the R script for Exercise H and follow the instructions below and save the downloaded file in the scripts folder that you will create.\n\n\nNow you are ready to begin your work in R and continue with Step I2!"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-e1-understanding-the-independent-samples-t-test",
    "href": "lab-uofg-02/lab-uofg-02.html#step-e1-understanding-the-independent-samples-t-test",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "3.1 Step E1: Understanding the Independent Samples t-test",
    "text": "3.1 Step E1: Understanding the Independent Samples t-test\nThe independent samples t-test is used when we have:\n\nA continuous dependent variable (like self-esteem scores)\nTwo independent groups (like males and females)\nIndependent observations (one person’s score doesn’t influence another’s)\n\nBefore we dive into our analysis, let’s prepare our data and create some helpful visualizations:\n# First, let's see what our data looks like\nhead(survey_data_full[c(\"sex\", \"tslfest\", \"tpcoiss\")])\n\n# Create boxplot with jittered points of self-esteem by gender\nggplot(survey_data_full, aes(x = factor(sex), y = tslfest)) +\n  geom_boxplot(aes(fill = factor(sex)), outlier.shape = NA) +  # Boxplot without default outliers\n  geom_jitter(width = 0.2, alpha = 0.5, color = \"darkgray\") +  # Individual points (jittered)\n  scale_fill_manual(values = c(\"lightblue\", \"lightpink\")) +\n  labs(\n    title = \"Distribution of Self-esteem by Gender\",\n    x = \"Gender\",\n    y = \"Total Self-esteem Score\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")  # Remove legend since colors only represent gender\nAs an alternative to a boxplot with jittered points, you can also create a violin plot. Violin plots are mirrored density plots for displaying of continuous distributions, similar to a boxplot.\n# Create violin plot with a small boxplot inside\nggplot(survey_data_full, aes(x = factor(sex), y = tslfest, fill = factor(sex))) +\n  geom_violin(trim = FALSE, alpha = 0.5) +  # Violin plot with full density curve\n  geom_boxplot(width = 0.2, fill = \"white\", outlier.shape = NA) +  # Add a small boxplot inside\n  scale_fill_manual(values = c(\"lightblue\", \"lightpink\")) + \n  labs(\n    title = \"Distribution of Self-esteem by Gender\",\n    x = \"Gender\",\n    y = \"Total Self-esteem Score\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")  # Remove legend since colors only represent gender"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-e2-performing-the-t-test-self-esteem-by-gender",
    "href": "lab-uofg-02/lab-uofg-02.html#step-e2-performing-the-t-test-self-esteem-by-gender",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "3.2 Step E2: Performing the T-Test (Self-esteem by Gender)",
    "text": "3.2 Step E2: Performing the T-Test (Self-esteem by Gender)\nLet’s conduct our first t-test examining self-esteem differences between genders:\n# First, let's check basic descriptive statistics\ntapply(survey_data_full$tslfest, \n       survey_data_full$sex, \n       function(x) c(mean = mean(x, na.rm = TRUE), \n                     sd = sd(x, na.rm = TRUE),\n                     n = sum(!is.na(x))))\n\n# Perform Levene's test for equality of variances\nvar_test &lt;- var.test(tslfest ~ sex, data = survey_data_full)\nprint(\"Levene's test results:\")\nprint(var_test)\n\n# Perform t-test based on Levene's test result\nt_test_result &lt;- t.test(tslfest ~ sex, \n                        data = survey_data_full,\n                        var.equal = var_test$p.value &gt; 0.05)  # true if p &gt; 0.05\nprint(\"\\nt-test results:\")\nprint(t_test_result)\nLet’s break down what these results tell us:\n\nLevene’s Test The p-value from our variance test helps us decide whether to assume equal variances. If p &gt; 0.05, we assume equal variances and use the standard t-test. If p &lt; 0.05, we use the Welch’s t-test which doesn’t assume equal variances.\nt-test Results\n\nThe t-statistic tells us how many standard errors the group means are apart\nThe degrees of freedom (df) help us determine critical values\nThe p-value tells us the probability of seeing such differences by chance\nThe confidence interval shows us the likely range of the true difference\n\nEffect Size Let’s calculate Cohen’s d to understand the practical significance:\n\n# Calculate Cohen's d\ngroup1 &lt;- survey_data_full$tslfest[survey_data_full$sex == \"Male\"]\ngroup2 &lt;- survey_data_full$tslfest[survey_data_full$sex == \"Female\"]\n\ncalc_cohens_d &lt;- function(x, y) {\n  # Remove NA values\n  x &lt;- x[!is.na(x)]\n  y &lt;- y[!is.na(y)]\n  \n  nx &lt;- length(x)\n  ny &lt;- length(y)\n  \n  # Ensure non-empty groups\n  if (nx &lt; 2 || ny &lt; 2) {\n    return(NA)  # Return NA if a group has fewer than 2 values\n  }\n  \n  pooled_sd &lt;- sqrt(((nx-1)*var(x) + (ny-1)*var(y))/(nx+ny-2))\n  abs(mean(x) - mean(y))/pooled_sd\n  \n  return(abs(mean(x) - mean(y)) / pooled_sd)\n}\n\neffect_size &lt;- calc_cohens_d(group1, group2)\ncat(\"Cohen's d effect size:\", round(effect_size, 3))\nNote: We purposefully do not call the function cohens_d as we will explore a function of the same name below when using the rstatix package. If we define a function with the same name, RStudio would refer to our custom defined function rather than using the function from the package.\n\n\n\n\n\n\nT-Tests with R Packages\n\n\n\n\n\nWe can use several R packages that provide enhanced capabilities for conducting and visualizing t-tests and work together to create a comprehensive analysis:\n# Install packages if needed\ninstall.packages(c(\"tidyverse\", \"car\", \"rstatix\", \"ggpubr\", \"effectsize\"))\n\n# Load required packages\nlibrary(tidyverse)  # For data manipulation and visualization\nlibrary(car)        # For Levene's test and additional diagnostics\nlibrary(rstatix)    # For statistical analysis\nlibrary(ggpubr)    # For publication-ready plots\nlibrary(effectsize) # For effect size calculations\nData Preparation\nFirst, let’s prepare our data and ensure it’s in the right format for analysis:\n# Create a small dataframe with relevant variables only\nanalysis_data &lt;- survey_data_full %&gt;% select(sex, tslfest, tpcoiss)\n\n# Display the structure of our prepared data\nstr(analysis_data)\nVisual Exploration\nThe ggplot2 package creates beautiful and informative visualizations (these are the same as in the base R solution, as we always use ggplot2 for visualizations):\n# Create boxplot with jittered points of self-esteem by gender\nggplot(analysis_data, aes(x = factor(sex), y = tslfest)) +\n  geom_boxplot(aes(fill = factor(sex)), outlier.shape = NA) +  # Boxplot without default outliers\n  geom_jitter(width = 0.2, alpha = 0.5, color = \"darkgray\") +  # Individual points (jittered)\n  scale_fill_manual(values = c(\"lightblue\", \"lightpink\")) +\n  labs(\n    title = \"Distribution of Self-esteem by Gender\",\n    x = \"Gender\",\n    y = \"Total Self-esteem Score\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")  # Remove legend since colors only represent gender\nHere is the code for the violin plot as an alternative to the boxplot with jittered points.\n# Alternative: Create violin plot with a small boxplot inside\nggplot(analysis_data, aes(x = factor(sex), y = tslfest, fill = factor(sex))) +\n  geom_violin(trim = FALSE, alpha = 0.5) +  # Violin plot with full density curve\n  geom_boxplot(width = 0.2, fill = \"white\", outlier.shape = NA) +  # Add a small boxplot inside\n  scale_fill_manual(values = c(\"lightblue\", \"lightpink\")) + \n  labs(\n    title = \"Distribution of Self-esteem by Gender\",\n    x = \"Gender\",\n    y = \"Total Self-esteem Score\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")  # Remove legend since colors only represent gender\nThe rstatix package can help us calculate descriptive statistics.\n# Add descriptive statistics\ndesc_stats &lt;- analysis_data %&gt;%\n  group_by(sex) %&gt;%\n  get_summary_stats(tslfest, type = \"common\")\n\nprint(desc_stats)\nChecking Assumptions\nModern packages provide comprehensive tools for checking t-test assumptions:\n\nNormality Check\n\nWe can check normality both visually and statistically:\n# Create Q-Q plots by group\nggqqplot(analysis_data, \"tslfest\", facet.by = \"sex\")\n\n# Shapiro-Wilk test for each group\nanalysis_data %&gt;%\n  group_by(sex) %&gt;%\n  shapiro_test(tslfest)\n\nHomogeneity of Variances\n\nThe car package provides a robust Levene’s test:\n# Levene's test using car package\nleveneTest(tslfest ~ sex, data = analysis_data)\nConducting the T-Test\nThe rstatix package provides a comprehensive t-test function:\n# Perform t-test\nt_test_results &lt;- analysis_data %&gt;%\n  t_test(tslfest ~ sex) %&gt;%\n  add_significance()\n\n# Display results\nt_test_results\nEffect Size Calculation\nThe rstatix has a function to calculte Cohen’s d:\n# # Calculate Cohen's d (using `rstatix` package)\ncohens_result &lt;- cohens_d(tslfest ~ sex, data = analysis_data)\nprint(cohens_result)\nThe effectsize package helps us understand the practical significance:\n# Interpret Cohen's d effect size\ninterpretation &lt;- interpret_cohens_d(cohens_result$Cohens_d)\n\n# Print interpretation\nprint(interpretation)\nAdvantages of Using Modern Packages\nThese modern R packages offer several benefits over base R:\n\nThe rstatix package provides:\n\nClearer output formatting\nAutomatic significance indicators\nBuilt-in assumption checking\n\nThe ggpubr package creates:\n\nPublication-ready plots\nEasy visualization of assumptions\nCombined plots with statistical results\n\nThe effectsize package offers:\n\nStandardized effect size calculations\nEffect size interpretation\nConfidence intervals for effect sizes\n\n\nCreating a Complete Report\nWe can create a comprehensive analysis report:\n# Function to run complete analysis\nanalyze_group_difference &lt;- function(data, dv, group_var) {\n  # Descriptive statistics\n  desc &lt;- data %&gt;%\n    group_by(!!sym(group_var)) %&gt;%\n    get_summary_stats(!!sym(dv), type = \"common\")\n  \n  # Assumption checks\n  normality &lt;- data %&gt;%\n    group_by(!!sym(group_var)) %&gt;%\n    shapiro_test(!!sym(dv))\n  \n  # Levene's test\n  homogeneity &lt;- leveneTest(as.formula(paste(dv, \"~\", group_var)), data = data)\n  \n  # T-test\n  t_test &lt;- data %&gt;%\n    t_test(as.formula(paste(dv, \"~\", group_var))) %&gt;%\n    add_significance()\n  \n  # Effect size\n  effect &lt;- cohens_d(as.formula(paste(dv, \"~\", group_var)), data = data)\n  \n  list(\n    descriptives = desc,\n    normality_test = normality,\n    variance_test = homogeneity,\n    t_test = t_test,\n    effect_size = effect\n  )\n}\n\n# Example usage\nself_esteem_analysis &lt;- analyze_group_difference(\n  analysis_data, \n  \"tslfest\", \n  \"sex\"\n)\n\n# Display results\nprint(self_esteem_analysis)\nWriting Up Results\nHere’s how to write up the results in APA format using our comprehensive analysis:\n# Create formatted output\nreport_results &lt;- function(analysis) {\n  with(analysis, {\n    cat(\"Results:\\n\")\n    cat(\"Descriptive Statistics:\\n\")\n    print(descriptives)\n    cat(\"\\nAssumption Tests:\\n\")\n    cat(\"Normality (Shapiro-Wilk):\\n\")\n    print(normality_test)\n    cat(\"\\nHomogeneity of Variance (Levene's Test):\\n\")\n    print(variance_test)\n    cat(\"\\nT-test Results:\\n\")\n    print(t_test)\n    cat(\"\\nEffect Size:\\n\")\n    print(effect_size)\n  })\n}\n\nreport_results(self_esteem_analysis)"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-e3-performing-the-t-test-control-levels-by-gender",
    "href": "lab-uofg-02/lab-uofg-02.html#step-e3-performing-the-t-test-control-levels-by-gender",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "3.3 Step E3: Performing the T-Test (Control Levels by Gender)",
    "text": "3.3 Step E3: Performing the T-Test (Control Levels by Gender)\nNow let’s examine our second research question about control levels between genders. First, we want to visually inspect the relationship between gender and perceived control:\n# Create boxplot with jittered points of perceived control by gender\nggplot(analysis_data, aes(x = factor(sex), y = tpcoiss)) +\n  geom_boxplot(aes(fill = factor(sex)), outlier.shape = NA) +  # Boxplot without default outliers\n  geom_jitter(width = 0.2, alpha = 0.5, color = \"darkgray\") +  # Individual points (jittered)\n  scale_fill_manual(values = c(\"lightblue\", \"lightpink\")) +\n  labs(\n    title = \"Distribution of Perceived Control by Gender\",\n    x = \"Gender\",\n    y = \"Perceived Control\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")  # Remove legend since colors only represent gender\nWe can also check descriptive statistics and perform the analysis.\n# Check basic descriptive statistics\ntapply(survey_data_full$tslfest, \n       survey_data_full$sex, \n       function(x) c(mean = mean(x, na.rm = TRUE), \n                     sd = sd(x, na.rm = TRUE),\n                     n = sum(!is.na(x))))\n\n# Perform Levene's test for equality of variances\nvar_test &lt;- var.test(tslfest ~ sex, data = survey_data_full)\nprint(\"Levene's test results:\")\nprint(var_test)\n\n# Perform t-test based on Levene's test result\nt_test_result &lt;- t.test(tslfest ~ sex, \n                        data = survey_data_full,\n                        var.equal = var_test$p.value &gt; 0.05)  # true if p &gt; 0.05\nprint(\"\\nt-test results:\")\nprint(t_test_result)\nLastly, we want to estimate the effect size using Cohen’s d. We are using our own function calc_cohens_d() that we created in Step E2.\n# Calculate Cohen's d\ngroup1 &lt;- survey_data_full$tslfest[survey_data_full$sex == \"Male\"]\ngroup2 &lt;- survey_data_full$tslfest[survey_data_full$sex == \"Female\"]\n\n# We defined our function `calc_cohens_d()` earlier.\n\neffect_size &lt;- calc_cohens_d(group1, group2)\ncat(\"Cohen's d effect size:\", round(effect_size, 3))\n\n\n\n\n\n\nT-Test (Control Levels by Gender) with R Packages\n\n\n\n\n\nWe can use the same R packages as in the previous example for conducting and visualizing t-tests and creating a comprehensive analysis. Below is the complete analysis for our second research question about control levels.\n# Create boxplot with jittered points of perceived control by gender\nggplot(analysis_data, aes(x = factor(sex), y = tpcoiss)) +\n  geom_boxplot(aes(fill = factor(sex)), outlier.shape = NA) +  # Boxplot without default outliers\n  geom_jitter(width = 0.2, alpha = 0.5, color = \"darkgray\") +  # Individual points (jittered)\n  scale_fill_manual(values = c(\"lightblue\", \"lightpink\")) +\n  labs(\n    title = \"Distribution of Perceived Control by Gender\",\n    x = \"Gender\",\n    y = \"Perceived Control\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")  # Remove legend since colors only represent gender\n\n# Check assumptions\n# 1. Normality\nanalysis_data %&gt;%\n  group_by(sex) %&gt;%\n  shapiro_test(tpcoiss)\n\n# 2. Homogeneity of variance\nleveneTest(tpcoiss ~ sex, data = analysis_data)\n\n# Perform t-test\ncontrol_t_test &lt;- analysis_data %&gt;%\n  t_test(tpcoiss ~ sex) %&gt;%\n  add_significance()\n\n# Calculate effect size\ncontrol_effect &lt;- cohens_d(tpcoiss ~ sex, data = analysis_data)\n\n# Display comprehensive results\nlist(\n  \"T-test Results\" = control_t_test,\n  \"Effect Size\" = control_effect\n)"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-e4-a-step-by-step-guide-to-interpreting-results",
    "href": "lab-uofg-02/lab-uofg-02.html#step-e4-a-step-by-step-guide-to-interpreting-results",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "3.4 Step E4: A Step-by-Step Guide to Interpreting Results",
    "text": "3.4 Step E4: A Step-by-Step Guide to Interpreting Results\nWhen interpreting t-test results, follow these steps:\n\nCheck Assumptions\n\nLook at the boxplots for obvious outliers\nCheck Levene’s test for equality of variances\n\nIf Levene’s test is significant (p &lt; 0.05), use the Welch’s t-test output (R does this automatically with var.equal = FALSE).\n\nConsider whether the groups are truly independent\nCheck if the data is normally distributed\n\nIf the data is not normally distributed, consider using non-parametric alternatives like the Wilcoxon rank-sum test:\n\n\n\n# Example of non-parametric test\nwilcox.test(tslfest ~ sex, data = survey_data_full)\n\nExamine the t-test Results\n\nLook at the p-value (significance level)\nConsider the confidence interval\nThink about the effect size\n\nDraw Conclusions\n\nIf p &lt; 0.05, we have evidence of a significant difference\nConsider the practical significance (effect size)\nThink about the real-world implications"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-e5-writing-up-results",
    "href": "lab-uofg-02/lab-uofg-02.html#step-e5-writing-up-results",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "3.5 Step E5: Writing Up Results",
    "text": "3.5 Step E5: Writing Up Results\nHere is an example for how to write up t-test results in APA format:\n\n“An independent-samples t-test was conducted to compare [variable] between males and females. There was a [significant/non-significant] difference in scores for males (M = XX.XX, SD = XX.XX) and females (M = XX.XX, SD = XX.XX); t(df) = XX.XX, p = .XXX. The magnitude of the differences in the means (mean difference = XX.XX, 95% CI: XX.XX to XX.XX) was [small/medium/large] (d = X.XX).”"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-f1-understanding-one-way-anova",
    "href": "lab-uofg-02/lab-uofg-02.html#step-f1-understanding-one-way-anova",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "4.1 Step F1: Understanding One-way ANOVA",
    "text": "4.1 Step F1: Understanding One-way ANOVA\nOne-way ANOVA is used when we have:\n\nA continuous dependent variable (like optimism scores).\nOne categorical independent variable with three or more groups (like age groups).\nIndependent observations (one person’s score doesn’t influence another’s).\n\nLet’s begin by preparing our data and creating some helpful visualizations:\n# First, let's prepare our age groups properly\nsurvey_data_full$agegp3 &lt;- factor(survey_data_full$agegp3, \n                                 levels = c(1, 2, 3),\n                                 labels = c(\"18-29\", \"30-44\", \"45+\"))\n\n# Create boxplot with jittered points of optimism levels by age group\nggplot(survey_data_full, aes(x = factor(agegp3), y = toptim)) +\n  geom_boxplot(aes(fill = factor(agegp3)), outlier.shape = NA) +  # Boxplot without default outliers\n#  geom_boxplot(aes(fill = factor(sex)), outlier.shape = NA) +  # Boxplot without default outliers\n  geom_jitter(width = 0.2, alpha = 0.5, color = \"darkgray\") +  # Individual points (jittered)\n  scale_fill_manual(values = c(\"lightblue\", \"lightgreen\", \"lightpink\")) +\n  labs(\n    title = \"Optimism Levels by Age Group\",\n    x = \"Age Group\",\n    y = \"Total Optimism Score\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")  # Remove legend since colors only represent gender"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-f2-performing-the-one-way-anova-optimism-across-age-groups",
    "href": "lab-uofg-02/lab-uofg-02.html#step-f2-performing-the-one-way-anova-optimism-across-age-groups",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "4.2 Step F2: Performing the One-Way ANOVA (Optimism Across Age Groups)",
    "text": "4.2 Step F2: Performing the One-Way ANOVA (Optimism Across Age Groups)\nBefore diving into the ANOVA, let’s examine our data descriptively:\n# Create comprehensive descriptive statistics\nget_descriptives &lt;- function(dv, group) {\n    tapply(dv, group, function(x) {\n        c(n = sum(!is.na(x)),\n          mean = mean(x, na.rm = TRUE),\n          sd = sd(x, na.rm = TRUE),\n          se = sd(x, na.rm = TRUE) / sqrt(sum(!is.na(x))))\n    })\n}\n\n# Get descriptives for optimism by age group\ndescriptives &lt;- get_descriptives(survey_data_full$toptim, \n                               survey_data_full$agegp3)\nprint(\"Descriptive Statistics:\")\nprint(descriptives)\nJust as t-tests have assumptions, ANOVA requires certain conditions to be met. Levene’s test is often performed before an ANOVA to ensure the validity of the ANOVA results by verifying that the variances across groups are similar (the “homogeneity of variance” assumption). However, Levene’s test uses the mean for deviations, making it appropriate if the data are normally distributed. We can perform the Shapiro-Wilk test, and if p &gt; 0.05, the data are approximately normally distributed and we can use Levene’s test.\n# Normality test (Shapiro-Wilk test)\nshapiro.test(survey_data_full$toptim)\n# Levene's test for homogeneity of variance\nlevene_test &lt;- function(y, group) {\n    group &lt;- factor(group)\n    means &lt;- tapply(y, group, mean, na.rm = TRUE)\n    abs_dev &lt;- abs(y - means[group])\n    anova(lm(abs_dev ~ group))[1, \"Pr(&gt;F)\"]\n}\n\n# Perform Levene's test\nlevene_p &lt;- levene_test(survey_data_full$toptim, survey_data_full$agegp3)\ncat(\"Levene's test p-value:\", levene_p, \"\\n\")\nIf p &gt; 0.05 from the Shapiro-Wilk test, the data are not normally distributed and the Brown-Forsythe test, which uses the median for deviations, is more appropriate.\n# Brown-Forsythe test (more robust to non-normality)\nbf_test &lt;- function(y, group) {\n    group &lt;- factor(group)\n    meds &lt;- tapply(y, group, median, na.rm = TRUE)\n    abs_dev &lt;- abs(y - meds[group])\n    anova(lm(abs_dev ~ group))[1, \"Pr(&gt;F)\"]\n}\n\nbf_p &lt;- bf_test(survey_data_full$toptim, survey_data_full$agegp3)\ncat(\"Brown-Forsythe test p-value:\", bf_p, \"\\n\")\nNow we’ll perform both standard ANOVA and its robust alternative:\n# Standard one-way ANOVA\nanova_result &lt;- aov(toptim ~ agegp3, data = survey_data_full)\nprint(\"Standard ANOVA results:\")\nprint(summary(anova_result))\n\n# Welch's ANOVA (robust to unequal variances)\nwelch_result &lt;- oneway.test(toptim ~ agegp3, \n                           data = survey_data_full, \n                           var.equal = FALSE)\nprint(\"\\nWelch's ANOVA results:\")\nprint(welch_result)\nWhen conducting an ANOVA test, a significant result indicates that at least one group mean differs from the others. However, ANOVA does not tell us which specific groups differ. To determine where these differences exist, we use Tukey’s Honest Significant Difference (HSD) test, which compares each pair of groups while controlling for multiple comparisons.\n# Tukey's HSD test for pairwise comparisons\ntukey_result &lt;- TukeyHSD(anova_result)\nprint(\"Tukey's HSD test results:\")\nprint(tukey_result)\n\n# Visualize the Tukey results\nplot(tukey_result)\nFollowing the steps below, we can confidently interpret the results of Tukey’s HSD test and understand which groups significantly differ from each other:\n\nCheck the p-value (p adj): If it is less than 0.05, the difference is statistically significant.\nLook at the confidence interval (lwr and upr): If the interval does not include 0, there is a meaningful difference.\nExamine the mean difference (diff): Determine whether one group has a higher or lower mean compared to another.\n\nLet’s calculate eta-squared to understand the practical significance. Statistical significance (i.e., a small p-value) does not tell us how important or meaningful the difference is in real-world terms. This is where effect size measures like eta-squared (η²) come in.\n# Calculate eta-squared\naov_summary &lt;- summary(anova_result)\neta_squared &lt;- aov_summary[[1]]$\"Sum Sq\"[1] / sum(aov_summary[[1]]$\"Sum Sq\")\ncat(\"Eta-squared:\", round(eta_squared, 3))\nCohen (1988) provides general guidelines for interpreting eta-squared in the context of ANOVA:\n\n0.01 (1%): The independent variable explains a small amount of variance (small effect).\n0.06 (6%): The independent variable explains a moderate amount of variance (medium effect).\n0.14+ (14% or more): The independent variable explains a large amount of variance (strong effect).\n\n\n\n\n\n\n\nANOVA with R Packages\n\n\n\n\n\nModern R packages provide enhanced capabilities for conducting and visualizing Analysis of Variance (ANOVA). We’ll use several powerful packages that work together to create a comprehensive analysis:\n# Install packages if needed\ninstall.packages(c(\"tidyverse\", \"car\", \"rstatix\", \"ggpubr\", \"effectsize\", \"emmeans\"))\n\n# Load required packages\nlibrary(tidyverse)  # For data manipulation and visualization\nlibrary(car)        # For Levene's test and additional diagnostics\nlibrary(rstatix)    # For statistical analysis\nlibrary(ggpubr)    # For publication-ready plots\nlibrary(effectsize) # For effect size calculations\nlibrary(emmeans)    # For estimated marginal means and post-hoc tests\nData Preparation\nFirst, let’s prepare our data and ensure it’s in the right format for analysis:\nanalysis_data &lt;- survey_data_full %&gt;%\n  select(agegp3, educ, toptim, tpstress)\n\n# Display the structure of our prepared data\nglimpse(analysis_data)\nVisual Exploration\nThe ggpubr package creates beautiful and informative visualizations:\n# Create violin plot with boxplot and individual points\nggviolin(analysis_data, \n         x = \"age_group\", \n         y = \"toptim\",\n         fill = \"age_group\",\n         add = \"boxplot\",\n         add.params = list(fill = \"white\")) +\n  geom_jitter(width = 0.2, alpha = 0.5) +\n  theme_minimal() +\n  labs(title = \"Optimism Levels by Age Group\",\n       y = \"Total Optimism Score\",\n       x = \"Age Group\") +\n  theme(legend.position = \"none\")\n\n# Add descriptive statistics\ndesc_stats &lt;- analysis_data %&gt;%\n  group_by(age_group) %&gt;%\n  get_summary_stats(toptim, type = \"common\")\nprint(desc_stats)\nChecking Assumptions\nModern packages provide comprehensive tools for checking ANOVA assumptions:\n\nNormality Check\n\nWe can check normality both visually and statistically:\n# Create Q-Q plots by group\nggqqplot(analysis_data, \"toptim\", facet.by = \"age_group\")\n\n# Shapiro-Wilk test for each group\nanalysis_data %&gt;%\n  group_by(age_group) %&gt;%\n  shapiro_test(toptim)\n\nHomogeneity of Variances\n\nThe car package provides both Levene’s and Brown-Forsythe tests:\n# Levene's test using car package\nleveneTest(toptim ~ age_group, data = analysis_data)\n\n# Brown-Forsythe test using car package\nleveneTest(toptim ~ age_group, data = analysis_data, center = median)\nConducting the ANOVA\nThe rstatix package provides comprehensive ANOVA functions:\n# Perform one-way ANOVA\nanova_results &lt;- analysis_data %&gt;%\n  anova_test(toptim ~ age_group) %&gt;%\n  add_significance()\n\n# Display results\nanova_results\n\n# Welch's ANOVA (robust to heterogeneity of variance)\nwelch_results &lt;- analysis_data %&gt;%\n  welch_anova_test(toptim ~ age_group)\n\nprint(\"Welch's ANOVA results:\")\nwelch_results\nPost-hoc Analysis\nModern packages offer various methods for post-hoc analysis:\n# Tukey's HSD using emmeans\nemmeans_result &lt;- emmeans(aov(toptim ~ age_group, data = analysis_data), \n                         \"age_group\")\npairs(emmeans_result)\n\n# Games-Howell post-hoc test (robust to heterogeneity of variance)\ngames_howell_result &lt;- analysis_data %&gt;%\n  games_howell_test(toptim ~ age_group)\nprint(\"Games-Howell test results:\")\ngames_howell_result\nEffect Size Calculation\nThe effectsize package helps us understand the practical significance:\n# Calculate eta squared\neta_squared &lt;- effectsize::eta_squared(aov(toptim ~ age_group, data = analysis_data))\nprint(eta_squared)\n\n# Interpret effect size\ninterpret_eta_squared(eta_squared$Eta2)\nComplete Analysis: Stress Levels Across Age Groups\nLet’s apply the same comprehensive analysis to perceived stress levels:\n# Visualization\nggviolin(analysis_data, \n         x = \"age_group\", \n         y = \"tpstress\",\n         fill = \"age_group\",\n         add = \"boxplot\",\n         add.params = list(fill = \"white\")) +\n  geom_jitter(width = 0.2, alpha = 0.5) +\n  theme_minimal() +\n  labs(title = \"Stress Levels by Age Group\",\n       y = \"Total Perceived Stress Score\",\n       x = \"Age Group\") +\n  theme(legend.position = \"none\")\n\n# Function for comprehensive ANOVA analysis\nanalyze_group_differences &lt;- function(data, dv, group_var) {\n  # Descriptive statistics\n  desc &lt;- data %&gt;%\n    group_by(!!sym(group_var)) %&gt;%\n    get_summary_stats(!!sym(dv), type = \"common\")\n  \n  # Assumption checks\n  normality &lt;- data %&gt;%\n    group_by(!!sym(group_var)) %&gt;%\n    shapiro_test(!!sym(dv))\n  \n  # Levene's test\n  homogeneity &lt;- leveneTest(as.formula(paste(dv, \"~\", group_var)), data = data)\n  \n  # ANOVA\n  anova &lt;- anova_test(data = data, as.formula(paste(dv, \"~\", group_var)))\n  \n  # Welch's ANOVA\n  welch &lt;- welch_anova_test(data = data, as.formula(paste(dv, \"~\", group_var)))\n  \n  # Post-hoc tests\n  posthoc &lt;- games_howell_test(data = data, as.formula(paste(dv, \"~\", group_var)))\n  \n  # Effect size\n  model &lt;- aov(as.formula(paste(dv, \"~\", group_var)), data = data)\n  effect &lt;- effectsize::eta_squared(model)\n  \n  # Return results\n  list(\n    descriptives = desc,\n    normality_test = normality,\n    variance_test = homogeneity,\n    anova_test = anova,\n    welch_test = welch,\n    posthoc = posthoc,\n    effect_size = effect\n  )\n}\n\n# Run complete analysis\nstress_analysis &lt;- analyze_group_differences(\n  analysis_data, \n  \"toptim\", \n  \"age_group\"\n)\n\n# Display results\nprint(stress_analysis)\nCreating Powerful Visualizations\nWe can create publication-ready plots that combine statistical information:\n# Create plot with statistical annotations\nggboxplot(analysis_data, \n          x = \"age_group\", \n          y = \"toptim\",\n          color = \"age_group\") +\n  stat_compare_means(method = \"anova\") +\n  geom_jitter(width = 0.2, alpha = 0.5) +\n  theme_minimal() +\n  labs(title = \"Optimism Levels by Age Group with ANOVA Results\",\n       y = \"Total Optimism Score\",\n       x = \"Age Group\") +\n  theme(legend.position = \"none\")\nAdvantages of Using Modern Packages\nThese modern R packages offer several benefits over base R:\n\nThe rstatix package provides:\n\nTidyverse-compatible statistical functions\nAutomatic assumption checking\nBuilt-in effect size calculations\n\nThe ggpubr package creates:\n\nPublication-ready plots\nEasy statistical annotations\nCombined plots with results\n\nThe emmeans package offers:\n\nSophisticated post-hoc analyses\nFlexible contrast specifications\nMultiple comparison adjustments\n\n\nWriting Up Results\nHere’s how to write up the results in APA format:\n# Function to create formatted output\nreport_anova_results &lt;- function(analysis) {\n  with(analysis, {\n    cat(\"Results:\\n\")\n    cat(\"\\nDescriptive Statistics:\\n\")\n    print(descriptives)\n    cat(\"\\nANOVA Results:\\n\")\n    print(anova_test)\n    cat(\"\\nEffect Size:\\n\")\n    print(effect_size)\n    cat(\"\\nPost-hoc Analysis:\\n\")\n    print(posthoc)\n  })\n}\n\nreport_anova_results(stress_analysis)"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-f3-performing-the-one-way-anova-stress-levels-across-age-groups",
    "href": "lab-uofg-02/lab-uofg-02.html#step-f3-performing-the-one-way-anova-stress-levels-across-age-groups",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "4.3 Step F3: Performing the One-Way ANOVA (Stress Levels Across Age Groups)",
    "text": "4.3 Step F3: Performing the One-Way ANOVA (Stress Levels Across Age Groups)\nLet’s apply what we’ve learned to analyze stress levels (tpstress) across age groups. First, we create some helpful visualizations:\n# Create an informative boxplot\nboxplot(tpstress ~ agegp3, \n        data = survey_data_full,\n        main = \"Total Perceived Stress by Age Group\",\n        xlab = \"Age Group\",\n        ylab = \"Total Perceived Stress\",\n        col = c(\"lightblue\", \"lightgreen\", \"lightpink\"))\n\n# Add individual points for better visualization\nstripchart(tpstress ~ agegp3, \n           data = survey_data_full,\n           vertical = TRUE,\n           method = \"jitter\",\n           add = TRUE,\n           pch = 20,\n           col = \"darkgray\")\nBefore diving into the ANOVA, let’s examine our data descriptively:\n# Create comprehensive descriptive statistics\nget_descriptives &lt;- function(dv, group) {\n    tapply(dv, group, function(x) {\n        c(n = sum(!is.na(x)),\n          mean = mean(x, na.rm = TRUE),\n          sd = sd(x, na.rm = TRUE),\n          se = sd(x, na.rm = TRUE) / sqrt(sum(!is.na(x))))\n    })\n}\n\n# Get descriptives for total perceived stress by age group\ndescriptives &lt;- get_descriptives(survey_data_full$tpstress, \n                               survey_data_full$agegp3)\nprint(\"Descriptive Statistics:\")\nprint(descriptives)\nJust as t-tests have assumptions, ANOVA requires certain conditions to be met:\n# Levene's test for homogeneity of variance\nlevene_test &lt;- function(y, group) {\n    group &lt;- factor(group)\n    meds &lt;- tapply(y, group, median, na.rm = TRUE)\n    abs_dev &lt;- abs(y - meds[group])\n    anova(lm(abs_dev ~ group))[1, \"Pr(&gt;F)\"]\n}\n\n# Perform Levene's test\nlevene_p &lt;- levene_test(survey_data_full$tpstress, survey_data_full$agegp3)\ncat(\"Levene's test p-value:\", levene_p, \"\\n\")\n\n# Brown-Forsythe test for a more robust check\nbf_test &lt;- function(y, group) {\n    group &lt;- factor(group)\n    meds &lt;- tapply(y, group, median, na.rm = TRUE)\n    abs_dev &lt;- abs(y - meds[group])\n    anova(lm(abs_dev ~ group))[1, \"Pr(&gt;F)\"]\n}\n\nbf_p &lt;- bf_test(survey_data_full$tpstress, survey_data_full$agegp3)\ncat(\"Brown-Forsythe test p-value:\", bf_p, \"\\n\")\nNow we’ll perform both standard ANOVA and its robust alternative:\n# Standard one-way ANOVA\nanova_result &lt;- aov(tpstress ~ agegp3, data = survey_data_full)\nprint(\"Standard ANOVA results:\")\nprint(summary(anova_result))\n\n# Welch's ANOVA (robust to unequal variances)\nwelch_result &lt;- oneway.test(tpstress ~ agegp3, \n                           data = survey_data_full, \n                           var.equal = FALSE)\nprint(\"\\nWelch's ANOVA results:\")\nprint(welch_result)\nIf we find significant differences, we need to know which groups differ from each other:\n# Tukey's HSD test for pairwise comparisons\ntukey_result &lt;- TukeyHSD(anova_result)\nprint(\"Tukey's HSD test results:\")\nprint(tukey_result)\n\n# Visualize the Tukey results\nplot(tukey_result)\nLet’s calculate eta-squared to understand the practical significance:\n# Calculate eta-squared\naov_summary &lt;- summary(anova_result)\neta_squared &lt;- aov_summary[[1]]$\"Sum Sq\"[1] / sum(aov_summary[[1]]$\"Sum Sq\")\ncat(\"Eta-squared:\", round(eta_squared, 3))"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-f1-writing-up-results",
    "href": "lab-uofg-02/lab-uofg-02.html#step-f1-writing-up-results",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "4.4 Step F1: Writing Up Results",
    "text": "4.4 Step F1: Writing Up Results\nHere’s how to write up ANOVA results in APA format:\n\n“A one-way between-groups analysis of variance was conducted to explore the impact of age on optimism levels. Participants were divided into three groups according to their age (Group 1: 18-29 years; Group 2: 30-44 years; Group 3: 45+ years). There was a [significant/non-significant] difference in optimism scores for the three age groups: F(2, XXX) = XX.XX, p = .XXX. The effect size, calculated using eta squared, was .XX. Post-hoc comparisons using the Tukey HSD test indicated that the mean score for Group 1 (M = XX.XX, SD = XX.XX) was significantly different from Group 2 (M = XX.XX, SD = XX.XX)…”"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-f4-a-step-by-step-guide-to-interpreting-results",
    "href": "lab-uofg-02/lab-uofg-02.html#step-f4-a-step-by-step-guide-to-interpreting-results",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "4.4 Step F4: A Step-by-Step Guide to Interpreting Results",
    "text": "4.4 Step F4: A Step-by-Step Guide to Interpreting Results\nWhen interpreting ANOVA results, follow these steps:\n\nCheck Assumptions\n\nReview Levene’s and Brown-Forsythe test results.\nConsider whether observations are truly independent.\nANOVA can handle unequal sample sizes, but you should pay extra attention to the homogeneity of variance assumption.\nExamine the boxplots for outliers and distribution shape. If the data isn’t normally distributed, consider using the non-parametric Kruskal-Wallis test:\n\n\n# Example of non-parametric alternative\nkruskal.test(toptim ~ agegp3, data = survey_data_full)\n\nExamine the ANOVA Results\n\nLook at the F-statistic and p-value\nConsider which ANOVA version to trust (standard or Welch’s)\nExamine effect sizes\n\nInterpret Post-hoc Tests\n\nLook for significant pairwise differences\nConsider the practical meaning of the differences\nThink about the confidence intervals"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-f5-writing-up-results",
    "href": "lab-uofg-02/lab-uofg-02.html#step-f5-writing-up-results",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "4.5 Step F5: Writing Up Results",
    "text": "4.5 Step F5: Writing Up Results\nHere’s how to write up ANOVA results in APA format:\n\n“A one-way between-groups analysis of variance was conducted to explore the impact of age on optimism levels. Participants were divided into three groups according to their age (Group 1: 18-29 years; Group 2: 30-44 years; Group 3: 45+ years). There was a [significant/non-significant] difference in optimism scores for the three age groups: F(2, XXX) = XX.XX, p = .XXX. The effect size, calculated using eta squared, was .XX. Post-hoc comparisons using the Tukey HSD test indicated that the mean score for Group 1 (M = XX.XX, SD = XX.XX) was significantly different from Group 2 (M = XX.XX, SD = XX.XX)…”"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-g1-setup",
    "href": "lab-uofg-02/lab-uofg-02.html#step-g1-setup",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "5.1 Step G1: Setup",
    "text": "5.1 Step G1: Setup"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-g1-chi-square-test-for-goodness-of-fit-smoking-rates",
    "href": "lab-uofg-02/lab-uofg-02.html#step-g1-chi-square-test-for-goodness-of-fit-smoking-rates",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "5.1 Step G1: Chi-Square Test for Goodness of Fit (Smoking Rates)",
    "text": "5.1 Step G1: Chi-Square Test for Goodness of Fit (Smoking Rates)\nImagine you’re wondering whether the proportion of smokers in your sample matches what you’d expect based on national statistics. This is exactly what a goodness of fit test helps us determine.\nIn this example, we check whether our sample’s smoking rate matches the expected population rate of 20%:\n# First, let's look at our data\nsmoker_table &lt;- table(survey_data_full$smoker)\nprint(\"Observed frequencies:\")\nprint(smoker_table)\n\n# Calculate percentages\nsmoker_props &lt;- prop.table(smoker_table) * 100\nprint(\"\\nObserved percentages:\")\nprint(round(smoker_props, 1))\n\n# Perform Chi-Square test\n# Expected proportions (20% smokers, 80% non-smokers)\nexpected_props &lt;- c(0.2, 0.8)\n\nchisq_result &lt;- chisq.test(smoker_table, p = expected_props)\n\n# Display detailed results\nprint(\"\\nChi-Square Test Results:\")\nprint(chisq_result)\n\n# Calculate and display expected frequencies\nn_total &lt;- sum(smoker_table)\nexpected_freq &lt;- n_total * expected_props\n\nprint(\"\\nComparison of observed vs expected frequencies:\")\ncomparison_df &lt;- data.frame(\n  Category = c(\"Smokers\", \"Non-smokers\"),\n  Observed = as.numeric(smoker_table),\n  Expected = expected_freq,\n  Difference = as.numeric(smoker_table) - expected_freq\n)\nprint(comparison_df)"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-g2-interpreting-goodness-of-fit-results",
    "href": "lab-uofg-02/lab-uofg-02.html#step-g2-interpreting-goodness-of-fit-results",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "5.2 Step G2: Interpreting Goodness of Fit Results",
    "text": "5.2 Step G2: Interpreting Goodness of Fit Results\nThe Chi-Square test gives us several pieces of information:\n\nThe Chi-Square statistic (χ²): Measures how different our observed values are from what we expected\nDegrees of freedom (df): The number of categories minus 1\np-value: Tells us whether any difference is statistically significant\n\nIn our example:\n\nIf p &lt; 0.05: The smoking rate in our sample is significantly different from 20%\nIf p ≥ 0.05: We don’t have evidence that our sample differs from the expected 20%\n\n\n\n\n\n\n\nChi-Square Test for Goodness of Fit with R Packages\n\n\n\n\n\nModern R packages provide enhanced capabilities for conducting and visualizing Chi-Square analyses. We’ll use several powerful packages that work together to create comprehensive and intuitive analyses:\n# Install packages if needed\ninstall.packages(c(\"tidyverse\", \"rstatix\", \"ggstatsplot\", \"ggsignif\", \n                   \"corrplot\", \"effectsize\", \"DescTools\"))\n\n# Load required packages\nlibrary(tidyverse)   # For data manipulation and visualization\nlibrary(rstatix)     # For statistical analysis\nlibrary(ggstatsplot) # For statistical visualization\nlibrary(ggsignif)    # For significance annotations\nlibrary(corrplot)    # For visualization of relationships\nlibrary(effectsize)  # For effect size calculations\nlibrary(DescTools)   # For additional statistical tools\nData Preparation\nLet’s prepare our data using tidyverse functions:\n# Prepare data for analysis\nanalysis_data %\n  mutate(\n    sex = factor(sex, levels = c(1, 2), labels = c(\"Male\", \"Female\")),\n    smoker = factor(smoker, levels = c(1, 2), labels = c(\"Smoker\", \"Non-smoker\"))\n  )\n\n# Display the structure of our prepared data\nglimpse(analysis_data)\nEnhanced Visualization of Observed vs Expected\nThe ggstatsplot package creates informative visualizations that include statistical results:\n# Create enhanced bar plot with statistical results\nggbarstats(\n  data = analysis_data,\n  x = smoker,\n  title = \"Observed vs Expected Smoking Rates\",\n  xlab = \"Smoking Status\",\n  ylab = \"Count\",\n  results.subtitle = TRUE,\n  subtitle = \"Testing against expected 20% smoking rate\",\n  type = \"parametric\",\n  paired = FALSE,\n  null.value = 0.2\n)\nComprehensive Statistical Analysis\nThe rstatix package provides clear statistical output:\n# Calculate observed frequencies\nobs_freq %\n  count(smoker) %&gt;%\n  mutate(\n    prop = n / sum(n),\n    expected_prop = c(0.2, 0.8),\n    expected_n = sum(n) * expected_prop,\n    contrib = (n - expected_n)^2 / expected_n\n  )\n\n# Display comprehensive results\nobs_freq %&gt;%\n  knitr::kable(digits = 3)\n\n# Perform test with effect size\nchisq_result %\n  add_significance()\n\n# Calculate effect size\neffect &lt;- cramers_v(table(analysis_data$smoker))\n\n# Display results\nlist(\n  \"Chi-square test results\" = chisq_result,\n  \"Effect size (Cramer's V)\" = effect\n)\nAdvantages of Modern Packages\n\nEnhanced Visualization\n\nOne-click visualization of observed vs expected frequencies\nAutomated proportion plots with error bars\nClear representation of deviations from expected values\n\nClearer Output\n\nFormatted tables comparing observed and expected frequencies\nClear presentation of test statistics\nAutomatic computation of standardized residuals\n\nAdditional Tools\n\nMultiple effect size measures (Cohen’s w, Cramer’s V)\nPower analysis capabilities\nEasy comparison with multiple expected distributions\n\nBetter Integration\n\nSimple workflow from data to visualization\nEasy export of results for reporting\nConsistent syntax across analyses\n\n\nBest Practices for Reporting\n\nReport:\n\nSample size and degrees of freedom\nExpected proportions and their source/justification\nChi-square statistic and exact p-value\nEffect size (typically Cohen’s w)\nVisual comparison of observed vs expected frequencies\n\nInclude:\n\nClear statement of the null hypothesis\nTable of observed and expected frequencies\nStandardized residuals for each category\nPower analysis if the result is non-significant\n\nConsider:\n\nWhether categories should be combined\nIf sample size is adequate\nAlternative tests for small samples"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-g3-chi-square-test-for-independence-smoking-and-gender",
    "href": "lab-uofg-02/lab-uofg-02.html#step-g3-chi-square-test-for-independence-smoking-and-gender",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "5.3 Step G3: Chi-Square Test for Independence (Smoking and Gender)",
    "text": "5.3 Step G3: Chi-Square Test for Independence (Smoking and Gender)\nNow let’s examine whether there’s a relationship between smoking and gender. This test helps us determine if two categorical variables are independent of each other.\nFirst, let’s create a cross-tabulation and examine our data:\n# Create cross-tabulation\ncross_tab &lt;- table(survey_data_full$sex, survey_data_full$smoker)\n\n# Add row and column names for clarity\ndimnames(cross_tab) &lt;- list(\n  Gender = c(\"Male\", \"Female\"),\n  Smoking = c(\"Smoker\", \"Non-smoker\")\n)\n\n# Display the cross-tabulation\nprint(\"Cross-tabulation of Gender and Smoking:\")\nprint(cross_tab)\n\n# Calculate and display percentages by gender\nprop_table &lt;- prop.table(cross_tab, margin = 1) * 100\nprint(\"\\nPercentages within each gender:\")\nprint(round(prop_table, 1))\nBefore performing the Chi-Square test of independence, we should check if our data meets the assumptions:\n# Calculate expected frequencies\nexpected &lt;- chisq.test(cross_tab)$expected\nprint(\"\\nExpected frequencies:\")\nprint(round(expected, 2))\n\n# Check if any expected frequencies are less than 5\nmin_expected &lt;- min(expected)\nprint(\"\\nMinimum expected frequency:\", min_expected)\nif(min_expected &lt; 5) {\n  print(\"Warning: Some expected frequencies are less than 5!\")\n}\nNow we can perform the Chi-Square test of independence:\n# Perform Chi-Square test with continuity correction (for 2x2 tables)\nchi_result &lt;- chisq.test(cross_tab, correct = TRUE)\nprint(\"\\nChi-Square Test Results:\")\nprint(chi_result)\n\n# Calculate effect size (Cramer's V)\nn &lt;- sum(cross_tab)\ncramer_v &lt;- sqrt(chi_result$statistic / (n * (min(dim(cross_tab)) - 1)))\nprint(\"\\nCramer's V:\", round(cramer_v, 3))\nTo understand effect sizes in a 2x2 table, we can interpret Cramer’s V as follows:\n\n0.1: Small effect\n0.3: Medium effect\n0.5: Large effect\n\nStandardized residuals help us understand which cells contribute most to any significant results:\n# Calculate adjusted standardized residuals\nstdres &lt;- chisq.test(cross_tab)$stdres\ndimnames(stdres) &lt;- dimnames(cross_tab)\nprint(\"\\nAdjusted standardized residuals:\")\nprint(round(stdres, 2))\nLet’s create some helpful visualizations:\n# Create barplot of smoking rates by gender\nbarplot(prop_table,\n        beside = TRUE,\n        main = \"Smoking Status by Gender\",\n        xlab = \"Smoking Status\",\n        ylab = \"Percentage\",\n        col = c(\"lightblue\", \"pink\"),\n        legend.text = TRUE)\n\n\n\n\n\n\nChi-Square Test for Independence with R Packages\n\n\n\n\n\nModern R packages provide enhanced capabilities for conducting and visualizing Chi-Square analyses. We’ll use several powerful packages that work together to create comprehensive and intuitive analyses:\n# Install packages if needed\ninstall.packages(c(\"tidyverse\", \"rstatix\", \"ggstatsplot\", \"ggsignif\", \n                   \"corrplot\", \"effectsize\", \"DescTools\"))\n\n# Load required packages\nlibrary(tidyverse)   # For data manipulation and visualization\nlibrary(rstatix)     # For statistical analysis\nlibrary(ggstatsplot) # For statistical visualization\nlibrary(ggsignif)    # For significance annotations\nlibrary(corrplot)    # For visualization of relationships\nlibrary(effectsize)  # For effect size calculations\nlibrary(DescTools)   # For additional statistical tools\nData Preparation\nLet’s prepare our data using tidyverse functions:\n# Prepare data for analysis\nanalysis_data %\n  mutate(\n    sex = factor(sex, levels = c(1, 2), labels = c(\"Male\", \"Female\")),\n    smoker = factor(smoker, levels = c(1, 2), labels = c(\"Smoker\", \"Non-smoker\"))\n  )\n\n# Display the structure of our prepared data\nglimpse(analysis_data)\nEnhanced Cross-tabulation Visualization\n# Create an enhanced visualization of the relationship\nggbarstats(\n  data = analysis_data,\n  x = sex,\n  y = smoker,\n  title = \"Relationship between Gender and Smoking Status\",\n  xlab = \"Gender\",\n  ylab = \"Proportion\",\n  label = \"percentage\",\n  results.subtitle = TRUE\n)\nComprehensive Analysis\n# Perform analysis with rstatix\nindependence_test %\n  tabyl(sex, smoker) %&gt;%\n  chisq_test() %&gt;%\n  add_significance()\n\n# Calculate effect size\nindependence_effect %\n  tabyl(sex, smoker) %&gt;%\n  cramer_v()\n\n# Display results\nlist(\n  \"Chi-square test results\" = independence_test,\n  \"Effect size (Cramer's V)\" = independence_effect\n)\nPost-hoc Analysis\nIf we find significant associations, we can examine standardized residuals:\n# Calculate and visualize standardized residuals\nresiduals_analysis %\n  tabyl(sex, smoker) %&gt;%\n  chisq_test() %&gt;%\n  subset_residuals()\n\n# Create heatmap of residuals\nggplot(residuals_analysis, aes(sex, smoker, fill = residual)) +\n  geom_tile() +\n  scale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\") +\n  geom_text(aes(label = round(residual, 2))) +\n  theme_minimal() +\n  labs(title = \"Standardized Residuals\",\n       fill = \"Residual\")\nEffect Size Visualization\nThe effectsize package helps understand practical significance:\n# Calculate and visualize effect sizes\neffect_size &lt;- effectsize::cramers_v(\n  table(analysis_data$sex, analysis_data$smoker)\n)\n\n# Create effect size plot\nplot(effect_size) +\n  theme_minimal() +\n  labs(title = \"Effect Size (Cramer's V) with Confidence Interval\")\nCreating a Complete Report\nWe can create a comprehensive analysis function:\nanalyze_categorical %\n        count(!!sym(var1)) %&gt;%\n        mutate(proportion = n/sum(n)),\n      \n      visualization = ggbarstats(\n        data = data,\n        x = !!sym(var1)\n      ),\n      \n      test = data %&gt;%\n        pull(!!sym(var1)) %&gt;%\n        table() %&gt;%\n        chisq_test() %&gt;%\n        add_significance(),\n      \n      effect = data %&gt;%\n        pull(!!sym(var1)) %&gt;%\n        table() %&gt;%\n        cramers_v()\n    )\n  } else {\n    # Independence test\n    result %\n        tabyl(!!sym(var1), !!sym(var2)),\n      \n      visualization = ggbarstats(\n        data = data,\n        x = !!sym(var1),\n        y = !!sym(var2)\n      ),\n      \n      test = data %&gt;%\n        tabyl(!!sym(var1), !!sym(var2)) %&gt;%\n        chisq_test() %&gt;%\n        add_significance(),\n      \n      effect = data %&gt;%\n        tabyl(!!sym(var1), !!sym(var2)) %&gt;%\n        cramer_v()\n    )\n  }\n  \n  return(result)\n}\n\n# Example usage\nsmoking_analysis &lt;- analyze_categorical(\n  data = analysis_data,\n  var1 = \"sex\",\n  var2 = \"smoker\"\n)\n\n# Display results\nsmoking_analysis\nAdvantages of Modern Packages\n\nEnhanced Visualization\n\nMosaic plots with statistical annotations\nHeat maps of associations\nInteractive contingency tables\n\nClearer Output\n\nWell-formatted contingency tables\nClear presentation of cell percentages\nHighlighted significant associations\n\nAdditional Tools\n\nMultiple association measures (Phi, Cramer’s V, Lambda)\nPost-hoc cell-wise tests\nAssumption checking for expected frequencies\n\nBetter Integration\n\nStreamlined workflow for multiple variables\nEasy integration with other categorical analyses\nConsistent reporting formats\n\n\nBest Practices for Reporting\n\nReport:\n\nComplete contingency table with row and column totals\nChi-square statistic and exact p-value\nEffect size (Cramer’s V or Phi for 2x2 tables)\nDegrees of freedom\nSmallest expected frequency\n\nInclude:\n\nCross-tabulation with percentages\nStandardized residuals for significant results\nVisual representation of the relationship\nConfidence intervals for proportions\n\nConsider:\n\nCell size assumptions\nNeed for Fisher’s exact test\nMultiple comparison corrections\nDirection and strength of associations"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-g4-writing-up-results",
    "href": "lab-uofg-02/lab-uofg-02.html#step-g4-writing-up-results",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "5.4 Step G4: Writing Up Results",
    "text": "5.4 Step G4: Writing Up Results\nHere’s how to write up the results of a goodness of fit test in a formal report:\n\n“A chi-square goodness of fit test was performed to determine whether the sample’s smoking rate differed from the expected population rate of 20%. The test revealed [insert significance statement based on results]. The observed rate was [X]% compared to the expected 20%.”\n\nAnd how to write up the results of an independence test in a formal report:\n\n“A chi-square test of independence was conducted to examine the relationship between gender and smoking status. All expected cell frequencies were greater than 5. The test revealed [insert significance statement based on results]. Among males, [X]% were smokers compared to [Y]% of females.”"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-h2-loading-the-dataset",
    "href": "lab-uofg-02/lab-uofg-02.html#step-h2-loading-the-dataset",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "6.2 Step H2: Loading the Dataset",
    "text": "6.2 Step H2: Loading the Dataset\nPlease download the dataset and download the code book and save both in the data folder within your project folder or working directory.\n# Load the CSV file stored in the \"data\" folder\nstaff_survey_data &lt;- read.csv(\"data/lab2-staff-survey.csv\")\nYou can easily explore and check the basic structure of your data and get a summary:\n# View the first few rows using head()\nhead(staff_survey_data)\n\n# Examine the structure\nstr(staff_survey_data)\n\n# Get basic summary statistics\nsummary(staff_survey_data)\nIn line with the code book, we want to assign labels to the variables in the staff_survey_data data frame using factors with labeled levels. This method ensures the data remains categorical but with human-readable labels for easier interpretation and analysis.\n# First, let's create vectors for our common level labels since they're reused often\nextent_levels &lt;- c(\"not at all\", \"to a slight extent\", \"to a moderate extent\", \n                  \"to a great extent\", \"to a very great extent\")\n\nimportance_levels &lt;- c(\"not important\", \"slightly important\", \"moderately important\",\n                      \"very important\", \"extremely important\")\n\n# Create age groups labels\nstaff_survey_data$age &lt;- factor(staff_survey_data$age,\n                               levels = 1:5,\n                               labels = c(\"under 20\", \"21 to 30\", \"31 to 40\",\n                                        \"41 to 50\", \"over 50\"))\n\n# Employment status\nstaff_survey_data$employstatus &lt;- factor(staff_survey_data$employstatus,\n                                        levels = 1:2,\n                                        labels = c(\"permanent\", \"casual\"))\n\n# Now let's handle the repeated patterns for Q1a through Q10a\n# We'll use a loop to avoid repetitive code\nfor(i in 1:10) {\n  # Convert \"extent\" questions (Q1a through Q10a)\n  staff_survey_data[[paste0(\"Q\", i, \"a\")]] &lt;- factor(\n    staff_survey_data[[paste0(\"Q\", i, \"a\")]],\n    levels = 1:5,\n    labels = extent_levels\n  )\n  \n  # Convert \"importance\" questions (Q1imp through Q10imp)\n  staff_survey_data[[paste0(\"Q\", i, \"imp\")]] &lt;- factor(\n    staff_survey_data[[paste0(\"Q\", i, \"imp\")]],\n    levels = 1:5,\n    labels = importance_levels\n  )\n}\n\n# Finally, convert the recommend variable\nstaff_survey_data$recommend &lt;- factor(staff_survey_data$recommend,\n                                    levels = c(0, 1),\n                                    labels = c(\"no\", \"yes\"))\n\n# Let's add a verification step to check our work\n# This will print the levels of each variable to confirm they're correctly labeled\nverify_factors &lt;- function(data) {\n  for(col in names(data)) {\n    if(is.factor(data[[col]])) {\n      cat(\"\\nLevels for\", col, \":\\n\")\n      print(levels(data[[col]]))\n    }\n  }\n}\n\n# Run the verification\nverify_factors(staff_survey_data)\nThe summary() function can also be used to confirm that the labels have been applied correctly to the variables.\n# Verify changes by printing a summary\nsummary(staff_survey_data)\nTry working through the folloing steps and answer the questions before looking at the solutions."
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-i2",
    "href": "lab-uofg-02/lab-uofg-02.html#step-i2",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "7.2 Step I2:",
    "text": "7.2 Step I2:"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-h5-total-staff-satisfaction",
    "href": "lab-uofg-02/lab-uofg-02.html#step-h5-total-staff-satisfaction",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "6.6 Step H5: Total Staff Satisfaction",
    "text": "6.6 Step H5: Total Staff Satisfaction\nHow do you think total staff satisfaction (totsatis) is calculated? Is there a difference in Total staff satisfaction among the two staff statuses? (Hint: t-test)\n\n\n\n\n\n\nSolution to Step H5\n\n\n\n\n\nTo understand how total staff satisfaction (totsatis) might be calculated, let’s examine its relationship with individual satisfaction items:\n# Identify satisfaction-related variables (Q*a)\nsatisfaction_vars &lt;- grep(\"Q.*a$\", names(staff_survey_data), value = TRUE)\n\n# Calculate correlations with total satisfaction\ncorrelations &lt;- sapply(staff_survey_data[satisfaction_vars], \n                      function(x) cor(x, staff_survey_data$totsatis,\n                                    use = \"complete.obs\"))\n\n# Print correlations\nprint(\"Correlations with Total Satisfaction:\")\nprint(round(correlations, 3))\n\n# Create scatterplot matrix of selected variables\npairs(staff_survey_data[c(satisfaction_vars[1:5], \"totsatis\")],\n      main = \"Relationships between Satisfaction Measures\")\nLet’s examine whether there are differences in total satisfaction between permanent and casual staff:\n# Calculate descriptive statistics by group\ntapply(staff_survey_data$totsatis, \n       staff_survey_data$employstatus,\n       function(x) c(n = length(x),\n                    mean = mean(x, na.rm = TRUE),\n                    sd = sd(x, na.rm = TRUE)))\n\n# Create box plot for visual comparison\nboxplot(totsatis ~ employstatus,\n        data = staff_survey_data,\n        main = \"Total Satisfaction by Employment Status\",\n        xlab = \"Employment Status\",\n        ylab = \"Total Satisfaction Score\",\n        col = \"lightblue\")\n\n# Add individual points for better visualization\nstripchart(totsatis ~ employstatus,\n           data = staff_survey_data,\n           vertical = TRUE,\n           method = \"jitter\",\n           add = TRUE,\n           pch = 20,\n           col = \"darkgray\")\n\n# Perform t-test\nsatisfaction_ttest &lt;- t.test(totsatis ~ employstatus, \n                           data = staff_survey_data)\n\n# Print t-test results\nprint(\"\\nt-test Results:\")\nprint(satisfaction_ttest)\n\n# Calculate effect size (Cohen's d)\ngroup1 &lt;- staff_survey_data$totsatis[staff_survey_data$employstatus == \"permanent\"]\ngroup2 &lt;- staff_survey_data$totsatis[staff_survey_data$employstatus == \"casual\"]\n\ncohens_d &lt;- function(x, y) {\n  nx &lt;- length(x)\n  ny &lt;- length(y)\n  pooled_sd &lt;- sqrt(((nx-1)*var(x) + (ny-1)*var(y))/(nx+ny-2))\n  abs(mean(x) - mean(y))/pooled_sd\n}\n\neffect_size &lt;- cohens_d(group1, group2)\nprint(paste(\"\\nEffect size (Cohen's d):\", round(effect_size, 3)))\nWhen interpreting these results, consider:\n\nConsider both statistical significance (p-value) and practical significance (effect size)\nLook at the distribution of scores within each group\nThink about potential confounding variables\n\n\n\n\n\n\n\n\n\n\nAlternative Solution to H5 with R Packages\n\n\n\n\n\nWe can also use R packages that work together to create comprehensive and intuitive analyses:\n# Install packages if needed\n# install.packages(c(\"tidyverse\", \"knitr\", \"kableExtra\"))\n\n# Load required packages\nlibrary(tidyverse)  # For data manipulation and visualization\nlibrary(knitr)      # For nice tables\nlibrary(kableExtra) # For enhanced table formatting\nThe total staff satisfaction score (totsatis) is likely calculated as a composite measure of various satisfaction-related questions in the survey. Let’s examine its components and distribution:\n# Examine the structure of satisfaction-related variables\nsatisfaction_vars &lt;- names(staff_survey_data)[grep(\"Q.*a$\", names(staff_survey_data))]\n\n# Look at correlations between these variables and totsatis\nsatisfaction_correlations &lt;- staff_survey_data %&gt;%\n  select(all_of(c(satisfaction_vars, \"totsatis\"))) %&gt;%\n  cor(use = \"complete.obs\")\n\n# Print correlations with total satisfaction\nkable(satisfaction_correlations[\"totsatis\", ],\n      digits = 3,\n      caption = \"Correlations with Total Satisfaction\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\nTo examine whether there are differences in total satisfaction between permanent and casual staff, we’ll conduct a t-test:\n# First, let's look at descriptive statistics\nsatisfaction_by_status &lt;- staff_survey_data %&gt;%\n  group_by(employstatus) %&gt;%\n  summarise(\n    n = n(),\n    mean = mean(totsatis, na.rm = TRUE),\n    sd = sd(totsatis, na.rm = TRUE),\n    se = sd/sqrt(n)\n  )\n\n# Print descriptive statistics\nkable(satisfaction_by_status,\n      digits = 2,\n      caption = \"Satisfaction Scores by Employment Status\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n# Create visualization\nggplot(staff_survey_data, aes(x = employstatus, y = totsatis)) +\n  geom_boxplot(fill = \"lightblue\") +\n  geom_jitter(width = 0.2, alpha = 0.2) +\n  theme_minimal() +\n  labs(x = \"Employment Status\",\n       y = \"Total Satisfaction Score\",\n       title = \"Distribution of Satisfaction Scores by Employment Status\")\n\n# Perform t-test\nsatisfaction_ttest &lt;- t.test(totsatis ~ employstatus, \n                           data = staff_survey_data)\n\n# Calculate effect size (Cohen's d)\ncohens_d &lt;- function(x, y) {\n  nx &lt;- length(x)\n  ny &lt;- length(y)\n  pooled_sd &lt;- sqrt(((nx-1)*var(x) + (ny-1)*var(y))/(nx+ny-2))\n  abs(mean(x) - mean(y))/pooled_sd\n}\n\neffect_size &lt;- with(staff_survey_data,\n                   cohens_d(totsatis[employstatus == \"permanent\"],\n                           totsatis[employstatus == \"casual\"]))\n\n# Print t-test results\nprint(satisfaction_ttest)\ncat(\"\\nEffect size (Cohen's d):\", round(effect_size, 3))"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-h3-frequency-tables",
    "href": "lab-uofg-02/lab-uofg-02.html#step-h3-frequency-tables",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "6.3 Step H3: Frequency Tables",
    "text": "6.3 Step H3: Frequency Tables\nCreate frequency tables of the demographic variables city, service, and employstatus.\nNote: The solution is provided in the callout notes below. We’ll explore the staff_survey_data using only base R functions (orange callout note) and also provide solutions using R packages (in the usual green callout notes). While modern packages offer many conveniences, understanding base R approaches provides a solid foundation and helps us appreciate the underlying statistical processes.\n\n\n\n\n\n\nSolution to Step H3\n\n\n\n\n\nLet’s begin by examining the distribution of our key demographic variables. Base R provides several functions for creating and formatting frequency tables:\n# Create frequency table for city\ncity_table &lt;- table(staff_survey_data$city)\ncity_props &lt;- prop.table(city_table) * 100\n\n# Combine counts and percentages\ncity_summary &lt;- cbind(\n  Frequency = as.vector(city_table),\n  Percentage = as.vector(city_props)\n)\nrownames(city_summary) &lt;- names(city_table)\n\n# Display the results with formatting\nprint(\"Distribution of Staff by City:\")\nprint(round(city_summary, 1))\n\n# Create frequency table for employment status\nstatus_table &lt;- table(staff_survey_data$employstatus)\nstatus_props &lt;- prop.table(status_table) * 100\n\nstatus_summary &lt;- cbind(\n  Frequency = as.vector(status_table),\n  Percentage = as.vector(status_props)\n)\nrownames(status_summary) &lt;- names(status_table)\n\nprint(\"\\nDistribution of Employment Status:\")\nprint(round(status_summary, 1))\n\n# Create frequency table for service\n# First, let's create reasonable bins for years of service\nservice_breaks &lt;- seq(0, max(staff_survey_data$service, na.rm = TRUE) + 5, by = 5)\nservice_cats &lt;- cut(staff_survey_data$service, \n                   breaks = service_breaks,\n                   include.lowest = TRUE)\n\nservice_table &lt;- table(service_cats)\nservice_props &lt;- prop.table(service_table) * 100\n\nservice_summary &lt;- cbind(\n  Frequency = as.vector(service_table),\n  Percentage = as.vector(service_props)\n)\nrownames(service_summary) &lt;- names(service_table)\n\nprint(\"\\nDistribution of Years of Service:\")\nprint(round(service_summary, 1))\nWhen interpreting these results, consider:\n\nLook for notable imbalances in group sizes\nConsider whether distributions match expectations\n\n\n\n\n\n\n\n\n\n\nAlternative Solution to H3 with R Packages\n\n\n\n\n\nWe can also use R packages that work together to create comprehensive and intuitive analyses:\n# Install packages if needed\ninstall.packages(c(\"tidyverse\", \"knitr\", \"kableExtra\"))\n\n# Load required packages\nlibrary(tidyverse)  # For data manipulation and visualization\nlibrary(knitr)      # For nice tables\nlibrary(kableExtra) # For enhanced table formatting\nFirst, we’ll create clear, informative frequency tables for our key demographic variables:\n# Function to create a nicely formatted frequency table\ncreate_freq_table &lt;- function(data, variable) {\n  data %&gt;%\n    count({{variable}}) %&gt;%\n    mutate(Percentage = n/sum(n) * 100) %&gt;%\n    kable(digits = 1,\n          col.names = c(\"Category\", \"Count\", \"Percentage\"),\n          caption = paste(\"Distribution of\", deparse(substitute(variable)))) %&gt;%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n}\n\n# Create tables for each demographic variable\ncreate_freq_table(staff_survey_data, city)\ncreate_freq_table(staff_survey_data, service)\ncreate_freq_table(staff_survey_data, employstatus)"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-h4-hisogram",
    "href": "lab-uofg-02/lab-uofg-02.html#step-h4-hisogram",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "6.4 Step H4: Hisogram",
    "text": "6.4 Step H4: Hisogram\nCreate a histogram of the demographic variable service and look for outliers.\n\n\n\n\n\n\nSolution to Step H4\n\n\n\n\n\nWe’ll create a histogram to understand the distribution of service years and identify potential outliers:\n# Create histogram\nhist(staff_survey_data$service,\n     main = \"Distribution of Years of Service\",\n     xlab = \"Years of Service\",\n     ylab = \"Frequency\",\n     breaks = 20,\n     col = \"lightblue\",\n     border = \"white\")\n\n# Add a box plot for outlier detection\nboxplot(staff_survey_data$service,\n        horizontal = TRUE,\n        main = \"Box Plot of Years of Service\",\n        xlab = \"Years of Service\",\n        col = \"lightblue\")\n\n# Reset plotting parameters\npar(mfrow = c(1, 1))\n\n# Calculate summary statistics\nservice_summary_stats &lt;- summary(staff_survey_data$service)\nservice_sd &lt;- sd(staff_survey_data$service, na.rm = TRUE)\n\n# Print summary statistics\nprint(\"\\nSummary Statistics for Years of Service:\")\nprint(service_summary_stats)\nprint(paste(\"Standard Deviation:\", round(service_sd, 2)))\n\n# Identify potential outliers using the 1.5 * IQR rule\nQ1 &lt;- quantile(staff_survey_data$service, 0.25, na.rm = TRUE)\nQ3 &lt;- quantile(staff_survey_data$service, 0.75, na.rm = TRUE)\nIQR &lt;- Q3 - Q1\noutlier_threshold_upper &lt;- Q3 + 1.5 * IQR\noutlier_threshold_lower &lt;- Q1 - 1.5 * IQR\n\noutliers &lt;- staff_survey_data$service[staff_survey_data$service &gt; outlier_threshold_upper |\n                                    staff_survey_data$service &lt; outlier_threshold_lower]\n\nif(length(outliers) &gt; 0) {\n  print(\"\\nPotential outliers identified:\")\n  print(sort(outliers))\n}\nWhen interpreting these results, consider:\n\nNote the shape of the distribution\nIdentify any unusual patterns or gaps\nConsider whether outliers represent errors or true values\n\n\n\n\n\n\n\n\n\n\nAlternative Solution to H4 with R Packages\n\n\n\n\n\nWe can also use R packages that work together to create comprehensive and intuitive analyses:\n# Install packages if needed\ninstall.packages(c(\"tidyverse\", \"knitr\", \"kableExtra\"))\n\n# Load required packages\nlibrary(tidyverse)  # For data manipulation and visualization\nlibrary(knitr)      # For nice tables\nlibrary(kableExtra) # For enhanced table formatting\nLet’s create a detailed histogram to understand the distribution of years of service and identify any potential outliers:\n# Create histogram with density curve\nggplot(staff_survey_data, aes(x = service)) +\n  geom_histogram(aes(y = ..density..), \n                 bins = 30,\n                 fill = \"lightblue\",\n                 color = \"black\") +\n  geom_density(color = \"red\") +\n  theme_minimal() +\n  labs(x = \"Years of Service\",\n       y = \"Density\",\n       title = \"Distribution of Years of Service\",\n       subtitle = \"With density curve overlay\") +\n  # Add boxplot for outlier visualization\n  geom_boxplot(aes(y = -0.02), width = 0.1)\n\n# Calculate summary statistics for service\nservice_summary &lt;- staff_survey_data %&gt;%\n  summarize(\n    Mean = mean(service, na.rm = TRUE),\n    Median = median(service, na.rm = TRUE),\n    SD = sd(service, na.rm = TRUE),\n    Q1 = quantile(service, 0.25, na.rm = TRUE),\n    Q3 = quantile(service, 0.75, na.rm = TRUE),\n    IQR = IQR(service, na.rm = TRUE),\n    Min = min(service, na.rm = TRUE),\n    Max = max(service, na.rm = TRUE)\n  )\n\n# Print summary statistics\nkable(service_summary, digits = 1,\n      caption = \"Summary Statistics for Years of Service\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n# Identify potential outliers\noutliers &lt;- staff_survey_data %&gt;%\n  filter(service &gt; (service_summary$Q3 + 1.5 * service_summary$IQR) |\n         service &lt; (service_summary$Q1 - 1.5 * service_summary$IQR))\nLooking at the distribution of years of service, we can observe:\n\nThe shape of the distribution (whether it’s symmetric or skewed)\nAny unusual patterns or gaps\nPotential outliers, which we’ve identified using the 1.5 × IQR rule"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-h5-cross-tabulation",
    "href": "lab-uofg-02/lab-uofg-02.html#step-h5-cross-tabulation",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "6.5 Step H5: Cross-Tabulation",
    "text": "6.5 Step H5: Cross-Tabulation\nCross-tabulate and study the age groups (agerecode) against employstatus.\n\n\n\n\n\n\nSolution to Step H5\n\n\n\n\n\nLet’s examine the relationship between age groups and employment status using a cross-tabulation:\n# Create cross-tabulation\nage_employ_table &lt;- table(staff_survey_data$agerecode, \n                         staff_survey_data$employstatus)\n\n# Calculate row percentages\nage_employ_props &lt;- prop.table(age_employ_table, margin = 1) * 100\n\n# Print the results\nprint(\"Counts by Age Group and Employment Status:\")\nprint(age_employ_table)\nprint(\"\\nPercentages within Age Groups:\")\nprint(round(age_employ_props, 1))\n\n# Create a visual representation using base R\n# Set up the plotting area\nbarplot(t(age_employ_props),\n        beside = TRUE,\n        col = c(\"lightblue\", \"lightgreen\"),\n        main = \"Employment Status by Age Group\",\n        xlab = \"Age Group\",\n        ylab = \"Percentage\",\n        legend.text = colnames(age_employ_props))\n\n# Perform chi-square test of independence\nchi_sq_test &lt;- chisq.test(age_employ_table)\nprint(\"\\nChi-square test of independence:\")\nprint(chi_sq_test)\nWhen interpreting these results, consider:\n\nLook for patterns in employment type across age groups\nConsider the chi-square test results\nThink about implications for workforce planning\n\n\n\n\n\n\n\n\n\n\nAlternative Solution to H5 with R Packages\n\n\n\n\n\nWe can also use R packages that work together to create comprehensive and intuitive analyses:\n# Install packages if needed\ninstall.packages(c(\"tidyverse\", \"knitr\", \"kableExtra\"))\n\n# Load required packages\nlibrary(tidyverse)  # For data manipulation and visualization\nlibrary(knitr)      # For nice tables\nlibrary(kableExtra) # For enhanced table formatting\nLet’s examine the relationship between age groups and employment status:\n# Create cross-tabulation\nage_employ_table &lt;- table(staff_survey_data$agerecode, \n                         staff_survey_data$employstatus)\n\n# Convert to percentages and format nicely\nage_employ_props &lt;- prop.table(age_employ_table, margin = 1) * 100\n\n# Combine counts and percentages in a nice table\nage_employ_combined &lt;- cbind(\n  as.data.frame.matrix(age_employ_table),\n  as.data.frame.matrix(age_employ_props)\n) %&gt;%\n  setNames(c(\"Permanent (n)\", \"Casual (n)\", \n             \"Permanent (%)\", \"Casual (%)\"))\n\nkable(age_employ_combined, \n      digits = 1,\n      caption = \"Age Groups by Employment Status\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n# Create a visualization\nggplot(staff_survey_data, \n       aes(x = agerecode, fill = employstatus)) +\n  geom_bar(position = \"fill\") +\n  theme_minimal() +\n  labs(x = \"Age Group\",\n       y = \"Proportion\",\n       fill = \"Employment Status\",\n       title = \"Employment Status Distribution by Age Group\") +\n  coord_flip()"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-h6-total-staff-satisfaction",
    "href": "lab-uofg-02/lab-uofg-02.html#step-h6-total-staff-satisfaction",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "6.6 Step H6: Total Staff Satisfaction",
    "text": "6.6 Step H6: Total Staff Satisfaction\nHow do you think total staff satisfaction (totsatis) is calculated? Is there a difference in Total staff satisfaction among the two staff statuses? (Hint: t-test)\n\n\n\n\n\n\nSolution to Step H6\n\n\n\n\n\nTo understand how total staff satisfaction (totsatis) might be calculated, let’s examine its relationship with individual satisfaction items:\n# Identify satisfaction-related variables (Q*a)\nsatisfaction_vars &lt;- grep(\"Q.*a$\", names(staff_survey_data), value = TRUE)\n\n# Calculate correlations with total satisfaction\ncorrelations &lt;- sapply(staff_survey_data[satisfaction_vars], \n                      function(x) cor(x, staff_survey_data$totsatis,\n                                    use = \"complete.obs\"))\n\n# Print correlations\nprint(\"Correlations with Total Satisfaction:\")\nprint(round(correlations, 3))\n\n# Create scatterplot matrix of selected variables\npairs(staff_survey_data[c(satisfaction_vars[1:5], \"totsatis\")],\n      main = \"Relationships between Satisfaction Measures\")\nLet’s examine whether there are differences in total satisfaction between permanent and casual staff:\n# Calculate descriptive statistics by group\ntapply(staff_survey_data$totsatis, \n       staff_survey_data$employstatus,\n       function(x) c(n = length(x),\n                    mean = mean(x, na.rm = TRUE),\n                    sd = sd(x, na.rm = TRUE)))\n\n# Create box plot for visual comparison\nboxplot(totsatis ~ employstatus,\n        data = staff_survey_data,\n        main = \"Total Satisfaction by Employment Status\",\n        xlab = \"Employment Status\",\n        ylab = \"Total Satisfaction Score\",\n        col = \"lightblue\")\n\n# Add individual points for better visualization\nstripchart(totsatis ~ employstatus,\n           data = staff_survey_data,\n           vertical = TRUE,\n           method = \"jitter\",\n           add = TRUE,\n           pch = 20,\n           col = \"darkgray\")\n\n# Perform t-test\nsatisfaction_ttest &lt;- t.test(totsatis ~ employstatus, \n                           data = staff_survey_data)\n\n# Print t-test results\nprint(\"\\nt-test Results:\")\nprint(satisfaction_ttest)\n\n# Calculate effect size (Cohen's d)\ngroup1 &lt;- staff_survey_data$totsatis[staff_survey_data$employstatus == \"permanent\"]\ngroup2 &lt;- staff_survey_data$totsatis[staff_survey_data$employstatus == \"casual\"]\n\ncohens_d &lt;- function(x, y) {\n  nx &lt;- length(x)\n  ny &lt;- length(y)\n  pooled_sd &lt;- sqrt(((nx-1)*var(x) + (ny-1)*var(y))/(nx+ny-2))\n  abs(mean(x) - mean(y))/pooled_sd\n}\n\neffect_size &lt;- cohens_d(group1, group2)\nprint(paste(\"\\nEffect size (Cohen's d):\", round(effect_size, 3)))\nWhen interpreting these results, consider:\n\nConsider both statistical significance (p-value) and practical significance (effect size)\nLook at the distribution of scores within each group\nThink about potential confounding variables\n\n\n\n\n\n\n\n\n\n\nAlternative Solution to H6 with R Packages\n\n\n\n\n\nWe can also use R packages that work together to create comprehensive and intuitive analyses:\n# Install packages if needed\ninstall.packages(c(\"tidyverse\", \"knitr\", \"kableExtra\"))\n\n# Load required packages\nlibrary(tidyverse)  # For data manipulation and visualization\nlibrary(knitr)      # For nice tables\nlibrary(kableExtra) # For enhanced table formatting\nThe total staff satisfaction score (totsatis) is likely calculated as a composite measure of various satisfaction-related questions in the survey. Let’s examine its components and distribution:\n# Examine the structure of satisfaction-related variables\nsatisfaction_vars &lt;- names(staff_survey_data)[grep(\"Q.*a$\", names(staff_survey_data))]\n\n# Look at correlations between these variables and totsatis\nsatisfaction_correlations &lt;- staff_survey_data %&gt;%\n  select(all_of(c(satisfaction_vars, \"totsatis\"))) %&gt;%\n  cor(use = \"complete.obs\")\n\n# Print correlations with total satisfaction\nkable(satisfaction_correlations[\"totsatis\", ],\n      digits = 3,\n      caption = \"Correlations with Total Satisfaction\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\nTo examine whether there are differences in total satisfaction between permanent and casual staff, we’ll conduct a t-test:\n# First, let's look at descriptive statistics\nsatisfaction_by_status &lt;- staff_survey_data %&gt;%\n  group_by(employstatus) %&gt;%\n  summarise(\n    n = n(),\n    mean = mean(totsatis, na.rm = TRUE),\n    sd = sd(totsatis, na.rm = TRUE),\n    se = sd/sqrt(n)\n  )\n\n# Print descriptive statistics\nkable(satisfaction_by_status,\n      digits = 2,\n      caption = \"Satisfaction Scores by Employment Status\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n# Create visualization\nggplot(staff_survey_data, aes(x = employstatus, y = totsatis)) +\n  geom_boxplot(fill = \"lightblue\") +\n  geom_jitter(width = 0.2, alpha = 0.2) +\n  theme_minimal() +\n  labs(x = \"Employment Status\",\n       y = \"Total Satisfaction Score\",\n       title = \"Distribution of Satisfaction Scores by Employment Status\")\n\n# Perform t-test\nsatisfaction_ttest &lt;- t.test(totsatis ~ employstatus, \n                           data = staff_survey_data)\n\n# Calculate effect size (Cohen's d)\ncohens_d &lt;- function(x, y) {\n  nx &lt;- length(x)\n  ny &lt;- length(y)\n  pooled_sd &lt;- sqrt(((nx-1)*var(x) + (ny-1)*var(y))/(nx+ny-2))\n  abs(mean(x) - mean(y))/pooled_sd\n}\n\neffect_size &lt;- with(staff_survey_data,\n                   cohens_d(totsatis[employstatus == \"permanent\"],\n                           totsatis[employstatus == \"casual\"]))\n\n# Print t-test results\nprint(satisfaction_ttest)\ncat(\"\\nEffect size (Cohen's d):\", round(effect_size, 3))"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-i2-loading-the-dataset",
    "href": "lab-uofg-02/lab-uofg-02.html#step-i2-loading-the-dataset",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "7.2 Step I2: Loading the Dataset",
    "text": "7.2 Step I2: Loading the Dataset\nPlease download the dataset and save the file in the data folder within your project folder or working directory.\n# Load the CSV file stored in the \"data\" folder\nsleep_survey_data &lt;- read.csv(\"data/lab2-sleep-survey.csv\")\nYou can easily explore and check the basic structure of your data and get a summary:\n# View the first few rows using head()\nhead(sleep_survey_data)\n\n# Examine the structure\nstr(sleep_survey_data)\n\n# Get basic summary statistics\nsummary(sleep_survey_data)\nWe want to assign labels to some of the categorical variables in the sleep_survey_data data frame using factors with labeled levels. This method ensures the data remains categorical but with human-readable labels for easier interpretation and analysis.\n# Let's start by creating our factor labels in a clear, organized way.\n# When working with binary variables (0/1), it's especially important to be \n# consistent with our labeling approach.\n\n# First, let's handle the binary (0/1) variables\n# We'll create these first since they share the same structure\nsleep_survey_data$sex &lt;- factor(sleep_survey_data$sex,\n                               levels = c(0, 1),\n                               labels = c(\"female\", \"male\"))\n\nsleep_survey_data$probsleep &lt;- factor(sleep_survey_data$probsleep,\n                                     levels = c(0, 1),\n                                     labels = c(\"no\", \"yes\"))\n\nsleep_survey_data$fallsleep &lt;- factor(sleep_survey_data$fallsleep,\n                                     levels = c(0, 1),\n                                     labels = c(\"no\", \"yes\"))\n\nsleep_survey_data$staysleep &lt;- factor(sleep_survey_data$staysleep,\n                                     levels = c(0, 1),\n                                     labels = c(\"no\", \"yes\"))\n\n# Now let's handle the categorical variables with multiple levels\n# For these, we'll use more descriptive labels\nsleep_survey_data$marital &lt;- factor(sleep_survey_data$marital,\n                                   levels = 1:4,\n                                   labels = c(\"single\", \n                                            \"married/defacto\",\n                                            \"divorced\",\n                                            \"widowed\"))\n\nsleep_survey_data$edlevel &lt;- factor(sleep_survey_data$edlevel,\n                                   levels = 1:5,\n                                   labels = c(\"primary school\",\n                                            \"secondary school\",\n                                            \"trade training\",\n                                            \"undergraduate degree\",\n                                            \"postgraduate degree\"))\n\n# Let's add a verification step to make sure our conversions worked correctly\n# This function will print the levels of each factor variable we created\nverify_factors &lt;- function(data) {\n    cat(\"Checking factor levels for all converted variables:\\n\\n\")\n    \n    # List of variables we converted\n    factor_vars &lt;- c(\"sex\", \"probsleep\", \"fallsleep\", \"staysleep\", \n                     \"marital\", \"edlevel\")\n    \n    for(var in factor_vars) {\n        cat(paste0(\"Levels for \", var, \":\\n\"))\n        print(levels(data[[var]]))\n        cat(\"\\n\")\n    }\n}\n\n# Run the verification\nverify_factors(sleep_survey_data)"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-i3-logistic-regression",
    "href": "lab-uofg-02/lab-uofg-02.html#step-i3-logistic-regression",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "7.3 Step I3: Logistic Regression",
    "text": "7.3 Step I3: Logistic Regression\n\n7.3.1 What is Logistic Regression?\nLogistic regression is a statistical method used when we want to predict a categorical outcome (like yes/no, pass/fail) based on one or more predictor variables. Think of it as answering questions like “What factors influence whether someone has sleep problems?” or “What characteristics predict if a student will pass an exam?”\nWe use logistic regression when:\n\nOur outcome variable is categorical (usually binary).\nWe have multiple predictor variables (can be continuous or categorical).\nWe want to understand both prediction and relationships.\n\nIn our sleep study, we’re trying to predict whether someone has sleep problems (yes/no) based on various characteristics and behaviors.\nUnderstanding the Math (In Simple Terms)\nWhile regular regression predicts actual values (like height or weight), logistic regression predicts the probability of belonging to a category (like having sleep problems). It uses a special S-shaped curve called a logistic function that keeps predictions between 0 and 1 (or 0% to 100% probability).\n\n\n7.3.2 Initial Data Preparation\nLet’s prepare our data and examine our sample:\n# First, let's check our sample size and missing data\ninitial_sample &lt;- nrow(sleep_survey_data)\ncomplete_cases &lt;- sum(complete.cases(sleep_survey_data[\n  c(\"probsleep\", \"sex\", \"age\", \"fallsleep\", \"staysleep\", \"hrswknight\")\n]))\n\n# Print sample information\ncat(\"Total cases:\", initial_sample, \"\\n\")\ncat(\"Complete cases:\", complete_cases, \"\\n\")\ncat(\"Missing cases:\", initial_sample - complete_cases, \"\\n\")\n\n# Check coding of categorical variables\ncat(\"\\nCoding of categorical variables:\\n\")\ncat(\"\\nSleep Problems (probsleep):\\n\")\nprint(table(sleep_survey_data$probsleep))\n\ncat(\"\\nSex:\\n\")\nprint(table(sleep_survey_data$sex))\n\ncat(\"\\nTrouble Falling Asleep (fallsleep):\\n\")\nprint(table(sleep_survey_data$fallsleep))\n\ncat(\"\\nTrouble Staying Asleep (staysleep):\\n\")\nprint(table(sleep_survey_data$staysleep))\n\n\n7.3.3 Building the Logistic Regression Model\nNow let’s create our model. We’ll use base R’s glm (Generalized Linear Model) function with the logit link:\n# Create the logistic regression model\nsleep_model &lt;- glm(probsleep ~ sex + age + fallsleep + staysleep + hrswknight,\n                   family = binomial(link = \"logit\"),\n                   data = sleep_survey_data)\n\n# Display the summary of our model\nsummary_results &lt;- summary(sleep_model)\nprint(summary_results)\n\n# Calculate odds ratios and confidence intervals\nodds_ratios &lt;- exp(coef(sleep_model))\nconf_int &lt;- exp(confint(sleep_model))\n\n# Combine results in a readable format\nresults_table &lt;- cbind(\n  Estimate = round(coef(sleep_model), 3),\n  \"Odds Ratio\" = round(odds_ratios, 3),\n  \"CI Lower\" = round(conf_int[,1], 3),\n  \"CI Upper\" = round(conf_int[,2], 3),\n  \"p-value\" = round(summary_results$coefficients[,4], 3)\n)\n\n# Print results\ncat(\"\\nDetailed Results:\\n\")\nprint(results_table)\n\n# Calculate model fit statistics\nnull_deviance &lt;- sleep_model$null.deviance\nmodel_deviance &lt;- sleep_model$deviance\npseudo_r2 &lt;- 1 - (model_deviance / null_deviance)\n\ncat(\"\\nModel Fit Statistics:\\n\")\ncat(\"Null deviance:\", round(null_deviance, 2), \"\\n\")\ncat(\"Model deviance:\", round(model_deviance, 2), \"\\n\")\ncat(\"McFadden's Pseudo R²:\", round(pseudo_r2, 3), \"\\n\")"
  },
  {
    "objectID": "lab-uofg-02/lab-uofg-02.html#step-i4-interpreting-the-results",
    "href": "lab-uofg-02/lab-uofg-02.html#step-i4-interpreting-the-results",
    "title": "MGT4018/MGT4090 Lab 2",
    "section": "7.4 Step I4: Interpreting the Results",
    "text": "7.4 Step I4: Interpreting the Results\nLet’s break down what these results tell us.\n\n7.4.1 Model Convergence and Overall Fit\nOur model successfully converged, which means it found a stable solution. The reduction in deviance from the null model (model with no predictors) to our final model indicates how much our predictors help explain sleep problems.\n\n\n7.4.2 Individual Predictors\nLet’s examine each predictor’s contribution:\n# Create a function to interpret odds ratios\ninterpret_or &lt;- function(or, p_value) {\n  direction &lt;- if(or &gt; 1) \"increase\" else \"decrease\"\n  magnitude &lt;- abs(1 - or) * 100\n  significance &lt;- if(p_value &lt; 0.05) \"significant\" else \"not significant\"\n  \n  sprintf(\"%.1f%% %s in odds (%s)\", magnitude, direction, significance)\n}\n\n# Print interpretations for each predictor\ncat(\"Interpretation of Effects:\\n\\n\")\nfor(i in 2:nrow(results_table)) {\n  var_name &lt;- rownames(results_table)[i]\n  or &lt;- results_table[i, \"Odds Ratio\"]\n  p_val &lt;- results_table[i, \"p-value\"]\n  \n  cat(var_name, \":\", interpret_or(or, p_val), \"\\n\")\n}\n\n\n7.4.3 Key Findings\nOur analysis reveals that:\n\nStaying Asleep (p &lt; 0.001): This is our strongest predictor. People who have trouble staying asleep are significantly more likely to report general sleep problems.\nFalling Asleep (p = 0.035): Difficulty falling asleep is also a significant predictor, though not as strong as - staying asleep.\nHours of Sleep (p = 0.007): Each additional hour of sleep is associated with a decrease in the odds of reporting sleep problems.\nAge and Sex: Neither demographic variable significantly predicts sleep problems (p &gt; 0.05).\n\n\n\n7.4.4 Model Accuracy\nWe can examine how well our model predicts sleep problems:\n# Calculate predicted probabilities\npredicted_probs &lt;- predict(sleep_model, type = \"response\")\npredicted_class &lt;- ifelse(predicted_probs &gt; 0.5, 1, 0)\nactual_class &lt;- as.numeric(sleep_survey_data$probsleep) - 1\n\n# Create confusion matrix\nconf_matrix &lt;- table(Predicted = predicted_class, Actual = actual_class)\nprint(\"\\nConfusion Matrix:\")\nprint(conf_matrix)\n\n# Calculate accuracy metrics\naccuracy &lt;- sum(diag(conf_matrix)) / sum(conf_matrix)\nsensitivity &lt;- conf_matrix[2,2] / sum(conf_matrix[,2])\nspecificity &lt;- conf_matrix[1,1] / sum(conf_matrix[,1])\n\ncat(\"\\nModel Performance Metrics:\\n\")\ncat(\"Accuracy:\", round(accuracy, 3), \"\\n\")\ncat(\"Sensitivity:\", round(sensitivity, 3), \"\\n\")\ncat(\"Specificity:\", round(specificity, 3), \"\\n\")\n\n\n7.4.5 Practical Implications\nOur analysis suggests several important practical implications:\n\nSleep Maintenance: The strong effect of staying asleep suggests that interventions focused on sleep maintenance might be most beneficial.\nSleep Duration: The significant effect of hours of sleep indicates that strategies to increase sleep duration could help reduce sleep problems.\nUniversal Impact: The lack of significant age and sex effects suggests that sleep problems affect people regardless of these demographic factors.\n\n\n\n7.4.6 Limitations and Considerations\nWhen interpreting these results, consider:\n\nSelf-reported data may be subject to recall bias.\nThe binary nature of our outcome variable might oversimplify complex sleep issues.\nThere might be other important predictors we haven’t included in the model.\n\n\n\n\n\n\n\nLogistic Regression with R Packages\n\n\n\n\n\nModern R packages provide enhanced capabilities for conducting and interpreting logistic regression analyses. We’ll use several packages that work together to create a comprehensive analysis while making the process more intuitive and the results more interpretable.\n# Install packages if needed\ninstall.packages(c(\"tidyverse\", \"broom\", \"performance\", \"sjPlot\", \"marginaleffects\"))\n\n# Load required packages\nlibrary(tidyverse)    # For data manipulation and visualization\nlibrary(broom)        # For tidying model output\nlibrary(performance)  # For model diagnostics and performance metrics\nlibrary(sjPlot)      # For plotting odds ratios and model summaries\nlibrary(marginaleffects)  # For calculating and plotting marginal effects\nUnderstanding our Data\nThe tidyverse package provides powerful tools for initial data exploration:\n# Create our analysis dataset\nsleep_data &lt;- sleep_survey_data %&gt;%\n  select(probsleep, sex, age, fallsleep, staysleep, hrswknight) %&gt;%\n  # Convert to factors with meaningful labels if not already done\n  mutate(across(c(probsleep, sex, fallsleep, staysleep), \n                ~factor(., levels = c(0, 1), \n                        labels = c(\"No\", \"Yes\"))))\n\n# Examine our data structure\nglimpse(sleep_data)\n\n# Check missing data patterns\nmissing_pattern &lt;- sleep_data %&gt;%\n  summarise(across(everything(), ~sum(is.na(.)))) %&gt;%\n  pivot_longer(everything(), \n               names_to = \"Variable\", \n               values_to = \"Missing_Count\")\n\nggplot(missing_pattern, \n       aes(x = reorder(Variable, Missing_Count), y = Missing_Count)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  theme_minimal() +\n  labs(title = \"Missing Data Pattern\",\n       x = \"Variable\",\n       y = \"Number of Missing Values\")\nBuilding the Logistic Regression Model\nThe tidyverse and associated packages make model building and interpretation more straightforward:\n# Fit the model\nsleep_model &lt;- glm(probsleep ~ sex + age + fallsleep + staysleep + hrswknight,\n                   family = binomial(link = \"logit\"),\n                   data = sleep_data)\n\n# Get tidy model summary\nmodel_summary &lt;- tidy(sleep_model, \n                     conf.int = TRUE, \n                     exponentiate = TRUE)\n\n# Create a nice summary table\nmodel_summary %&gt;%\n  mutate(across(where(is.numeric), ~round(., 3))) %&gt;%\n  knitr::kable(col.names = c(\"Predictor\", \"Odds Ratio\", \"Std. Error\", \n                            \"z value\", \"p-value\", \"CI Lower\", \"CI Upper\"),\n               caption = \"Logistic Regression Results\") %&gt;%\n  kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\nModel Diagnostics and Performance\nThe performance package provides comprehensive model diagnostics:\n# Check model performance\nmodel_performance &lt;- check_model(sleep_model)\n\n# Get various performance metrics\nperformance_metrics &lt;- model_performance(sleep_model)\n\n# Plot ROC curve\npred_data &lt;- sleep_data %&gt;%\n  mutate(predicted = predict(sleep_model, type = \"response\"))\n\nggplot(pred_data, aes(d = as.numeric(probsleep) - 1, m = predicted)) +\n  geom_roc(n.cuts = 0) +\n  style_roc() +\n  theme_minimal() +\n  labs(title = \"ROC Curve for Sleep Problems Model\")\nUnderstanding Variable Effects\nThe marginaleffects package helps us understand how our predictors influence sleep problems:\n# Calculate average marginal effects\nmarg_effects &lt;- avg_slopes(sleep_model)\n\n# Plot marginal effects\nplot_slopes(sleep_model, \n           variables = \"hrswknight\",\n           condition = \"staysleep\") +\n  theme_minimal() +\n  labs(title = \"Effect of Sleep Hours by Staying Asleep Status\",\n       x = \"Hours of Sleep per Weeknight\",\n       y = \"Predicted Probability of Sleep Problems\")\n\n# Create effects plot for categorical variables\nplot_model(sleep_model, \n          type = \"pred\", \n          terms = c(\"staysleep\", \"fallsleep\")) +\n  theme_minimal() +\n  labs(title = \"Interaction between Falling and Staying Asleep\",\n       y = \"Predicted Probability of Sleep Problems\")\nVisualizing Model Results\nsjPlot provides excellent visualization tools for model results:\n# Plot odds ratios\nplot_model(sleep_model, \n          show.values = TRUE, \n          title = \"Odds Ratios for Sleep Problems\") +\n  theme_minimal()\n\n# Create predicted probabilities plot\nplot_model(sleep_model, \n          type = \"pred\", \n          terms = \"hrswknight\",\n          title = \"Effect of Sleep Hours on Problem Probability\") +\n  theme_minimal()\nAdvantages of Using Modern Packages\nThese modern R packages offer several benefits over base R:\n\nThe tidyverse provides:\n\n\nMore intuitive data manipulation\nEnhanced visualization capabilities\nConsistent syntax across operations\n\n\nbroom offers:\n\n\nStandardized model output formats\nEasy extraction of model statistics\nSimple integration with other tidyverse tools\n\n\nperformance gives us:\n\n\nComprehensive model diagnostics\nEasy-to-interpret visualizations\nMultiple performance metrics\n\n\nmarginaleffects enables:\n\n\nIntuitive interpretation of variable effects\nBeautiful visualization of interactions\nStraightforward prediction scenarios\n\nCreating a Complete Report\nWe can create a comprehensive analysis report using these tools:\n# Function to create a complete model summary\ncreate_model_report &lt;- function(model) {\n  # Model summary\n  summary_stats &lt;- glance(model)\n  \n  # Coefficients and odds ratios\n  coef_table &lt;- tidy(model, conf.int = TRUE, exponentiate = TRUE)\n  \n  # Predictions\n  pred_data &lt;- augment(model, type.predict = \"response\")\n  \n  # Return as list\n  list(\n    model_stats = summary_stats,\n    coefficients = coef_table,\n    predictions = pred_data\n  )\n}\n\n# Generate report\nmodel_report &lt;- create_model_report(sleep_model)\n\n# Print key findings\ncat(\"Model Performance Metrics:\\n\")\nprint(model_report$model_stats)\n\ncat(\"\\nKey Predictors:\\n\")\nprint(model_report$coefficients)\nPractical Implementation\nHere’s how to use these results in practice:\n# Create a prediction function for new cases\npredict_sleep_problems &lt;- function(new_data) {\n  predictions &lt;- predict(sleep_model, \n                        newdata = new_data, \n                        type = \"response\")\n  \n  tibble(\n    probability = predictions,\n    predicted_outcome = if_else(predictions &gt; 0.5, \"Yes\", \"No\")\n  )\n}\n\n# Example usage\nexample_cases &lt;- tibble(\n  sex = factor(c(\"Male\", \"Female\"), levels = c(\"Male\", \"Female\")),\n  age = c(30, 45),\n  fallsleep = factor(c(\"Yes\", \"No\"), levels = c(\"No\", \"Yes\")),\n  staysleep = factor(c(\"No\", \"Yes\"), levels = c(\"No\", \"Yes\")),\n  hrswknight = c(7, 6)\n)\n\npredictions &lt;- predict_sleep_problems(example_cases)\nprint(predictions)"
  },
  {
    "objectID": "lab-uofg-01/lab-uofg-01.html#step-c5-scatterplots",
    "href": "lab-uofg-01/lab-uofg-01.html#step-c5-scatterplots",
    "title": "MGT4018/MGT4090 Lab 1",
    "section": "4.5 Step C5: Scatterplots",
    "text": "4.5 Step C5: Scatterplots\nScatterplots are essential for visualizing the relationship between two continuous variables. They help identify trends, correlations, and potential outliers. By adding categorical grouping and labeling points, scatterplots become even more informative, allowing for deeper insights into patterns within subgroups.\nIn this exercise, we create three scatterplots using the survey_data_full dataset:\n\nA simple scatterplot with tpstress as the dependent variable (y-axis) and tpcoiss as the independent variable (x-axis).\nA scatterplot with color-coded points based on sex (categorical grouping).\nThe same scatterplot as above, but with point labels based on the id variable.\n\n\n4.5.1 Simple Scatterplot\nThe first scatterplot shows the relationship between tpstress (perceived stress) and tpcoiss (control over internal states).\n# Simple scatterplot\nscatter_stress_control &lt;- ggplot(data = survey_data_full, aes(x = tpcoiss, y = tpstress)) +\n  geom_point(color = \"blue\", size = 2) +\n  labs(\n    title = \"Scatterplot of Perceived Stress vs Coping Strategies\",\n    x = \"Coping Strategies (tpcoiss)\",\n    y = \"Perceived Stress (tpstress)\"\n  ) +\n  theme_minimal()\n\n# Show plot\nscatter_stress_control\n\n# Save plot\nggsave(\"output/figures/scatter_stress_control.pdf\", width = 8, height = 5)\nExplanation of the Code\n\nggplot() specifies the dataset (survey_data_full) and maps tpcoiss to the x-axis and tpstress to the y-axis.\ngeom_point() adds scatterplot points. color = \"blue\" sets the color of all points. size = 2 adjusts the point size for better visibility.\nlabs() adds a title, x-axis label, and y-axis label for clarity.\ntheme_minimal() ensures a clean and professional appearance.\n\nInterpretation of the Graphs\nThe simple scatterplot shows the relationship between tpstress (perceived stress) and tpcoiss (coping strategies) across all participants (Figure 8). When examining a scatterplot, there are a few key points to consider.\n\nDirection of the relationship:\n\nA negative trend (points sloping downward) as shown in Figure 8 suggests that higher coping strategies are associated with lower perceived stress.\nA positive trend (points sloping upward) would, alternatively, suggest that higher coping strategies are associated with higher perceived stress.\nA flat trend (points scattered without a clear pattern) would, alternatively, suggest no apparent relationship between the variables.\n\nStrength of the relationship:\n\nPoints clustered tightly along an imaginary line indicate a strong relationship.\nPoints scattered widely indicate a weaker relationship or greater variability.\n\nOutliers:\n\nPoints far from the general trend or clustering might indicate participants with unusual scores (e.g., very high stress despite low coping strategies).\n\n\n\n\n\n\n\n\nFigure 8: Simple scatterplot for tpstress and tpcoiss\n\n\n\n\n\n4.5.2 Scatterplot with Categorical Grouping\nTo differentiate points by gender, we map the sex variable to the color aesthetic. This helps identify potential differences in the relationship between tpstress and tpcoiss for males and females.\n# Scatterplot with grouping by sex\nscatter_stress_control_gender &lt;- ggplot(data = survey_data_full, aes(x = tpcoiss, y = tpstress, color = sex)) +\n  geom_point(size = 2) +\n  labs(\n    title = \"Scatterplot of Perceived Stress vs Coping Strategies by Gender\",\n    x = \"Coping Strategies (tpcoiss)\",\n    y = \"Perceived Stress (tpstress)\",\n    color = \"Gender\"\n  ) +\n  theme_minimal()\n\n# Show plot\nscatter_stress_control_gender\n\n# Save plot\nggsave(\"output/figures/scatter_stress_control_gender.pdf\", width = 8, height = 5)\nExplanation of the Code\n\nggplot() specifies the dataset (survey_data_full) and maps tpcoiss to the x-axis and tpstress to the y-axis, color = sex assigns different colors to males and females.\ngeom_point() adds scatterplot points. color = \"blue\" sets the color of all points. size = 2 adjusts the point size for better visibility.\nlabs() adds a title, x-axis label, and y-axis label for clarity. color = \"Gender\" labels the legend as “Gender” for clarity.\ntheme_minimal() ensures a clean and professional appearance.\n\nInterpretation of the Graphs\nThe grouped scatterplot adds a layer of complexity by differentiating the points based on sex (males and females) using color coding (Figure 9), which allows for subgroup comparisons. When examining a grouped scatterplot, there are a few key points to consider.\n\nComparing trends between groups:\n\nLook for differences in the direction, strength, or spread of points for each group.\nParallel trends suggest that the relationship between tpstress and tpcoiss is consistent across genders.\nDiverging or crossing trends may indicate that the relationship differs between males and females.\n\nClustering patterns:\n\nAre males and females clustered in similar regions of the plot, or are they spread differently?\nFor example, one group may predominantly occupy the lower tpcoiss range while the other spans the full range.\n\nGroup-specific outliers:\n\nOutliers can be identified separately for each group, helping to explore whether certain groups have more extreme responses.\n\n\n\n\n\n\n\n\nFigure 9: Grouped scatterplot for tpstress and tpcoiss by sex\n\n\n\n\n\n4.5.3 Scatterplot with Point Labels\nAdding point labels based on the id variable allows us to identify individual data points in the scatterplot. This is similar to the “Point ID label” feature in SPSS.\n# Scatterplot with point labels\nscatter_stress_control_gender_id &lt;- ggplot(data = survey_data_full, aes(x = tpcoiss, y = tpstress, color = sex)) +\n  geom_point(size = 2) +\n  geom_text(aes(label = id), hjust = 0, vjust = -0.5, size = 3) +\n  labs(\n    title = \"Scatterplot of Perceived Stress vs Coping Strategies with Point Labels\",\n    x = \"Coping Strategies (tpcoiss)\",\n    y = \"Perceived Stress (tpstress)\",\n    color = \"Gender\"\n  ) +\n  theme_minimal()\n\n# Show plot\nscatter_stress_control_gender_id\n\n# Save plot\nggsave(\"output/figures/scatter_stress_control_gender_id.pdf\", width = 8, height = 5)\nExplanation of the Code (only difference to the previous code)\n\ngeom_text() adds labels to each point. aes(label = id) specifies that each point is labeled with the id variable. hjust = 0, vjust = -0.5 adjusts the position of the labels relative to the points. size = 3 sets the text size for readability.\nThe rest of the code is similar to the grouped scatterplot, with points color-coded by gender.\n\nInterpretation of the Graphs\nThe labeled scatterplot builds on the grouped scatterplot by adding participant identifiers (id) as point labels (Figure 10). This is useful for identifying specific data points and exploring individual-level patterns. There are a few key points to consider when analyzing labeled scatterplots.\n\nIdentifying specific participants:\n\nOutliers or points of interest can now be linked to specific participants using their id.\nFor example, if a participant shows very high tpstress despite low tpcoiss, their id can be used to investigate their survey responses further.\n\nLabel clustering:\n\nOverlapping labels can indicate regions with many participants sharing similar scores.\nSparse labels suggest regions with fewer participants, highlighting gaps in the data.\n\nPotential for follow-up:\n\nBy identifying participants with unusual scores (e.g., a specific participant shows extreme stress levels tpstress with high coping strategies tpcoiss), researchers can seek qualitative responses or additional variables to better understand these cases.\n\n\n\n\n\n\n\n\nFigure 10: Grouped scatterplot for tpstress and tpcoiss by sex with point labels"
  }
]